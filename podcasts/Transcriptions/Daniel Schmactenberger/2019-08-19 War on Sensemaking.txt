I think it's clear to probably most of your listeners, that the things called news are mostly propaganda, narrative warfare for some agency, and that they aren't good sources of sense making. We would hope though, that there are some sources of high signal low noise, true information like maybe scientific journals, like academia, science itself. I hope this a long time ago, and I had the continuous kind of disappointment. You know, I started being like, okay, can't Can't trust the news to be true? Because news is narrative for fair, I can't trust science without actually really looking at what was the methodology employed? How was it funded? What were the axioms that the team was using? What were the logical transforms missing all of their data or the cherry pick data? And as we, as I started to kind of unfold to say, Where are the high signal, low noise sources that I can offload? Some of the cognitive complexity of making sense of the world to answer is really sad, right? I don't know any sources that are very high signal and low noise across lots of areas. So disturbing, like, why is that? And what would it take to fix that? What would it take to make a world that had an intact information ecology? Well, that requires understanding why the current information ecology is as broken as it is, and we're starting to touch on a couple things here, but this goes deep. And how do we make good choices if we don't have good sense make? Well obviously, we can't but due to Increasing technological capacity, right? increasing population multiplied by increasing impact per person. We're making more and more consequential choices with worse and worse sense making to inform those choices, which is kind of running increasingly fast through the woods increasingly blind, right. And so I think many of the people that you've had on rebel wisdom have been in a deep inquiry around, how do we actually fix our own sense making and it's some of what has brought us to have conversations with each other. Because a part of how we work with our own sense maintenance, we recognize the cognitive complexity of issues that the world faces is more than a single person can process a single brain that can't actually hold that karmic complexity. So it requires collective intelligence and collective sense making. But I can't just offload the cognitive complexity to some folks D, because I can't trust that they're actually doing good sense making, maybe they're doing good sense making within a very limited context. But then the application of that outside of the context is different. And maybe there's even distortions within their context. So, I have to try and find other people that are also really endeavoring this sense make well, which means they have to understand what causes failures and sense making and then we have to see can we create relationships with each other that removed the distortion basis, that is normally there. So I think, from what I have seen a rebel wisdom, this is probably the strange attractor of what is bringing everybody to watch it is people who are trying to make sense of the world better themselves and are trying to find sources of content of other other people that have been trying to make sense of it well, which is what I'm excited about. And so those are just some opening thoughts and I look forward to getting into why we have as friends And information at colleges we have and what it would take to correct that at scale, and how we can make sense of the world even in the broken information ecology. Now in terms of practical processes. 
I've never actually shared publicly these types of frameworks before. So this feels fun and exciting. And I hope that's useful. As I've been trying to make sense of the world, making sense of why, since making it so hard, is pretty Central. There's a famous quote, I think, attributed to Einstein make things as simple as possible, but not simpler. As simple as possible. Really, the goal isn't is as clear as possible, right? But simpler would mean it's wrong. Like it's not accurate anymore. If I'm, you know, you're gonna have to face this doing media work, there will be pressures on you to say, hey, people can't pay attention to more than sound bites, you got to make it five minute chunks, the word sizes too big make it for an eighth grade level, right? Which is saying people are dumb. So spoon feed them stuff that dumb people can handle, which to the degree you do that and it's successful will keep people dumb. But that's, that's what like those are the pressures and in anyone doing broadcast even for a hopefully good intention, right? And if we want people to actually be able to make sense of the world, well. You can't do it in very short periods of time with lots of distraction. And oversimplified like, if you if you look at anyone who actually increase the sense making capacity of the world you look at any scientist or philosopher, they didn't do it in tweets. And they didn't do it radically distracted. And they didn't do it in a dumbed down process. Right like I have. I have so many people who have written to me saying like, we want to create a new kind of education, young people, we want to create a new kind of education that makes everybody like Bucky Fuller's or Leonardo's that conditions, polymath, and they say this because I've written some stuff on that topic. And that they have some sense that they could leave that and I'm like, have you read bunkies books? Like, well, no, we mostly don't read books. And have you read the references and Becky's books just see the amount of shit that he read and referenced to make sense things well, and so there's a there, there's a decoupling of the sense of the agency possible with what it takes to do it. It's you know, like, there's a saying everywhere in almost all domains to this effect of like, everybody wants to be buffed, but nobody wants to lift heavy ass weights or everybody wants to win. 
Nobody wants to work harder. There's something like that that happens here is if I want to be able to make sense of the world, well, I have to work at that. And if I want to be able to make sense of the world better, the world better than I currently do, like a tension requires being trained. Just like muscles require being trained. thinking clearly requires being trained. And anytime I'm there's a hormetic process, you know, hormesis is the principle by which you stress an adaptive system to increase its adaptive capacity. So I have to stress a muscle to get the muscle to grow. If I'm lifting an amount of weight that super Easy, the muscle, there's no input that says the muscle needs to be bigger. And there's a cost to getting bigger, right? So it's only going to go through that cost if it's being stressed. And the same is true, like if I expose myself to more heat and more cold than is comfortable, actually gain greater metabolic flexibility to deal with heat and cold, which means that if I stay in an environment where I always have heating and air conditioning actually lose metabolic flexibility, you have to stress the system to be able to grow the system in a particular kind of way. Not all stressors are going through the system. But this is definitely true cognitively. Which means if I keep paying attention to hyper normal stimuli that are moving quickly, so I get the stimuli of lots of novelty. I'm going to be decreasing my attention. But if I want to have any kind of nuanced view, I have to be able to hold multiple partial views and working memory. It's not that some people have good memory or good attention and other people don't intrinsically any more than some people buffin some aren't intrinsically, it's developable, but it has to actually be developed. So to the impulse to say, hey, make it really simple, so everybody can get it and the impulse to say help people actually make sense of the world well, or different things. Now, some people will make stuff technical, seeming intentionally to obscure it as a power game. Right? So that to encourage others to defer their sense making to them, I understand this complex shit, you're not gonna be able to understand this. So defer authority to me. 
We want to do something. If we actually want to empower people, I don't want them to defer their sense making to me. But I also don't want them to do lazy shitty sense making or defer it to anyone else, which means I want them to grow the quality of their own sense making which means to grow the depth of their care, right anti nihilism to grow the depth of their care to grow. The depth of their earnestness, their own self reflectiveness, to pay attention to their biases, and where they're sloppiness and thinking their own skills and capacity on them to grow their attention span. And both the clarity of their logic and the clarity of their intuition and the noticing when something's coming from intuition or logic and how to relate those like, all of those things, but that's actually what increasing sovereignty means. So information ecology is that there's a there's a whole ecosystem of information, right? Like we have information coming in from marketing information coming in from government sources, from campaigning from just what our neighbors tell us and our friends tell us from social media from like, and we use information to make sense of the world to make choices that are aligned with whatever our goals are and our values and what's meaningful to us. And what we hope is that the information around us is mostly true and representative of reality, so that we can use Use that to make choices that will be effective. When I say broken information ecology, it means that we can't trust that most of the information coming in is true and representative of reality and will inform Good choice making. And so then this is where we have to get into. Okay, so where does information come from? Right? signals are being shared by people in like groups of people that have shared agency like corporations and governments and political parties and religions and whatever, right? And so we want to start getting into why do people share information other than just sharing what is true and representative of reality? This is actually a really key thing to start to understand. So maybe I'll actually define something that I was just referencing, which is the difference between true and truthful. So first important distinction when we say someone's being truthful What we mean? Is that what they, if you're being truthful with me, it means that what you are sharing maps to what you believe, right? That there's a correspondence between the signal that you're communicating to me and what you believe is true. So we can look at breakdowns of truthfulness, which is where people are distorting information with some intentionality. And that can either be through overt lying, or through lying through omission, or lying through emphasis bias, right, those kinds of things. So that's truthful. And when we say something is true, what we typically mean and this is actually this gets very nuanced. So we end up having to get into like fundamental epistemology, ontology concepts of what does it mean for something to be true? What are our fundamental axioms about the nature of reality? Put that on hold for now. And just say, in general, if we say that someone's saying something that's true, we don't just mean There's a correspondence between what they're saying and what they think. But there's a corresponds between what they're saying and some independently verifiable reality. And so, of course, someone can be truthful, meaning they say what they believe, but what they believe is misinformed because they did sense making poorly. So they're propagating information, honestly. But that is not true. And so we need to look at distortions in both of these. There's a third thing, which is representative, which is, it's possible for someone to be truthful, share exactly what they think is going on, and that what they're sharing is actually true. They've actually done good epistemology, and empirically validated that what they're saying maps to reality and in some clear way, and yet, the interpretation I get from that will still actually mislead me. Because it's not the true information is not representative of the entire content. Well, articles published in famous journals, peer reviewed scientific journals like Journal of American Medical Association. 
Five years later, we'll see that a major percentage of them something like 50% are found to be mostly inaccurate. 50% is a coin toss, right? Or we see the replication crisis, or we see that the things that get studied, even if it's true information, it can be misleading, because for the most part, where does the money to fund the research come from? It's going to come within capitalism, mostly where there's some ROI on the research and so some areas have moral ROI than other so even a bunch of true information but that is weighted towards certain parts of the information ecology over others, create misrepresentation through preponderance of information, right so even a bunch of true information can create distortion. So then you start to say, oh, okay, so the essence of science within the philosophy of science, the essence of it is earnestness of inquiry, right. It's an empiricism. But then earnestness of inquiry. Eddington define sciences, the earnest endeavor to put into order the facts of experience. And the essence of capitalism is, so you can say the essence of science has no bias, right? At least the idea the spirit of it, we can get into where even the philosophy of science has built in axiomatic bias later. But then the, in capitalism, it is about optimizing for bias, right? Like I actually have an agency that I'm trying to get ahead, I have intention to increase my balance sheet. And so if there's capital funding of science, it's going to fund the things that create ROI on that research so we can keep doing more research that creates both a reason to distort the info. And the reason to withhold information that is a source of competitive advantage, or reason to create disinfo to other competitors and to at least wait you know, of course in biotech. If I can get a patent on a synthetic molecule, and I can't get a patent on a natural molecule, there's a lot more money is going to go into synthetic molecules and natural and then we look at and say, well, there's not that many phase three clinical trials on herbs and there are on pharma med. So the pharma meds must be more accurate. 
No, this is even true information, preponderance of data is going to create problems, right. And that's actually true information that is being shared truthfully, that would still be Miss representative of reality. So this is where I have to say, Do I have some sense of what the actual territory is? And do I have a sense that the map that's being created actually maps onto the territory reasonably well, because since making means map generation, right to be able to make choices of how we navigate how we do choice making and relationships with some actual territory. So that's true, truthful, and then representative and we can look at distortions and all three of those. So when we look at why is an individual distorted information that the most fundamental way of thinking about it is there's this idea in terms of signaling, like if I'm just in nature watching and I'm watching what is happening with rabbits and trees and birds, I'm getting information about them that they aren't even intending to transmit. And so the information is just reflective right lights actually reflecting off of them of the nature of reality. As soon as there's an agent that can share information strategically, for an intention, then I don't know if what they're sharing is reflective of reality or reflective of what they think will advance their intention. And that's kind of the key distinction is that the moment we get abstract signaling, which language allows us and the ability to kind of forecast and our ability to model each other and your well being and the basis of your agency doesn't seem coupled with my well being and the basis My agency perfectly in the case of the partner wanting to cheat and get away with it, right, there's a decoupling well being an agency in the case of, if I'm a marketer of a product, and I want you to purchase it, whether my product is actually the best product or not, whether competitor's product is better, whether you need the product or not, I want you to think that you need it and the thing that minus the best, right, so there's a breakdown between what seems to be in my well being and what seems to be your well being. So wherever there is a any misalignment in agency, and there's the ability to share signal for strategic purposes, then you have a basis to have a signal that's being shared that isn't just truthful, right? So then we look at what where's that happening and it's fucking everywhere, right, to really gross or subtle degrees pretty much everywhere. And sometimes for dreadful purposes. 
Like I mean, you got the prosaic purposes, which are basically market type dynamics, which most of the dynamics in the world are market dynamics or at least influenced by market dynamics, right. market dynamics are fundamentally at least partially if not mostly rivalrous, meaning my balance sheet can get ahead independent of your balance sheet getting ahead and definitely independent of the comments, right. And so, in a market type dynamic, I'm going to be sharing information and this is why buyer beware. But as soon as buyer beware is not just, you know, check to make sure that the car isn't about to break down. It's also check to make sure that the information shared is being true because if if I'm actually sharing information as a service, right, and you're purchasing that information, whether it's whether you're paying for it with your attention that's being monetized through an ad, or you're paying for directly or whatever. There's nothing that says Sharing true and truthful information. So in market type dynamics, the, the goal of marketing is that there is see as a company, and from the supply side of supply and demand dynamics, the goal is to compel the purchasers action in a particular way, which means, as a company I want to do sense making for you, because I want to control your choice making at least one to influence your choice making, I'm not actually interested in your sovereignty, and I'm not even that interested in your quality of life. 
I'm interested in you thinking that I'm interested in your quality of life. I'm interested in you believing that my stuff will affect your quality of life. But whether that actually corresponds or not, I don't care. In fact, if I can sell you food that is very addictive, or cigarettes or social media, or media or porn or whatever it is, that actually decreases your baseline happiness, but then makes you need another hit faster and it's addictive. That's Really good for lifetime revenue of a customer. And to the degree that my fiduciary responsibility is to maximize profitability for me and my shareholders. And so I need to maximize lifetime revenue of my customers multiply by maximizing the customer base, addiction is the most profitable thing I can get. Right? Where that's never in the best interest of the of the customer. Now as a corporation, where I get to employ a whole bunch of people to do market research and to split test ads and to see what works best and to use psychological insights and to be thinking about your choice, making more than you're thinking about your choice making, not only is the information I'm sharing with you, not just truthful, and it's a form of kind of narrative warfare, because that were agents that are actually competing for what you do, or you I want you to do something in particular you want to do what's best for you. Those aren't the same thing. But it's actually an asymmetric warfare because I have a lot more ongoing team and focus now especially as you start to look at a big question. In powered by AI and big data and etc, it's radically asymmetric info warfare that you don't even know it's happening, right you don't even know you're engaged in. So we can see that it's all the way down to the little guy in a market, right, who's just peddling Where's his incentive is to compel people to buy the thing not to really adequately informed them that he just marked the price up a lot from where he got it down the way and if they go down the way off the beaten path, like the other stuff is better. And so this is ubiquitous, right? Okay. And then as we're exploring reasons that people share things that are not fully truthful and and representative. There of course, things worse than this. This is I would say most of where the distortion comes from is agency misalignment. Well, it's always agency misalignment, right? Mostly, we'll call that market. 
But any sources where you have some agent, whether it's a company or a country or a person that can think about their own well being independent of the well being of other agents and or the commons, then there's a basis for them to optimize their well being at with some externality in the same way we externalize cost to the environment, we can externalize the cost to the information environment and externalize costs to the information environment is like this information is pollution to the information ecology. Right, that's a kind of a good way of thinking about it. And as ubiquitous, as ubiquitous as pollution is where we see that the snow on the top of Mount Everest is full of pollution, right? of many different kinds. I would say information ecology, pollution is more of the quickness, because it's not just big industrial players doing it. It's everybody doing it and you can't even see it as clearly But even people will create distortions and information for seemingly positive reasons. Like, first is kind of innocuous reasons like okay, I'm going to write a testimonial or an endorsement for my friends book, because they're my friend. Even though I think their stuff wrong in their book, it wouldn't be that gracious of me to say that. And maybe there's some game theoretic stuff in there. Like, they wrote a nice testimonial for my book, and I want them to keep doing that. And so my giving the endorsement of my whatever credibility that other people proxy there since making to me I'm now you know, proxying, that credibility over here is not necessarily true. Even if it's not that they did the endorsement on my book, and I just am supportive of them taking a positive step. That doesn't necessarily mean that anyone else who sees that I offered that testimonial and is using that as a method of their own sense making knows why I did it. So here's the other thing. A decoupling of the signal that I'm sharing with the intention that I'm sharing it for. And so I might be sharing something with you. And I have four or five complex intentions, I might not share any of them with you. Or maybe I share one. When you're getting information from a news channel, and you're like, Oh, this news channel wants to maximize my time on site. And it can do that through appealing to my cognitive biases and my emotional biases and my identity biases. It can do that through things that are inflammatory. It can do that through all kinds of things that are hyper normal stimulus, and that hijack my attention. 
This is where it's competing for my attention against where I would want to put my attention because it's monetizing my attention, right. So I have to factor that agency the intention of the news station, and try and remove that article. Fact from the information to try and infer what the true information might be, basically, to infer what the source of distortion might be the same with the political candidate, the same with science that's coming forward, and I'm looking at, okay, so who's, who is seeking more grant funding? And what is easiest to fund? And where are their standard model biases, where only the things people are only going to share the ship that's going to get them more funding, and it's going to get tenure where they have to defend the thing that got them the Nobel Prize that not might not be true anymore for ego and identity biases, got to factor all of those kinds of sources of possible bias. And so this is the first I would say kind of valuable thing when you're trying to do sense making is to recognize that the signal that you're getting everywhere, is mostly strategic, on strategic on the part of which is just another way to say intentional on the part of the agent sharing it for Their purpose is not yours. And where there is a disalignment between your well being and there's or at least an apparent one, then what their basis for intention might actually suck for you. And even if there seems to be alignment, you still don't want lied to for your good you still want your information. So I would say one of the first things we want to do when we start to do sense making is to look at why is anyone sharing what they're sharing and not assuming that they are being truthful? So basically, truthful is about being truthful is about the fact that people are lying all the fucking time. And okay, we're actually gonna say a little bit more about that one for a moment. When you're playing poker, you learn how to bluff. Because it it's not who has the best hand that wins. It's who makes everyone else think that they have the best hand and right there's there's a lot that goes on in that. And so because it's a zero sum game, right that if my wind does not equal your wind, my wind is going to equal some other players losses. Then I have an incentive to dis inform you were information about reality as a source of competitive advantage. 
This is actually the real kind of key way of thinking about it because this information even happens in nature with other animals. Right, you'll see a caterpillar that evolved to have something on its tail that looks like a head to misinform birds so that they go to pick up the false head and it might still be able to live right like that's actually an evolved disinformation strategy. And it's just the disinformation in nature happens very slowly and where the selective pressures on the side of The caterpillar and the bird or co evolving right to the bird is getting better at noticing those things as the caterpillar is getting better at dealing with that. camouflage is a kind of disinformation, right? It's an attempt to not signal something fully because there's rival risk dynamics between the caterpillar and the bird in that scenario. But with people with our abstract replicators, we can create the distortion much, much, much faster. We can have asymmetries in the capacity to create the distortion and even exponential asymmetries. And so it's actually really quite different. So you think about the poker bluff and you think about like even in soccer or football and someone fakes left and then goes right, that's a disinformation strategy where if we're competing and information about the nature of reality, where the water is where the gold is what the market is going to do next. If this company is going Make it whatever equals a source of advantage. But we're an assumed rivalrous dynamic, we're competing for the same money competing for the same attention, whatever, then first, I have the incentive to withhold information. Right? So I don't want to tell you where the gold is. Or I don't want you to know the intellectual property that I'm going to monetize. Simply the withholding of information sucks up the information ecology so much, because I'm doing cancer research. And I've had some big breakthroughs. 
But I'm not trying to share that with everyone else who's doing cancer research, because this is being funded by a for profit process that needs to be able to monetize that through intellectual property. Right. And so we can see how much problem happens as a result of withholding of information. But we can also see how intractable this problem seems, within a game theoretic environment like capitalism, right? I keep saying capitalism, I'm not going to say that any other bad economic system we've ever tried is the answer because they aren't. We have basically disinformation and communism and socialism and fascism, we're going to suggest that new structures that have not ever happened or needed, I'm just wanting to say that here so people don't attach to me criticizing capitalism is probably gonna suggest something that doesn't work. So the first thing is withholding information. And we see in business, how much focus is on IP and MBAs and you know, those types of things. But then it's not simply withholding information. It's also dis informing, right, just like the poker block for the fake left and go, right, we haven't. And we can see in warfare, we try and have black projects where we withhold the information because we don't want the other side to know what our military capacities are. But we also try to dis inform what our military capacities are at or where we're going to attack or whatever else as a source of events. And that's been happening forever. sunsoo writes about that, right? I mean, it's just, we've we've had a basis for disinformation for a long time. We've had rival risk dynamics for a long time, the rival risk dynamics are a basis by which we can get ahead by war and killing somebody else, or lying to them right or ruining the comments. 
It's just exponential tech leads to with those same incentives leads to exponential disconfirmation exponential extraction, exponential pollution, exponentially scaled warfare, and on a finite playing field that self destruct. So the underlying cause is the same stuff that's been happening, but at a speed and scope and scale and level of complexity that forces us to have to actually deal with the underlying structures now because they, they can't continue. Okay, so that's the game theoretic side of it now. What would it take to have an intact information ecology where any information that anyone had just on the truthfulness side was being shared? There was no incentive for disinformation. First, let's just imagine Right, like no disinformation. Let's give some other examples of disinformation. There's not just where I'm intentionally trying to mislead you. There's also where I'm sharing signal for some purpose for me that might mislead you. And I'm not intending to I just don't care if I do. So let's say, there, I want some increased attention. And this might be because I'm going to monetize that attention might be because I'm going to get political power might be simply because I just want attention. Right? So let's say I comment on what some famous person is doing. Let's say I disagree with him. I'm instantly going to get some attention if I critique them effectively, that I didn't necessarily earn and I don't even have to believe the critique. Because the Association of that type, I'm going to get some attention. So now people have a basis to focus on something they weren't focused on before to criticize it because that will get attention or to compliment it or to play off In a way, that is not actually what they care about or believe. And again, you, you look at how ubiquitously it is, you know, that kind of phenomenon. Alright. So the answer to getting over the truthfulness issue is actually post game theoretic world. Because, which is the same answer is like, how do we get past warfare? Well, it's not just kinetic warfare where we throw bombs or rocks at each other. It's also info warfare, and narrative warfare and economic warfare, right, which is basically any in group that is coordinating to compete against an out group in some kind of zero sum dynamic. And that's companies to companies, it's companies, two people, two people, two people, it's countries to countries, its global economic trading blocks with each other. It's all of those things. 
What can people do right now within a game theoretic world to start to create spaces of truthfulness? This start to create relationships where one of the highest values is truthfulness with other people that are capable of and want and are committed to that where people are not only not lying to each other, but they are endeavoring to not withhold information, which is tremendous intimacy, and tremendous vulnerability. And see if you can create enough psychological safety with some people to be able to start exploring what does it mean to actually share information, honestly, so that we can have that and all kind of make sense together. That's one thing. And there's also something where it's like if you don't throw trash out the window of your car, because you don't pollute the environment. Be careful about not polluting the information. ecology by rationalizing why your own Mr. disinformation is okay. And just start to think of it that way think of anytime you're sharing Little Lies as polluting the information ecology and being like, Oh wow, I don't want to do that I, I don't want to be part of the fucked up information ecology. 
Okay so now on the true side, which is not just a mapping or a correspondence between what I'm saying and what I think but between what I'm saying and what shared reality is which means there has to be a correspondence between what I think in reality that means I had to do sense making well before I share something, right. So this is the topic of epistemology. So one is movement past game theory. The next is epistemology. How do we know stuff so even if nobody was lying, withholding information, the complexity of the world makes epistemology hard. And most people aren't even endeavoring at it. So I have, if no one was lying, and I could take all the information as at least truthful, there would be certain epistemic processes that I could apply that I can't apply if I can't even take the sources of signal as being signal without a lot of noise. Right. So there's a epistemology that I have to have, within the context of an urban environment has a lot of disinformation, how do I make sense of what is true and what isn't true? About signal coming in? And then how do I parse from lots of sigma what might be true about reality? And for like to just get a sense of why, like how big a deal this is, you take any of the biggest issues in the world like the issues that could determine whether or not we keep existing as a species. Okay, so take big environmental issues like climate change is there's disagreement as to whether climate change is real even I think and to the extent that it is a thing, what the causes are, and what the timescales are. 
Now, most people who believe fervently know climate change is real 97% of climate scientists agree it's anthropogenic greenhouse gases, etc. Most of the people that believe that fervently enough to kind of like go into narrative warfare for it have never actually looked at the primary data deeply themselves. And yet, there's an almost religious fervor around it. That was based on having proxied their sense making the people who they believe so the UN said it or the Gates Foundation said it or the whatever it is, I've heard it repeated. enough times to  just through repeatability like I have been programmed to believe this thing is true, which is not that different than believing a fundamentalist religion, religious idea, right? And let's say we take people's fervent ideas on vaccines, or their fervent ideas on the viability of market ideology or almost anything like that. Almost no one who has proven ideas has a good epistemic basis for the level of certainty they hold. There's a decoupling between how much certainty they have and how much certainty they should have through right process. And then you look at who are they practicing their sense making to and most of the time, they're not even practicing their assessment of the people who did the original research, many of whom disagree with each other, and were funded by somebody to say something that is not fully true in the first place, and who maybe were employing epistemic biases themselves. But typically it's somebody else who looked at all of that. And then someone else who looked at all of that. 
So you might have like a bunch of climate scientists into someone who is speaking about that as a clients, climate scientists at a more synthetic level, like a James Hansen or whatever to then like a gore or someone who is actually speaking to the public, who were practicing our sense making to, and we say, Okay, how many steps removed? is it and how good was the original data? And so if we think about, okay, how much radiation actually was released into the environment from Fukushima? It seems like a very straightforward thing, take a Geiger counter, and go out and do the studies. But how many people are quick to take a Geiger counter out and go do that or to be able to actually pay attention to how the flow dynamics in the air and the water are going to work or you know, so many things and so we have to take other people's time. To begin with, and those other people, let's say the data was the Japanese government or TEPCO, or whoever it was, or a conspiracy theory group that is saying no, no, it's actually releasing huge amounts of ocean although the Fisher, totally toxified. But they might just be, they have a basis to misinform, because they're getting viewership that they're monetizing through that. What How the fuck do we make sense of it? Right? So we what we start to get as it's like, is AI going to solve a bunch of problems and be relatively safe or is AI the biggest risk and going to kill us and you see that you see kind of fervent disagreement, but you see us still pedal to the metal going as fast forward as we can, with AI. And with crisper biotech, and with every type of exponential technology that could be catastrophic. 
And so there's increasing speed of choice making with decreasing sense make it intuitive Just think about like, Okay. Or even what's really going on with the Chinese government and its cyber warfare relationship with the US government. And with kind of the, what its actual capacities are and what its intent and agency is and those types of issues? Well, we know that's going to be obscured. We know both sides and all kinds of sides are going to be obscuring information. And it gets even worse, because it's not just that you've got this group of people called China and this group of people called the US and that they're in a game theoretic relationship with each other. But everybody on Team USA cooperates perfectly. No, of course, it's not that right. So even within the intelligence agencies, I might have two different intelligence agencies that are supposed to be cooperating, but they're competing for a bigger percentage of the black budget. And so they might be withholding information from each other or even dis informing each other then I might have two agents within an agency competing for the same promotion, who might run decentral on each other. So I have fractals. This information, right and almost every place because of a game theoretic incentive system, which is the balance sheet of countries, the balance sheet of organizations, the balance sheet of all the way down to individual people, right, this separation of the of the agency. Now, I'm back to the game theory truthfulness side. But I have to factor that when I'm trying to make sense of things because I have to be able to parse signal from noise to then be able to synthesize the signal. But then, even if that wasn't the case, I'm just just trying to do epistemology on good signal. And I have to say, okay, in a complex system, like where we can't even forecast the weather 10 days out very well, how do I forecast the effect of putting certain kinds of pesticides or genetically modified organisms or whatever into the environment, right. It's a complex system that we can't forecast very well at all. We we don't we don't know the tiniest bit of the actual information of how that complex system is going to regulate. But we're going to do stuff that affects those systems at scale. What is the right epistemology to be able to make sense of is this a good choice? And so you can see and you know, what are all the metrics, we have to factor? Let's say, we're talking about biotech. Okay, so I can give you a drug that is good for some biometric that happens to be associated with a disease that I'm taking. I'm trying to get the doctors to be able to use this drug allowed by the FDA to treat a particular disease. 
And since the disease is identified by this biomarker, I have to affect this biomarker. So let's say I'm talking about high cholesterol, and so we develop a standard for it. How many other metrics are this this data affecting? Well, every day we're learning new biometrics we didn't even know existed. How many of those are being affected? They're part of the Unknown, Unknown set that we don't even know to be able to do risk calculation on. Now, we could say, well, let's run the experiment long enough before we Release the drug to see if it affects total longevity and all cause mortality. Well, nobody fucking does that nobody is going to run hundred year experiments on something before they release the thing, they're going to run the shortest ones they can. So where you have a system that has delayed causation, how do I know if that's creating problems way down the road? What does all the time right? So we get rid of DDT or marathon or marathon because we see that it's super poisonous after we've been spraying it on everybody. And then we bring in a new drug that we also didn't do long term studies on, I mean, a new pesticide. And then we outlaw it after a little while, and then we bring a new one, the new ones aren't safer, they just haven't had as much time to show how dangerous they are. So then the question is like, what would the right epistemology be? How many metrics Do I have to factor? How do I know how to factor those metrics? What is the total information complexity of the scenario relative to how much I've actually the information complexity of the assessment that we've done? So we can get into at some depth the topic of appropriate epistemology, for very various contexts. But the I guess the first thing I can say is that if people aren't even thinking about that their chance of making sense well is pretty close to zero. We think about the concept of a mean, the way that Dawkins originally put it forward, it's a abstract pattern replicated where a gene is an instantiated pattern replicator, which means that it can mutate and change and affect behavior and propagate much, much, much faster. Right? 
And we can kind of say that in homosapiens, our genetics selected for mimetics for higher order mimetics, right, or genetics, because most other species, what the selective pressures had them be adaptive to an environment, right? They this mutation, and then the mutations that survive and make the best of the ones that make it through but that's within the context of survive in that environment and are able to make successfully in that environment, they become more more fit to their environment. So the cheetah does really well in the Savannah would not do well in the Arctic and the polar bear wouldn't do well in the Sudan. And the Orca wouldn't do well outside of the ocean, right like so they they are well adapt to their environment, because of our abstraction capacity, which is both our capacity for language and means as well as tools. We were able to go and become adaptive become actually apex predators in the savanna, and in the Arctic, and in the ocean, and everywhere, right, we were able to go to every environment, which means that as soon as our population would normally if we were any other animal start to level off in relationship with the environmental carrying capacity of an environment we just moved, we were able to decimate that environment and move to the next one, right until all of them and then but that part isn't the part I want to get into it. Now. It's it since we were going to be adaptive to totally new environments. And since we were going to create tools where what was to be adaptive was changing. Since since we modify our environment in ways the other animals don't, we can't come in genetically fit to a specific environment we have to come in and be able to imprint the environment that we're in. So we know how to be fit two totally different environments because like, it's not that adaptive for us to throw Spears, or even climb trees all that well, but it is to be able to like text and drive and stuff that wouldn't have been adaptive thousand years ago. And so this is why human babies are embryonic or Niantic this for so long, right compared to any other animal and if you like, the thing I like to do here is to think about a horse standing up in like 20 minutes. And a human being able to walk in like a year. And just think about how many 20 minutes segments multiply into a year to get a sense of how much longer we are helpless than anything else's. 
And even amongst the other primates close to us. This is this really nothing thing like us in terms of the extended helplessness. And that's because we're, we don't have inherited knowledge of how to be us since the environment is going to be different, we have to imprint the environment that we're in to be able to be adaptive to environments that we're changing, right. So and so this is a saying that our genetics selected for neural plasticity selected for mimetics, our hardware selected for faster software updates that could have faster changes in adaptive basis so that we could move our environments and all those types of things. So if we think about a meat and kind of like a gene as an as a pattern replicator, but as an abstract pattern, replicator that can mutate much quicker. There's also a big difference is that the other animals aren't it in an environment, the mutation across genes is very evenly distributed. mutations happening to the gazelles and to the cheetahs at an equal rate, right. And there's co selective pressures on both of them. So they're both getting faster the slowest ones and eat your dying off. And so there's this kind of symmetry of power that has the competitive pressures between them have them all up level. But when we start being mostly mimetic, and the other species are still mostly genetic, meaning we're largely based, we're getting adaptive based on abstract pattern applicators are still instantiated pattern replicators we can increase our predictive capacity much faster than they can increase their than the environment can increase its resilience to a productive capacity, which means that we can debase the whole substrate that we depend upon, which is self terminating, right, you can't keep debasing that which you depend on. So, in evolution, there is a selection process for the genes that make it through, right. But they there is this kind of semi A tree of the genes that make it through because of the evenness of mutation and because of the CO selective pressures. Now with mimetics the means that make it through are the means that when in a rival risk context, not the ones that necessarily represents the true or the good or the beautiful, so the propagate of names propagate more than the true means propagate. 
This is a super important concept to understand, which is, like I was always dumbfounded, thinking about the evolution of religions and take Christianity for instance, and you say, okay, so Jesus, when they brought Mary Magdalene said, Let He who has no sense amongst you cast the first stone, right? And then when they're nailing him up, he says, Father, forgive them for they know not what they they do, and he's like, bringing forgiveness to Judaism. And in his name, we did the Crusades in the Inquisition, and said, We will not just kill but torture. Anyone who doesn't accept the lord of pieces. There. Like, how the fuck did we do that? How did we do the mental gymnastics to take the guy whose key teachings were forgiveness and torture people in the name of that? Well, we figured out how to do it right. But the key is it was super adaptive. So you you've got an idea, right? 
So you've got Jesus teachings, or we can take it in any of them. And then there's going to be a bunch of mutations on that idea, different interpretations of it. Some of the mutations say, Be quiet, and don't push your ideas on anyone, be contemplative, and you know, etc. And those ones don't catch on because they aren't being intentionally propagated. And other ones say, go out and propagate these ideas on missions and and crusades and focus on the not the forgiveness parts, but on the like wrath and Leviticus and who God's enemies were like focus on those parts, and that you actually get better spots and heaven for Converting more people, right and, and so what you end up getting is that the ideas that catch on are the ones that win in narrative warfare. But they're having to catch on. So then say Islam is also competing for some of the same people, right? Because ultimately, the religions become the basis of, of in groups that are competing against our groups for fundamentally political and economic and survival type bases. So I can hold people together with a political left or political right ideology, or a capitalist communist ideology or racial identity ideology or religious ideologies, all of those become the basis of an in group that can be that can bind together to be more successful in competition with assumed out groups, right. But what that means is that rival risk game theoretic environment is going to be selecting for what is effective at rivalry, not what is true, and, and definitely not what it's good for the whole and the moment that anybody figure something out that is more effective at rivalry than everybody else reverse engineers it and you know, create similar mimetic mutations on other sides. And so there's not that many James. Right? Terrible, they're lovely people, right and totally nonviolent and aren't in aren't going to hurt anybody but they're also not pushing their ideas on anybody. 
So the ideas aren't spreading that fast. So the idea is that have an artificial focus on the spreading of ideas, and figure out how to emotionally manipulate people into believing the idea was heaven and hell and whatever right are going to spread more. So this is a key thing to get is, you know, whether we're taking, it's not just right, I'm giving the example of the teachings of Jesus turning into the crusades, or the Inquisition. But it's also take thinking like Darwin, right. So take the context in which Darwin came about. Darwin came about Just following malefics right, so, so we've got the British Empire's first kind of real world ruling Empire. First time that a global inventory of resources was ever conducted. Malthus came up with the fundamental principle of scarcity or inadequacy that says, hey, people are reproducing geometrically resources reproduce arithmetically there's not going to be enough for everybody, not everybody's going to make it. Well, then who's going to make it? Fuck? That idea says compassion is not viable. We can't all make it fundamentally, mathematically, there aren't the resources for now. This is jibberish. Actually, today, because we know that populations don't reproduce exponentially forever. They steady state and we've already seen the population in Japan and in Denmark and and other like the most economically successful countries start decreasing. Right. And we also know that we can recycle resources. We don't have to just have a linear materials economy where we use them up and turn in the trash. And that completely fundamentally changes the underlying scarcity based We can also share resources in different ways. So the underlying thinking behind Malthus isn't true. But he didn't know that at the time, it seemed quite compelling. So let me say, okay, so fuck solution for everyone a world that works for all is not even viable. Those who want it are simply not facing up to reality. And so it's not everyone's gonna make it who's going to and so then Darwin comes up in that context. And so the idea of survival of the fittest is the idea we focus on the most even though that's not an idea that he emphasized early in the writing hardly at all right. And so there was again, taking Darwin's idea in one context, and then also taking the most propagated version of it that led to social Darwinism that basically reified, institutional sociopathy. Right, which is, okay, well, if not everybody's going to make it. Some people are going to be like predators, other people are going to be like prey. 
Predators don't feel bad when prey die, you have to actually call the herd sometimes, like there. And if you start to think about how hierarchical power structures work to get to the top of a hierarchical power structure, like a big corporation or government or religion that structured that way. Let's leave that one off for a moment. Just say corporation or government. I have to win at a lot of win-lose games, I have to get the promotion over or win at the campaign over other people were zero, some somebody wins, somebody loses, right? So the top is going to be people who are best at winning at winning those games. So it's actually going to so if I have a lot of empathy, and I don't want actually care about other people's loss, I'm going to do less well, if I'm a sociopath and don't give a shit about it. I'm going to do better at that. If I'm willing to misinform to get ahead, I'll do better at so this is why we see higher percentage of sociopaths and psychopaths at CEOs and in the normal distribution of population, which also means that the people who have the most influence in the world Our asymmetrically empowered and asymmetrically sociopathic. But the way that we interpreted Darwin was the was reifying that as a reasonable thing, and even a good thing. So we have to recognize that any idea, even if it started as true or good or beautiful, gets put into the game theoretic mill, right, and what comes, what propagates is the thing that's propagated. So why do bad ideas catch on, like, largely for this reason. So oftentimes, the best ideas are not well marketed and aren't even easily marketable. And the best marketed ideas that are going to catch on the most are not that true and pretty shitty results. So this is again, something that people have to really pay attention to is I think, Jordan and one of his interviews with you talked about the difference between real thinking and simulated thinking. So if I'm just taking names that I've heard and in a conversation, and I'm listening for which of the things I'm going to say, that I have heard somewhere else, and basically a meme propagator, it's not real thinking. Right, I'm not actually endeavoring to try to make sense of the world in a new way that I've never done before. 
Most people hear something here. I mean, that comes in. And because it's from Fox, they believe it or don't believe it, or because it's from CNN or whatever it is, they believe it or don't believe it. So they basically have some cluster of means. That creates like a memetic immune system that says which ideas to accept in which ones to reject and then once it's accepted them, propagate them. That's not thinking and there's no sovereignty in that. And groups that have asymmetric mean broadcast capacity are good at me. Making memes that are sticky customized to specific audiences and being able to split test uptake, right? And then being able to, you know, then you get into high tech things like Facebook, and it's like, okay, I can actually pay attention to what you click on and do profoundly deep analytics, I can pay attention to mouse hover, I can pay attention to all these types of analytics, and customize the information to everybody. Using the kind of AI that beats the best chess players in the world of chess, right, this is stuff that Tristan Harris talks about. And so the AI that beats Kasparov at chess easily. Nobody is as good at being strategic with themselves as Kasparov is at chess and we don't even know that we're engaged in that and yet, it's competing with us for our attention for the its purpose of maximize time on site. Now, it just happens to be that I'm going to scroll and bounce unless something catches my attention. Short things will catch my attention more because I'm in a hurry. So just orient mentation for small bit size makes everyone more fundamentalists with shittier attention spans. And then if the headline is more kind of sensational, it's going to attract attention more. So then we get these big platforms that don't want to make people fundamentalist or drive politics. But they do simply as a byproduct of the fact that limbic hijacks are sticky, and they're optimizing for time on site. So first thing is that individual memes don't get selected for me. memes interrelate with other memes to create worldviews. Because I usually can't make a choice based on a meeting to make a choice based on a representation of the world. Just going to be a bunch of ideas, right, a bunch of meetings, a bunch of data. 
And so we get these kind of meme complexes. And so we can think about the evolution of meme complexes. So let's go ahead and look at like the evolution religious ideas. We can look at the evolution of political ideas or anything scientific ideas. So religious ideas. So you'll have some kind of Central mean. But then you'll also have protector memes that emerge with it, that also believing them protects against the kind of cognitive processes that could have someone stopped believing the primary mean, because if the primary doesn't have protective means it won't last. So the question isn't just what makes a mean propagate, but also what makes it indoor and resist change. So there's the evolution of memes, but also there, the main complex is resilience and the presence of other competing meme complexes, right. So we'll get these particular memes and then we'll also get propagator names that are trying to take the whole complex and propagate it to this. There's a whole football team of defense and All fence and carrying the ball, right like that happens. So let's say we look at some kind of fundamentalist religion. So let's say we we look at Christianity, this would be the same for any religion, this just probably the one that most people here will relate to. So you'll have some kind of Central doctrinal teachings about Christ and God and what good is and those types of things. But then protector memes are what could make me not believe these things? And how do we protect against those processes? 
So if we want to have say, a literal interpretation, then we don't want people to doubt the literal interpretation then we start to have things means like, faith is something God likes and doubt, which is another term for critical thinking is something that God doesn't like it actually comes from the devil and you'll burn in hell for it. And so the more that you just believe in the teaching, the better your chances of heaven on, and the more good you are. And the more that you doubt it, the more that Satan actually got to you. Right? So that's a very strong protector meme against the kind of critical thinking that could make you question the basis of the religion. You'll also have other protective means, like, if I believe this, if I continue to believe this, I get to keep having a family and a community that will take care of me if I'm poor, and if I'm sick, and you know, will help me out in times of warfare and all those things. And if I stop, everybody will disown me or to various degrees that like, there will be direct implications to my life regarding the change in these beliefs. And then again, you'll have propagator means we need to go on mission and share the good word with other people and convert them. So you start to see a medic ecosystem. So now, if I've got propagator names coming up against some, some people who also have protector means from a previous complex, then there's an evolution there's a competition, of which means are more successful. So then we look at the kind of evolution of the types of mean complexes over time. Now there are other people have a lot more expertise in this than I do. And I don't have adequately detailed history to say this is a re historical narrative. It's an example of the type of thing that could happen, right? So take it as that. So, say you look at the evolution of the concept of hell, right? Hell does it mean in western traditions. So first, say you take Eastern traditions like Hinduism or Buddhism, they might have many different hell realms and nobody stays in any of them forever, right? Like most of the interpretations have, everybody gets to Moksha or liberation. Eventually, these are places that people go to learn things. As part of the liberation path, so and if you look at the descriptions of hell at various points in Christianity, hell got nastier as time went on. And God also got more authoritarian. And heaven got better. 
And even if we go before that we look in early cultures and we see most early cultures were animistic. Right, the spirit of the Buffalo and of the tree and of the river and there is the spirit of everything. And so spirit was radically decentralized. And then there was an evolution because of evolutionary pressures on memes that corresponded with little tribes living in nature, to early civilizations, there is an evolution to polytheism which is now not the spirit of everything, but some smaller number of more powerful spirit or gods right. So there starts to be a consolidation of power in the religion corresponding to a consolidation. actual power in the social structures that are happening and the way that we make sense of the world in the way that the religious idea actually supports the thing that we're doing in the politics and like that, right? And then we end up going from polytheism to monotheism. And if you think about control systems, right, some few being able to control a mini in ways that are better for the few than they are for the many and how you have systems of kind of institutional control or oppression. So if we're having consolidation, for having increasing power inequality in our social systems, and we want to justify that increasing power inequality having and we want to justify increasing authoritarian power, having gods that reflect that is valuable, those means are going to actually be adaptive to the social systems doing that right. And if you think About an authority that controls a population with reward and punishment. And then we make, we actually make a God in our image. And we say, Okay, well what would the infinite authority be? And what would infinite reward and infinite punishment and you just take all the concepts to their logical zenus? That's what Christianity did right? So you have one, all powerful God beyond reproach with an infinite punishment, and then infinite eternal punishment, infinite reward. If you're trying to look for maximum behavior mod, that's what you end up coming to. But it's almost like the strange attractor of a landscape that just takes it to Zenith right? Where it's so terrifying once you've been indoctrinated. 
Leave that belief system because it because Hell is so bad that any chance of it is so unacceptable, that all kind of do Pascal's Wager and just stay in it just because right now, of course by believing that I might be going to the Muslim health They're true, but that never got it took Sunday when I was young, so I'm not as afraid of it unless I grew up there, in which case it has the hooks I'm much more afraid of that than I am of the Christian. So we can see that you get an evolution of the gods getting more powerful and more authoritarian, and more propagating, and more ideology around propagation and reward and punishment. Like those things that you would expect that that and it specifically it's that the groups that instantiated those means would have actually done better in a natural selection determined in warfare then and and also if I have a man's dominion over Earth ideology that says yes, destroying the environment for us, and it's okay if we destroy the environment because God's going to come back and make everything you know after purgatory anyways, and, and treating animals badly, really does matter because again, dominion over, like those ideas are actually going to be adaptive in terms of increasing the game of power. Even though  if you take to Zenith that game itself terminates, it destroys the whole world and the substrate that we depend on. So, you want to think about, and we can see that there, there's like, so we're looking at a kind of Christian worldview, right? But you can see that a whole worldview of ideas comes up around supporting Trump, or climate change or critical thinking and Dawkins kind of scientific materialism or each of those worldviews have processes of doing an in group out group pressures, right, like you'll be something bad will happen if you don't believe these things. going to hell was the worst example. But simply being rejected by the group and being called like a stupid conspiracy theorist or a pseudo scientist or an anti vaxxer or whatever it is that you know infidel, that goes against whatever the in group idea is, there's a strong selective pressure to defect on our own thinking to the center of the group. And a lot of advantage will occur if I defect on my own sense making to the center of the group. And it's not, I don't trust my own sense making so I'd rather be part of an in group or at least I'll be safe by being part of an in group. And I can't actually because I can't make sense of the world and I can't take care of myself really in the present. And it's not safe to disagree with everybody. Right? 
If I share views, it just have me disagree with everybody and I don't have any in group than I see in fact, so what I do is I look at which in group seems to be closest to what I think and then I defect on my thinking to normalize with the in group, right. So we want to just kind of pay attention to you know, looking at these different information, ecosystems memetic ecosystems, to seeing how they evolve into how they apply in group out group types of selective pressures and how they apply appeal other than good epistemology, right like how they apply rhetorical skills and emotional manipulation skills to compel people to believe something where the basis to believe it should actually be some better epistemic process. Then the key thing is if we can start noticing this in ourself and noticing where we feel a kind of bias towards or away from something before we thought about it well, based on how it fits with the rest of our memetic complex that we also haven't analyzed well. I guess a lot of people, a lot of people might be tempted just to give up on trying to make sense of the world. Think I must say Has, again that's like, is Fukushima still in risk of further breakdown or not? Has it already polluted the ocean? Should we not be eating fish from the Pacific or not? Is 5g actually possibly a problem or not? is climate change and coral reef die often eminent issue in the next five years or not? And if so, what is the right way to approach it? Are we approaching our own Doom with crisper with AI? Like these are seriously important things to have some clarity on. Right? These are things that we actually want to come to enough certainty on to make choices because we are making choices. And by not making choices, we're making choices by default in terms of the face of what market pressures are, are doing. And almost everyone, if they really kind of think about it will admit I actually don't know the answer to any of those things. But that doesn't slow down. The rate of first to market for powerful AI or You know what, anything else right? And to the degree that people don't admit that they have no idea and they think they have an idea, if they're honest, most of them will say, I'm pretty sure I have an idea because I proxied my sense making the other people that I trusted. But I didn't actually do the foundational research and to the degree that people did the foundational research, if they're honest enough, they'll say, the total amount of data that I looked at relative to the complexity of the scenario was orders of magnitude too small. 
So most people have given up on sense making about base reality. They just haven't admitted that. We were I didn't get ahead in a human ecosystem, by affecting what other people believe independent of what is true, independent of base reality then we live in a simulated reality where If I can, if I can get you to believe something that will lead you to vote in my interest or to purchase things in my interest or whatever, Game Theory will have me try to optimize distortion and optimize my ability to get ahead at creating and winning at simulations, and it won't have me try to connect the base reality at all right until we, we get a world that is so constructed and decoupled from base reality that most of the time what is true isn't even relevant. And it's even further than that. It's that there's a whole class of people for whom that idea that there are true concepts doesn't even appeal to them very much. Now, some people might think that sounds like excessively cynical or, but Okay, I'm gonna be careful with this because I don't want to Say, names that will create conflict unnecessarily. But I was talking to someone the other day, who was saying that what I believe is kind of give or take the same as what this other person believes. And what we believe on this topic couldn't be more diametrically opposite. And the person who was saying, you know, we all kind of are on the same page, we all believe the same thing. wanted to put on an event where we would all be there that she would have lots of tickets for and and her orientation is what is actually going to optimize viewership. And so how do we get people that are going to be engaging mixed with people who are famous enough whatever to optimize viewership, and I was focused on what is actually true, do we are, are we being earnest and what we're endeavoring to do here and her son That we believe kind of the same thing because like we both talked about technology, and we both talked about the future, and we both kind of want stuff to be good. And we both use the word exponential sometimes. 
It wasn't that she actually thinks that what I think is true or what this other person thinks is true. She doesn't. It's the idea of true beliefs is not what she's optimizing for. What she's optimizing for is what's going to get the most views. And then there's a backfill, a rational backfill, that set that tries to rationalize that it's, we believe, kind of the same thing or whatever. But the orientation isn't even trying to say do I believe what this person saying it saying do I believe that I can make money on what this person is saying? So you realize that We live so much in a simulated reality. Like, if I'm a venture capitalist, I can make money on a product that is shittier than products that currently exist. Even though the market is supposed to be a sense making mechanism, within the context of demand that there will be mutation, right, lots of different versions of the same product for the same service. And the one that's actually the best at the best price is the one that the market will select for, and it'll be up regulated. That's kind of to the first part, which mutation then survival selection, and then good parts of a few different ones might combine. And that's kind of mate selection, right? That's kind of how we think of markets as a sense making system minded evolutionary theory. But we all know that the best marketed product will oftentimes beat the actual best product, where the price of product development drops, the price of marketing and customer acquisition goes up, which means that it's a shittier product better marketed that means the sense making system system is broken, right? It's not a good syncing system. So there's a venture capitalist, I can invest in a company that I know is going to create a massive distortion bubble in the market really successfully. And maybe the company will go bankrupt at some later point, but I will have exited by then. So I don't really care long term, I care that it's going to market successfully and be successful financially, not if it's actually a better product or service. And so if the if the CEO is a really compelling sociopath that is highly motivated and spins distortion bubbles, I'm going to be more motivated by that then thinking that the product is actually fundamentally novelty better in many cases, right? This not only story but this a story. 
And so then, my goal is to actually invest in someone else's ability to generate a distortion bubble that will pull enough people along that me as an early investor, it'll lead to adoption of customers and other investors. And then I exit before the distortion bubble pops, right? And so we can see like there are whole domains that are fairly decoupled from reality from base reality where spinning simulated realities is the whole goal. So a lot of people, there's another thing we have to pay attention to is that the cognitive complexity of a lot of the issues we face is just much faster than most people have time for it most people have training for and even faster than we evolved to process. So this idea of hyper object, right, that there's not just plutonium, but all of the plutonium or all of climate change, or all of species extinction, or whatever, I can't actually observe that directly, but I can infer it know that it's a real thing. But how do I hold the cognitive complexity of any of those, let alone all of them Right is it is a very tricky thing and but I still have to feed my kids and pay the bills tomorrow. And so the adaptive pressures on me are to focus on what I need to focus on in the very small. And in the short term. Even though what I'm doing because of globalized supply chains, is affecting the global in the long term. The idea is think globally, act locally, most of us are doing the opposite, right? We're actually thinking very locally, but having actions that affect the world globally, which means we're we're thinking on very short timescales, fairly narcissistic, self indulgent, you know, timescales, but with things that will have enduring and massive impact. And that is a decoupling of scale. 
It's a decoupling of sense making a choice making a bunch of things. But so for most people, the idea of having the luxury of trying to make sense of the world is something they don't even feel like they have because their nose down, just trying to like do the next couple things they have to do. And then Another people who are actually trying to get ahead, or optimizing for simulations and distortion bubbles rather than trying to make sense of the world. So there's a lot of people who aren't actually even trying to make sense of the world. Now, when I asked what is meaningful, what is meaningful is going to be bound to what I think is real. And if I give up on knowing what is real, there's a way in which I'm giving up on the depth of my connectedness to what's meaningful. So yes, giving up on sense making, there's a is kind of an expression of a type of nihilism and, and it feeds into further nihilism. First thing is I stopped trying to squish reality into a perspective. This is super important. And then anytime I have a perspective and I am defaulting into thinking of it, as the Truth, I become dubious of that in myself. And they become curious about the partial truth and other people's perspectives, including the ones that I think are stupid and crazy, right? Because they none of them have no signal. 
Even if I think there's a lot of noise, so I want to say why do they think it is true? Well, this bias, that bias, okay, all that and some perception mixed with the bias, what is the what are they perceiving that then with the bias is also there? Maybe it's not that much sense making but it's something that's meaningful, right. So, this is St. Francis's quote of seek more to understand them to be understood. Right, seek first understand that means actually seek to take different perspectives. So the Hague alien dialectic is you've got a thesis, and then the anti thesis I actually want to try and take this perspective and construct this case. And once I've constructed both of these now I'm stuck with either that I Flip Flop between them. Or I'm just confused or I just claimed paradox. Or the next step is thesis, antithesis, synthesis, there's a higher order truth, it is actually not paradoxical. That reconciles. And it just requires a higher order of complexity. It's paradoxical within to lower level of complexity. Einstein's you can't solve a problem at the level of problem at the level of complexity. And so, since two houses two is three dimensional, no two dimensional picture will actually give me a solid sense on it. If I'm looking at this cylinder, we talked about this the other night. If I'm trying to collapse the cylinder by a dimension and take this cylinder which a three dimensional object and take a 2d slice of it, if I got a cylinder like this, a slice like this as a circle, a slice like this is a rectangle into the circle and rectangle are mutually exclusive descriptions of the shape. One has straight lines and corners, the other has no straight line to no corners. If I tried to say well, it's been Both, that just makes no sense at all right? 
If I say, well, it must be part of both. So it's a rounded rectangle, well, that has no truth at all. But I have to actually be able to construct a higher dimensional space in which rectangles and circles fit together in a way that is makes perfect sense cold it cylinder. But this is what a level of consciousness that isn't the level that caused the problem. The problem is partiality of perspective, that can create than a basis for conflict, right? So then there is a higher order that is able to reconcile those. And so seeking that, and this is where, you know, we're seeking clarity, more than simplicity, because the simplicity can happen through reduction. Right. And typically, the synthesis comes from novel insight that neither the thesis or the anti thesis held, it's not just Well, it's a little bit of both So a couple of examples. Let's say we take kind of political left and political right ideology, there's a gazillion examples and what we call the political left and right today might seem actually quite different than what it was in the past. So let's take a kind of what had previous to recently been kind of some essential ideas and Republican or Democrat platform. So we kind of have this republican right oriented idea of wanting to empower the self responsibility and sovereignty of the individual and more individualistic, and so smaller government, less social services, more empowering of those who are entrepreneurial and pull themselves up by their bootstraps, and you know, that kind of thing. And then you have the kind of more democratic left perspective that says, well, and here it's saying the collective is actually created by the individual. So we want to empower the individuals that are creative and take a Because better individuals make a better whole, that's kind of the gist. Over here, it's like, well, but the individuals are being conditioned by the environment that they're born into by the whole. And so even though I can find that one story of that one guy who pulled themselves up by the bootstraps in the ghetto, there's a whole lot more people that succeeded who were born into the Hamptons and born into South Central. 
And so let's create better environments that actually conditioned better people because there's top down effects the holes create affecting the individuals. So there's, there's for many people, some seemingly compelling truth in both of these. And also problems, right, so there can be a right oriented perspective that says, hey, look, if we set up social services and welfare and whatever we actually condition, shitty or people who are less strong and resilient in the face of the environment, we d incentivize those who are most entrepreneurial and creative like what And we make people who are doing badly still good well, and that actually kind of down regulates evolutionary pressure in the whole system. Like, why would we want to do that? And of course, over here, we can have a kind of left perspective that says, Yeah, but some people are getting ahead using shared services that the government pays for from everybody's tax money that they aren't actually really accounting for, and they're affecting the commons negatively in a way that is externalizing. The cost everyone else so that they're being claimed to be more entrepreneurial just means they're extracting from the commons and externalize and cost to the commons better. And do we? Do we really want to let people die on the footsteps of hospitals because they don't have money or insurance, you know, in the fully individualistic libertarian kind of idea and fully libertarian kind of ideology can't solve multipolar traps. And so, like, but there's there's clearly truth in both of these and they are Clearly neither complex enough to actually handle reality in which there are bottom up effects are the individuals affect the whole and there's also a top down effects for the holes in turn affect the individual and there's feedback and feed forward loops and neither of them are factoring those enough. But the debate process doesn't bring about dialectic. Right? 
The debate processes here actually make the idea of more polarized to get people on this side, emphasize rhetoric over real sense making and emphasize winning over collectively trying to make sense together. So the debate process is not a good sense making process. It's a narrative warfare process. dialectic is different. It says okay, I think we have some truth and not all of it. I think you have some let's endeavor together earnestly to figure out the things that we're all interested in figuring out. And then we start to say, Okay, well, do we want that? Do we want better individuals who are more sovereign independent of environment? Nobody doesn't want it or do we want holes that support all the individuals within them to do better well the way we want them to. But the way that we've done social services makes, oftentimes some of them makes the people not more sovereign, but more dependent. So it's actually not making better people. It's make them more comfortable, but shittier people, right, and the way that we incent individuals over here, in sense people who are entrepreneuring, but by externalizing costs to the commons and creating radical wealth inequality, so it's not incentivizing the most truly creative and intelligent and good people. It's incentivizing effective sociopathy and things like that. So like, neither of these are doing all that good at the thing they're even claiming to do. So how do we create social services? collective processes that condition healthier people who are more sovereign? How do we create environments that condition people who do better in any environment, right, that actually conditions strength and resilience and sovereignty in the individuals who then in turn affect the environments in ways that support the increased sovereignty of ever Else, that's a totally higher order way of starting to think about the relationship between them. 
That starts to recognize the inexorable, failing of both of those perspectives. And and that what the approach would take is more complex, right? That's an example of struggling to move towards synthesis from a thesis and an anti thesis, right? And if you if you look at even personal things in your life you're wrestling with like, Okay, do I want to accept and love reality and people in myself as I am or do I want to, like help strive to make things better. There, there's similar like those types of things, you'll find the thesis and the thesis everywhere, where the actual insight to synthesis is novel insight not contained in either of those, if I when I say except you as you are right now, or help work to change it to make you better and I see those as as Different, it's because I'm seeing you as a noun. And I'm seeing you as a fixed thing or accept you as you are, you are this current state. Whereas if I see you as a process, I see you as a verb I see you as a becoming that is different than you were yesterday and different than you were when you were two, right? Then accepting you as you are and includes dynamism includes the impulse to change, grow and evolve. So I can accept you fully as you are, which and love you as you are, which includes accepting and loving the impulse to grow and expand and clewd and transcend. So I can support you to become more not on the basis of judging you as insufficient, but loving you completely, including loving the evolutionary trajectory inside of you, right? But that inside of you as a verb, rather than as a noun was actually not captured in either of these. 
So the dialectic process of saying like, Okay, well, how do I see the partial truth here, construct this fully? And then how do I see the partial truth? Here, construct this fully and then what new incites, bring these together in a higher order perspective that is more complex and more nuanced than either of them. So that's kind of a dialectic process. And it might not just be two thesis anti theist might be lots of perspectives. This is a tool I would this is a process that would love to see people start practicing at four cents making of whenever they're talking with someone start by seeking to understand before seeking to be understood, and seek for the truth value and what people are saying not just the wrongness, but then don't holistically throw out what they're saying is totally wrong or totally true, be able to separate that their signal and noise. And then be able to say if I see signal from a number of sources, how does that fit together and the higher order perspective this this is another sense making process. You mentioned emotional vulnerability as key components of sense making You that may seem a little bit counterintuitive to people, can you explain what you mean by that? If I want to make sense of the world well, and I'm going to engage in some communication processes with other people to make sense of the world, some collective sense making, then I want them to share true information with me to not descend form nor withhold. So how do I create the trust and psychological safety for them to do that? I'm probably gonna have to do that too. And so how do we create mutual trust and psychological safety that we're not going to use the information that we're sharing with each other in game theoretic ways with each other? That's a huge part. And if people don't have some spaces and some relationships where they feel like they can actually share fully, openly, honestly and feel trust in that their sense making this great Going to be radically curtailed right to what they can just do on their own. And without anybody's ability to help error, correct them with full sharing. 
Also, one of the sources of bias is identifying with what I believe, because it because I'm identifying with part of an in group that believes that thing, or because I am special or smart or right or whatever, for believing in that thing. So the, the impulse to be right means that I won't seek to understand other perspectives. And so if I'm going to actually seek to understand the truth value and other perspectives like earnestly trying to get what they are seeing what, where they're coming from. I have to stop seeing it the way that I'm seeing it for a little while, and I also have to completely suspend debate and narrative warfare and the impulse to be right and all of that. And to there's a deeper human connection that's involved. There's also something there's a psychological process that almost seems like a spiritual process where, for me to really try and get where you're coming from on a topic. I have to really take your perspective. Well, what is it in me that is taking your perspective because not my perspective? Right? It is actually having to drop the way that I see things to really try and see it the way that you see things to make sense of it. So that means that it is some there's a capacity in me that can witness my perspective that can also witness your perspective. But it is deeper than the current perspective I have and we all know we can change our beliefs and there's still something that is us. So there is a US ness that is deeper than the belief system. To be able to really try to make sense of someone else. I actually have to move into that level of self That is deeper than belief systems. What do you hope that people will get from it? I would like if they start looking at their own biases and saying okay, where do I have emotional needs that are affecting what I believe Where do I have in group out group stuff happening? Where am I actually doing this information where, you know, like, what am I cognitive biases? What How do I even know? Well, let me go look up the list of cognitive biases and start to inventory then keeps talking about epistemology like and what the axioms are. I don't even know what the fuck that means. How do I actually go explore what the right steps of logical process and axiom or can I empower my own learning so if people felt inspired to learn how to learn better, and then inspired to create relationships with other people, where they actually do care about understanding what is true and real, so that they can also have a better relationship with what is meaningful and being able to make choices landed there. And were there endeavoring to understand what is true and real together and also endeavoring to create an intact information ecology where no one is dis informing anybody, which is as much or even more an emotional process as it is a cognitive one. Because to really create an impact information ecology involves vulnerability and intimacy. 
That's what happens getting out of a game theoretic context where I say oh are well beings are shared? Well, what if you defect on me, I have to actually create a situation and of trust, to be able to share real information. So then I get to see where my own wounds make it make me incapable of trusting or of or revealing. So I'd be I mean, those would be things that I would be happy of if people looked at the emotional and cognitive and overwhelmed by time and lazy and biased and whatever sources of where they aren't sense making well and endeavor. to work on those. And I'd be happy if, if maybe you guys with rebel wisdom took a lot of people who you interview who like maybe one thing they have in common is they're all people who are endeavoring to make sense well, and started to ask them more about sense making processes that they employ. So people can actually learn like Brett could talk about, here's how evolutionary theory, here's things that we know from evolutionary theory, here's how you can apply this as an epistemic tool. Or, Eric could talk about here are principles in the philosophy of science and in physics that are valuable tools and understanding reality, those types of things. And then, if they were even not that many people who started to really think about breakdowns and information ecology better and write on that more and those ideas were able to start to become better understood, and be happy about that. Hopefully look at the frame Work of sharing things that are truthful, true and representative. We start with the truthful side, we would need to remove the incentive for disinformation. And the first major source there is kind of market is the game theoretic dynamics that emerge from market type dynamics. 
And so again, if I have two different branches of the government competing for budget, or different representatives who are supposedly both seeking to be in benefit of the country competing for percentage of the budget, now they have the incentive to dis inform whoever's allocating the budget dis inform the public dis inform each other. Which means that the total level of coordination just sucks right and this happens, this is corporate politics inside of corporations. This happens everywhere. So, as long as we have separate balance sheets, right, as long as the different intelligence agencies are competing for that as long as as people we have separate balance sheets, then we have a fundamental basis that my well being is separable from and oftentimes directly rivalries with yours and with others and with the comments. So then we will compete with each other for a lot of things. And we will engage in, in at the worst case, physical warfare, kinetic warfare, but will mostly engage in economic warfare competing against each other and at the cost of the commons, and information and narrative warfare also at the cost of the information, Commons and each other. So to really get over that we would need to couple or we need to create alignment between agencies, right between what you have intention to do and what is also in my well being and vice versa, which means that we would need to have More coupling between our well beings which means we need to have a different process of resource provisioning. And I will say that the type of system that could do that adequately has never been proposed in any kind of major way. Because obviously, none of the systems ever proposed so far or tried do that. But if we have a rival risk relationship with each other information will be part of that rivalry and will damage the information ecology in the same way we damage the physical environment or where each other kinetically just a big ask, right. 
So, our balance sheets are kind of at the foundation of what create rivalrous dynamics and this is at the level of cooperation to the level of individuals were at ground level families at the level of nations. So Can we still have private nation states that could benefit each other at the expense of others? Or Commons that share information perfectly? So, like if we really want to say how do we have a perfectly intact global information ecology, it couldn't happen within the context of nation states and private balance sheets and political left's and rights and in group out group type structures. It would take us a while to talk about what something post game theoretic might look like. But if you want to just start to Intuit it, you say, Well, if we look at all of the neurons in your brain, or all of the cells in your body, they're all their own agents, right? 
Like the cell self organizes, and I can take it out of you and put it into a traditional keep self organizing, for period, controlled by its own internal genetic code, but even your body something like 70 trillion individual cells, those cells are organized in a way that's best for them as individuals and best for the ones around them invest for the whole simultaneously then either sacrificing themselves for the whole, nor are they sacrificing others for a game theoretic benefit the and this is true at the level of cell the cell interaction, but it's also a trickle of organ to organ interaction organ system to organ system or cell to organ right like at fractally. And all these levels, vertical and horizontal there is a kind of symbiotic process that happens. And if you tried to model like the organs in a capitalist relationship with each other where they were trying to the heart and the lungs were competing against each other for scarce resource to hoard as much resource for future as possible. And you model that out and happening at the cellular level buddy dies very quickly. Cancer cells are actually doing that, right. a cancer cell is doing what is good for it in the near term, but bad for the whole and it will end up killing the whole and killing itself in the process. And that the cancer cell only happened because the body As a whole had some Miss health that had carcinogenesis exceed the immune response capacity to deal with the carcinogenesis. 
So the whole was already sick to make the individual sick to some degree, right, there's a feedback and feed forward process between the parts on the whole. If you think about, like, vision, and the way that parallax error correction and parallax occurs in vision, one eye doesn't give me peripheral vision, and it doesn't give me depth perception. Two eyes together, give me something that and also the single I will have errors that aren't corrected for the two eyes together. The overlap of what they both see but also the difference of what one sees in the other one doesn't allows any error and this side to be corrected for error in the sky. And it allows peripheral vision in depth perception. So this is a place where not only are the eyes, not in competition for which one One is seen as true. But the process of how they're related in the optical cortex gives me error correction on the, on the imperfections in each of them. And it gives me new synergistic information that neither of them had on their own. That's fucking amazing to think about, right? And this is true, like, your brain is a whole processes information that no individual of types, no individual neuron or sub neural networks are processing. And individual neurons can get something wrong, but there's error correcting processes that don't propagate that but but the processes do propagate the true information. So we're like, Why the fuck does it work that we get that the information processing that each of the parts are doing goes through a communication protocol, that error corrects the false parts, and also gives parallax on the true part where we get not only the truth of all the parts, but a way of binding that together for synergistically higher order information. The cells are sense making. And they're communicating, they're signaling with each other, right? A hormone is a communication, a neurotransmitter, like those are all signaling processes, but they don't have a game theoretic relationship with each other. Right? They actually have a mutually symbiotic relationship with each other. 
So they are supporting each other sense making in that way, they're the lungs obviously do better if the hearts doing better, as opposed to doing worse at at the hearts doing better. So if we just start to kind of imagine into what type of communication processes protocols would have to happen between humans, that allowed for error correction on any individuals perceptions, but allowed the true parts of everyone's perceptions to be separated from the error parts, and then all the true parts to be synthesize at a higher order of complexity than individuals could do on their own. When we think about the civilization of the future and the collective intelligence of the future, we think about it that way. Rebel Wisdom is a new sense making platform, bringing together the most rebellious and inspiring thinkers from around the world. If you're enjoying our content, then you can help us make more by becoming a subscriber, which will give you access to a load of exclusive films. Also, you can then join our group zoom calls to discuss the ideas and the films. And you can send us ideas for questions for upcoming interviews. We're also looking for talented people to help us out with editing graphics and music, that kind of thing. And if you're a regular viewer, you'll know we talk a lot about the value of embodying or actually living out the ideas we talk about. That's why we run regular events in London. Check out the links on the website for more and hope to see you soon. 

