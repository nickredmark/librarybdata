The regulatory capacity of complex systems. complex systems have a bunch of different regulatory dynamics that interact with each other in ways that we only understand that a little bit. And so, and different kinds of complex systems have different kinds of regulatory dynamics. And we have to get clear which ones are going to be the right models for economics for civilization as a whole, for governance for infrastructure.
So specifically, we have complex adaptive systems that don't have clear boundaries and don't have any centralized ability and information. So forest is an example. Right, or any kind of ecosystem is an example where that whole thing can't behave as one economists unit in any kind of real time capacity, there might be coordination and things like mycelial networks that will share resources, but this is a very slow kind of response curve. And so there are dynamics of how that is a complex adaptive system. But that doesn't actually have singular agency.
Right. And that's defined by a lack of membrane, lack of self organizing membrane that separates the complex system from everything else that allows agency what's on the inside of the membrane in relationship to the environment outside.
We see then, you know, the earliest membranes are prokaryotes, and they have the capacity to navigate with agency and relationship to the environment. Then as we start to get into eukaryotes and slime molds, we get into something we have multiple steps of boundaries. These are you can think of these as Super organisms can prized of simple organisms. And so here you have to get the agency of different things to participate with a high coherence, which is already happening in the forest, but participate with a different kind of high coherence where they don't have competitive dynamics with each other. They have coherent dynamics with each other and maybe competitive dynamics outside of that boundary. And then you get a new boundary outside of it right which is the biofilm around the slime mold and that whole thing starts to operate as a unified organism. Even though it's a super organism of micro, smaller organisms, that's a totally different kind of behavior than just the individual organism because the individual organism doesn't have to take agents and create coherence between them. Right, whereas the super organism that like a forest that is not yet a secondary organism doesn't also have to create certain kinds of coherence, it just has to create homeostasis, predation cycles of balance, but then the next one where you get, you know, a slime mold boundary, or you carry out that is made of kind of pro periodic like dynamics. 
Now you have to get separate agents to cohere and then become a new meta agent, right? Then, that starts to evolve in eukaryotic systems to greater complexity. And as soon as we add a neural net, we start to get a different kind of way of centralizing information across this kind of complex that allows a lot more adaptive capacity than the slime mold has the slime mold is going to do chemical signaling which is going to go very slowly. And the you know, something that has a neural net is going to be able to actually coordinate danger of lots of organisms from a top down fashion. So, you can actually start to have a boundary. Anytime you have a boundary, you start to get some top down coordination, but then you have phases of what kinds of top down so, then you go from distributed neural net to central nervous system and higher kinds of central nervous system. And so, top down organization is actually an emergent property of certain kinds of bottom up organization, right, you get bottom up organization of separate cells coming together to make up a human right hundred trillion the autonomous agents that function more coherently together and adapt differently to be together than separately. And each cell is regulating its own function genetically internally in a bottom up fashion. 
But then the top down neuroendocrine control of massive groups of cells where the top down system is sensing the entire system, and then can do coordination of the whole system. But sitting on top of bottom up dynamics, which is if the cells weren't still doing their own thing, genetically, the top down system wouldn't work at all. But if the top down system is not working well, like persons in a coma, and the higher the highest functions are turned off, and only autonomic is on the bottom up is working just as well, but it doesn't have the same capacities at all right? You have emergent capacities that relate to boundary and top down capability. Which of these are models for what civilization will be, right? Is it going to be individual humans that are just like a forest that don't have any kind of boundary around it? And we just get balance through getting the right kind of prediction cycles? equilibriums is it humans as a slime mold that are working together but without central top down control that a nervous system give? Or is it what kind of level of nervous system that has centralized capacity, and then at the level of human nervous system, forecasting ability, right? 
Rather than abstraction, giving forecasting ability? So super deep question because also our human consciousness and human sense of self is the emergent property of the coordination of all of these things working together. But if all those things are working together, but without certain kinds of synergistic dynamics, you don't think human consciousness it a person in a coma, you don't have the same thing. So, is humanity going to become a super organism that actually has its own agency? Right, and we're building that kind of nervous system of humanity? Or is humanity a boundary list non agent, but we're at least getting the kind of coherence between agents that keeps it from self destructing.
Those are, those are fundamentally different kinds of complex adaptive systems. They're different relationships of their different methodology, right, you have a different relationship between the parts and the other parts and the parts in the hole and then, totally different forecast of what kind of capacities are going to come about. So if we simply do the, you know, the libertarian models totally bottom up, right? How do we get people to be individually Good choice makers and good at making deals with each other that are effective, and no top down structure.
All of the anarchie models basically are those kinds of models.
But as soon as we have complex decisions to make complex choices to make that involve lots of us and data capacities that individual humans can't do, which we have lots of that if we don't address we go extinct and the questions that has to sit on top of the good libertarian like framework of individual people making good choices, so that's necessary, but it's not sufficient, right? There are things that will have to be decided on by large groups of people and participated in faster than would happen to bottom up only dynamics. So now this is the next topic which is our business to affect things and our ability to make good decisions regarding how we affect things have to be paired. Otherwise, if we can affect things, but we're not making good choices regarding how we affect things. And the externalities that start compiling become problematic, as our ability to affect things is on an exponential curve right now, if our choice making capacity is not similarly on an exponential curve, that is a fundamentally self terminating scenario. So exponential tech, this was the third center you brought up exponential tech gives individual agents and small groups of agents capacities that never happened before. So when you think about like, you think about Nash equilibriums and wanting to get us out of fucked up Nash equilibriums you don't need everybody to do the right thing because individual agents all have quasi equal power and the worst thing and to get it to be really fucked up. Everybody has a certain critical mass that people have to do the wrong thing.
In a dynamic where you have exponential tech that has passed powerful enough to be catastrophic, that can be decentralized. Everybody's choice Making matters. So how do we deal with that as a totally different thing, right. And so for humanity to make it through us, individually and in small groups scaling our actuator capacity of exponentially, our choice making capacity regarding what we do with it, actuator fasci, in our feedback loops on it, also have to scale up. Now, whenever we develop new technology in the past, we did heaps of destructive applications, but the technology wasn't so bad that it destroyed everything. We burned a lot of shit down with fire before we kind of learned how to manage fire to be more positive than negative. But you can't do that with nukes. Right? And you can't do it with CRISPR because it's not the impact potential is radically more than it was with fire.
And so how do we take our new emerging technologies and do something with them that is radically different than we've ever done with any technologies in the past. Which is adequate anticipatory process so that we don't learn from trial and error and things that are too powerful to learn from trial and error as a totally different set of scenarios that we have to address. So then we get into the issue of incentive. One of the things is that we have to, you can't avoid a problem while you incentivize them, you also can't solve a problem while you're continuing to incentivize it at scale. One of the problems with exponential tech and why we are not doing a good enough job of thinking through the problems of exponential tech slowly, is because there's a lot of fiscal incentive to get there first. And there's not that much fiscal incentive to really think through the issues, you know, in a long, slow, thoughtful way. And so funny, we're actually externalizing extinction, we are taking away thinking about it, we are increasing the probability of extinction for the probability of winning in the in the near term profit game that will be obsolete in the process. But each of those increasing the probability of extinction compound on all the other ones, till the probability reaches one. Right. And it's it, the current trajectory is an extremely reaching 100% probability of extinction.
And so you have to change the whole fucking thing. So you can't have an economic system that incentivizes speed on things that have to go slowly. Right. That's just, I can't underscore that one enough. But then that also brings up the issue of incentive in general with complex systems is, how do you get a bunch of individual cells or algae or whatever to work together to a super organism rather than compete with each other? Well, you have to change the behavioral dynamics from competitive to cooperative. You have to change all the things that affect behavioral dynamics. So incentive is one of the major categories of patronymic as long as we have any systems of incentive, and then we'll go with Larger passing sense. So kind of diving into systems of incentive more if as there are more humans than there have ever been right exponentially more, and the impact per capita capacity of the humans is also been on an exponential curve and it's an exponential curve point that is reaching escape velocity.
You know, we can kind of, metaphorically say we are achieving the power of God's over the next little while, without the wisdom, discernment care of God's that is a inexorably self extincted scenario. So how do we deal with that? You kind of can't put the technological curve cats back in the bag. That's an impossible thing to do. outside of just fail scenarios on what we call civilization right now. So you have to come up with adaptive capacities in factoring for that level of technology.
And so if you think about as we have that much capacity to affect stuff, and there's that many of us affecting stuff, that means the ability for humans to affect other humans, and the ability for humans to affect the ecosystem, and all of the cascade effects of both of those are radically increase. Now, the total, you know, humans affecting the ecosystem is right near breaking points of the biosphere, losing key life support capacity. And even before it loses life support capacity overarching like it, there's no viable places to live, you start losing certain Bible places to live as soon as you start losing certain Bible places. So climate change, causing severe droughts where farmers have to move out of those areas into cities, which is what happened in Syria, low land areas, flooding, etc. Then you start to deal with massive migrations, refugee issues, and then resource wars and then fragile grids collapsing. 
And so we're not looking at ecosystem scenarios just in terms of the ecosystem by itself, but ecosystem scenarios and culture issues, war issues, resource issues, graduate grid issues, any of those, they're all interconnected enough. And there's enough fragility across those systems, that failure in any of those systems can lead to catastrophic cascades currently. So as we have that level of capacity to affect things, the coherence of everyone affecting things in neutral positive ways is critical. Right? It is existentially necessary. So how do we get that much coherence? Well, we have to get coherence amongst the behavioral dynamics, Rachel, that people are behaving in ways that net benefit the balance sheet of the comments and and each other. So let's just talk about the Center for a moment.
Like we said, you cannot incentivize a problem and prevent that problem from happening simultaneously and just it's really important to get you cannot legislate against incentives successfully long term ever, if you make a piece of law that says it's illegal to do this, but it's still profitable to do this, the companies can always move headquarters to another country, and then pay taxes there, which actually makes a market for countries to make law that's more favorable to shitty things, right? Whatever that incentive is. And yet, so the sort of companies really are not under the full jurisdiction of countries and yet countries, the people who need election budgets and the people who need campaign budgets are under the jurisdiction of whoever can fund those things. And so economics as an incentive system, you can't you ultimately can't confer resource and advantage to certain kinds of behavior and prevent those behaviors through agreement fields that are still subject to the resources, you know, the pools of accrued resources. And so it's important to get that because any strategy that says we're going to solve climate change through primarily regulation, we're going to solve or whatever through regulation while the incentives are misaligned has never and will never lastingly work you can get temporary blips that's about it.
And so, you know what that looks like is if we want a world without war, we can't have any incentive for war. And we have to have incentive for collaboration, cooperation, etc. So where's their incentive for war? Let's start with the obvious you can't have the largest block of global economy be a military industrial complex that stops existing without war and have war stop existing and have it continue. Right. So its own continuous requires a reason for its existence. So any model of lasting peace and reconciliation that obsoletes militarized conflict has to obsolete a for profit military industrial complex or it has no chance of succeeding. So any strategies that aren't trying to do that have no chance of succeeding as a big deal because so far everything that has tried to do Peaceman conciliation hasn't been focused on that at all.
Which means that none of those things ever had any chance of succeeding. Now then we can also look at as long as you have separate balance sheets that have interest on ownership that encourages hoarding and competition in a zero sum finite game dynamic, then just resource ownership and purchase war, right? Because it ends up being for fighting over things and fighting always ends in a in a force dynamic at the end of the day. And so can you have freedom from war as long as we have zero sum game dynamics know. So, this is, you know, not only do you not get you have to get rid of a for profit military industrial complex, you have to get rid of zero sum games period, because as long as you have 07 games, were losing at the game ends up meaning can't support the people of your country adequately means losing adaptive competitive power means all that then it is a survival to not lose those games and which means military is going to come in, and that means that you're going to keep doing the zero sum, fucked up thing of arms races, right to continue to maintain the depth of power, which means you put all the resources into the exact wrong things, things that normally don't support, life support anything and don't make the scarce resources, better utilize, but make the scarce resources poorly utilized and increase our risk of extinction every bit of the way because if anyone does it, everybody has to do it. So to go deep with that, any system of differential advantage, right? finite games that are zero sum is, which means any private balance sheets that will always end up generating those meaning they're scarce resources, were competing for the scarce resources, and you possess them rather than have access to them and you possessing them means I don't have access, and the more that I possess, the more I do better at everything.
Level of Maslow's hierarchy that inexorably leads to dynamics that will continue to cascade into progressively worse. clusterfuck. So we've basically since private balance sheets, we've had wars over resources. It's just as we keep getting more and more people. And as the legislative ability, the judicial ability to try and stop bad acting from happening is less and less capable as economics as learn better and better strategies to deal with that. And our technological capacities are increasing, our population is increasing those strategies that always resulted in unremovable destruction of resources and or just lead to undeniable destruction of resources that in the biosphere is capacity to support life and more than in the placers capacity, support life and technology that's powerful enough that even accidentally ends the capacity to support life. 
So we've actually been on it on a trajectory towards this inexorably as long as we going on credit balance sheets, and then all of the additional dynamics that have kicked in limited liability, etc have been kind of inexorable evolutionary byproduct of differential advantage to begin with, which means we've been individual agents that had not yet cohered into a super organism. And basically, we're at the point now, where those, those organisms are fighting each other with a strong enough capacity to destroy the whole ecosystem in which they live. So that doesn't work for any of them. So they either have to unify in the super organism or die. That's kind of where we're at. And so then it's how do we unify super organism? Well, how do you get all of the agents to align their agency? So how do you make sure that the incentive of every agent is as close to perfectly align with the well being of every other agents and of the commons as possible, so that all the internality are externalized so that we are conferring advantage and resource to that which is on the positive we're not conferring advantage and resource to that which is externalizing home economics sits right at the intersection of worldview and infrastructure because worldview is what do we value? We value our people, our religion or nation or skin color, whatever more to, you know worldview is what do we value that is the basis of what we're working towards. infrastructure is how do we meet our physical needs and relationship with a physical planet build tools that have an advantage, right? Because we increase our adaptive capacity, unlike other animals, where they're just corporeal tools, give them adaptive capacity, we extend ourselves through our extracorporeal tools. And so infrastructure is the extensions of ourselves that lead to the adaptive capacity of the group that is developing those.
And so economics sits right at the intersection between value systems and our increased physical adaptive capacity because it's how we codify value systems in a value equation, what are we actually going to ascribe value and convert power to right?
If we're looking for differential advantage, and there's no real way to get differential advantage from air, there's enough of it, everybody can have access to it. So it's worth nothing. Because it's worth nothing. We have no economic incentive to not burn it up and pollute it. Right? If there's a resource that there's not that much of them, I want to own it because I get differential advantage even if that provides only symbolic advantage. So all the gold sits in safes. We don't actually do anything with the goal but because there's a scarce amount of it, or at least to believe scarce amount of it. We will ruin ecosystems and fight wars to get the gold to put it in safes that provide no utility value to anybody. So that you know, or the whale being worth real tangible money dead or willing bow but nothing alive. What does it mean that the commons has no balance sheet, you know, that is respected. That's a set of value systems, right differential advantage value systems that have been codified in a value equation, that then determine what technology and infrastructure is built and how its applied.
And so we have all of those our value systems, our infrastructure and tools and our social systems, economic governance, law, language. They're all inter affecting each other. But we can simply say suffer to move up, and they're all inter self stabilizing. So you actually can't have an omni considerate worldview. As long as you have infrastructure, we're meeting your needs requires hurting the rest of the world. Because in order to meet your needs through that system, you have to justify doing which we have to down regulate empathy. So new tools affect our world that perhaps inexorably right, they're all interacting. So we have to move our worldview or social systems and our infrastructure holistically the next self stabilizing complex up so what we're interested in is what are the necessary and sufficient activities transforms after happen in each of those areas, to lead to a new self stabilizing dynamic that is anti fragile in the presence of all the dynamics we're actually facing over the next period of time. So anti fragile to exponential technology. 
So you know, order to the move up to the next self stabilizing complex we can actually define the high level criteria of what has to transform in each of those categories and how they interact each other. And we can define all of them in terms of closing causal feedback loops that have been open. So in the area of infrastructure, part of why infrastructure has been why it is fundamentally not only unsustainable, but that means self terminating is because we have primarily a linear materials economy where we're taking stuff out of the earth faster than it can renew, and then turning into trash, trash back in our faster than it can be naturally biodegradable. So that means we are converting a living ecosystem into dead zones and trash at a rate that requires exponential year over year growth of the total linear materials economy, right because the capital has to expand year over year and that sits on top of the materials economy to not debase the currency 50 Increased goods and services etc.
So we have to close that loop where the stuff that was trash becomes the basis to make new stuff. And we have continuous closed loop cycling, that is post growth, meaning it doesn't require growth doesn't mean it can't ever grow. But if we have a system that is actually stable without more net atoms coming into the materials economy, now we're going to be getting more photons all the time, and we're going to be getting input of energy. So it's not a closed system, but it's let's say it's close to atoms, or it's at least doesn't require input of new atoms. Well, then you can continue to upcycled atoms, right, you can take the trash and turn back in a new stuff or the new stuff keeps up cycling into higher and higher forms because you keep having new energy and new pattern, right new information and design. We have to have a system that is closed loop, post growth and upcycling as far as the materials economy goes.
If it's not those things, it is mathematically self terminating. By the way, we can we can connect that set of is back to just the basic framework of how commenting system self regulate in general. Yes, it is a generalized problem. Daniel's not talking about happens generalize often that applies in the zone of enter complexity.
So when we study complex adaptive systems and the things that we see in all the complex adaptive systems is that they are defined by closed causal feedback loops and then massive parallel processing. And so close causal feedback loops means every organism is defined by its capacity to sense the environment, right sense the environment and itself. So it's external and internal sensing, sense making information processing capacity of all that to then be able to actually have a sense of what's really going on from all those sensory channels and all the past information and etc. to then inform action and then act greater capacity to act on the world. And then the ability White's closed loop is that can sense the way that it acted on the world and then that work well or didn't work well now already left nor your right, you know. And so I can continue to up regulate its capacity with closed loops, one of the and if you think about sensory systems, motor systems and cortex for information kind of processing systems, right, and animals, when we think about it, those necessarily co evolved because there would be no evolutionary advantage and a lot of evolutionary disadvantage to send stuff that we couldn't act on. Right, just be freaked out about stuff. Or if we acted and couldn't, in turn sense, the effect that it happened, then we would have no way of knowing that action with adaptive right showed me We do a lot of non adaptive action. So those three co evolved and they define the organism, right? Well, what happened with humans, our capacity for abstraction, allowed us to see what we were doing and all those areas and build tools that extended those capacities independent of each other. So we started to as our tool group, break, open the feedback loop.
So we struggle with mostly actually are tools right we hammer would extend our fist and plow would extend our digging ability and extend that now to our fist is extended through the entire military industrial complex, right. And intercontinental ballistic missiles are extension of that capacity. And the entire industrial supply chain is an extension or capacity to go pick something or cut, you know, cut something down? Well, if I'm affecting things every time I purchase across all the continents through massive global supply chains, I can't sense what's happening at all to inform my decisions, right? That's a completely broken open causal feedback loop. In turn, I can send stuff to the internet and billions of pages of everything from, you know, from Hubble telescope to electron tunneling microscopes to everything in between. But there's more information than we can actually vet if it's true or not parse and synthesize together to actually know what's really going on anywhere. So our sensory input we can't actually make sense of, and then to the degree that we can make sense of things. 
We've also extended our capacity technologically with computation to make sense of stuff. But then if we really get climate change is real, we don't know how to act on it. Right. So basically, we have broken on been our information processing systems. And that is core to why we're not adaptive, right? It's core to why we are doing quarterly actions that are increasing our risk of extinction is because we don't factor what's happening well enough, put all the pieces together to inform decision making, you know, continue to cycle that. So we have to close the incentive loop. So that the incentive of some agents and the well being of other agents in the comments since they inevitably interact each other on a little biosphere where we all have increased capacity to affect each other. That's actually another key part to say is when our capacity to affect each other was not existential, the idea of winning a win lose game made sense, right? Let's make sure our military is better than theirs, and we can actually win this thing. When we both have nukes. Nobody can win.
Right. And the idea of being able to just beat them economically by we can cut down trees faster than they can and actually just build up more economic surplus when we weren't at risk of cutting down all trees right or overfishing the entire ocean that made sense. Win lose games at our level of power are all lose, lose lose games. So basically win lose is becoming obsolete game theoretic model. Now we either have Win Win or we have lose losing, we have no space in between. That's a big deal to get that right. And it's not that they weren't true before. They were true at a certain level of power. They're not true anymore. And so we have to figure out the win win games where anyone's incentive and advantage is tied to collective advantage because if I go hurt somebody and I engender their enmity, and they have existential tech, I fucked myself, right. If I go increase the speed at which I can extract resources from the environment in a competitive game with others who are doing that we're heading towards the tipping points of chemical irreversibility.
Those peak resources and the environment we just from ourselves radically. So we have to get over those bad Nash equilibriums as bad, you know, win those games. And so that is full incentive alignment. And that requires to we can say, you know, come back we're saying, we have to close the loops in infrastructure, right? So we can think about the materials economy being a totally closed loop materials economy, we have to close the loops in human incentive, which means the incentive of all agents and well being of other agents in the comments are perfectly aligned. We have to close loops at the level of worldview, which means our definition of self and our definition of everything else in the biosphere are not definable with outside of relationship with each other, right? The idea that I can advantage myself at the expense of other things goes because that idea is existentially unsafe. It's just it's not true. It's essentially unsafe in the presence of the level of technology we have. So the win lose games require separate sense of self right? As soon as we have idea of self as an emergent property of everything, right as a fundamentally interconnected, dynamic emergent property of the biosphere, then they can't get ahead at the expense of that which my life is fundamentally are connected to. 
So the world that's a closed loop at the level of self and other right, worldview has to close loop. But we could just say, because economics sits right at the junction of worldview. And we could actually say, if you if you succeed at any of those, you succeeded, because you can only succeed at any of those by all of them succeeding. But it's a fairly succinct one to say, if we align the incentive of every agent with the well being of every other agent in the commons, and we succeed at them, thereby internalizing all externality, thereby incentivizing only only positive behavior, when you can't do that without the right infrastructure that can actually measure on the positive behavior, right, you have to have the kinds of sensor systems that can actually measure a balance sheet of the comments and make sure that the action is not enriching the balance sheet of the commons, you have to have the data processing we can take all that sensing and make sense of it.
You know, so that capacity requires tooling shifts, and, you know, worldview shifts, but that is essentially what our task is. One way of framing or task is right.