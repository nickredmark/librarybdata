hey folks read Here I am sitting with
someone most of the people who follow me
almost certainly no but for those who
don't this is Benjamin Voice Benjamin
has been chronicling what has been going
on at Evergreen since the debacle in
spring of 2017 he and I did not know
each other before but Benjamin is an
alum of Evergreen I was teaching there
and we've become friends in the
aftermath of that event so anyway we are
here to talk on what will soon be the
set of Bret Weinstein is Dark Horse
podcast we are here to talk about what
is taking place with you with Google
with the recent revelations out of
Project Veritas
do you want to say something about what
you've been up to and what you've
experienced recently at the the hands of
Google well let's back up a little bit
so I've been working on the story about
evergreen which includes you but I've
gone beyond the Bret Weinstein story
into various layers of student activism
and student counter activism and then
the administration and the faculty and
I've been following this for now two
years and I've kind of it's kind of
obvious to me that I might be kind of
annoying for certain people within the
institution of the Evergreen State
College because I keep on bringing to
light things that they very explicitly
don't want to be brought to light
however they are a public institution
and Washington state law has a very
explicit public records set of statutes
so they owe me information they owe the
public information and I've been able to
get information even though they've been
basically obstructing my access through
official means the public records
Department is basically locked at a
standstill so I get information from
other places well wait I want to stop
you right there because I think this is
an incredibly important fact that the
public doesn't know which is that this
public institution is by all evidence
conspiring again
the laws of the state of Washington it
is obstructing your attempt to get
information that you are legally
entitled to get from the institution and
it's giving you the runaround so that
raises serious questions about an
institution that has problems that have
been revealed through public records
requests so effectively the institution
has gone rogue and surely there is some
legal mechanism that should kick in that
forces them to comply because the
mechanism that keeps them honest is
people like you or me taking information
that we are able to extract and exposing
it and discussing it and letting the
chips fall where they may
mmm-hm will add to that the fact that
evergreens enrollment is tanking and
their main source of revenue right now
is the legislature and the only thing
that they can legislate sure legislature
legislature yeah it is a governing body
the governing body full of legislatures
yes yes they have the one proud thing
that evergreen can't out as a when is
getting securing funding from the
legislature they are getting state money
in order to survive
therefore it compounds that the
problematics of why would they not be
following the letter of the state law or
even the spirit of the law why would
they be wanting to take money but not
giving anything back in return it seems
like a quid pro quo if you are a public
servant then you are beholden to the
public yeah and the law is the law and
the Legislature should surely be holding
them to the laws of the state of
Washington and presumably withholding
funds if they don't comply I would also
say that the instruction not to comply
must have come from somewhere and I
think you and I would be likely to guess
the same source
yeah George has been all about spin and
president bridges yeah
yes George bridges and current president
current president bridges oddly not
fired after one of the most amazing
shows of incompetence anyone has ever
seen on
in college well at least live-streamed
yeah well that's for sure but let's just
say we don't have evidence for greater
incompetence shown by other college
presidents that I'm aware of this is
really singular and yet the man retains
his job so what brings it up to an
intersection my work on evergreen
intersecting with this project ferret s
revelation about the way that Google is
we've already known that Google has a
hand at controlling information that
should be pretty much obvious but this
makes it very explicit a couple weeks
ago I got demonetised no last Tuesday I
got to monetize about 40 videos in the
last six months were all of a sudden
well at the monitors I don't want to
quibble here but I think we have to be
super careful you were soft
Deanna ties softly which I wasn't even
aware was a thing but apparently a
monetized video can exist at different
levels of monetization and a bunch of
your videos suddenly dropped from the
green state to the yellow state yeah
thanks for caring and you have inquired
from yeah I inquired into it and I was
told that I need to have all those
videos manually reviewed and I've since
submitted all those videos to manual
review and most of them are getting
flipped back into the green but more
interesting to me this caused me to look
at the Google search and I just typed in
evergreens
evergreen college and Evergreen State
College and I've repeated this a couple
times now and I know everybody has a
different result so it might be because
I'm in the area of evergreen that
they're straining it for some reason but
my videos of which I have ninety two
about the Evergreen State College and
most of those videos are based entirely
on fact and what's not based on fact is
me responding or processing what these
documents say but it's all based on
public records on primary sources it's a
major source of material for every
documentarian that comes and does the
Evergreen story they contact me because
I have all the information and the
contacts so I'm the basis for any story
about evergreen I mean
the main basis and I am no longer listed
in the video tab on Google search
results you have become hard to find
yeah in fact if you use Google to search
for you which I find amazing on the
other hand there's something I hear you
I would say you're working too hard what
you're saying about the difficulty
finding you is very disturbing but in
light of what's come out of Project
Veritas in the last couple days I think
there's a very interesting
interpretation which is that machine
learning is being employed by Google in
order to create what they are calling
fairness which is much like equity is
the inverse of what we would normally
assume that term means fairness is the
inverse of what we would normally assume
that term means when deployed by Google
but the idea that a bunch of your videos
suddenly got shifted and then manual
review is restoring them opens the
possibility that what happened is that
the machine learning algorithm whether
it was sent to look at your stuff or
whether it finally got around to it or
whether somebody changed a parameter and
that's what caused your videos to be
altered in in their state somehow some
thing inside Google did a lot of
thinking for the public and decided that
your stuff which is very interesting
clearly to many who are paying attention
to the story should disappear and the
idea that that can happen ought to
frighten us because as you point out
what you do is really just expose the
facts of the situation you're not
hostile to Evergreen I know from many
conversations with you some of them on
camera and some of them not that you and
I and Heather all share a desire to see
the institution write itself and restore
the model that we know can be so
successful at educating students so the
fact is the public has every reason to
want to look at your content because the
critique that you're leveling at this
institution is actually in the hope of
making the institution
we're storing it to its former glory
making it better in the future serving
students and the idea that some
algorithm might think that it knows best
what people should hear about evergreen
and that somehow you're off-limits based
on I don't know what project Veritas
suggested was that they're using some
kind of analysis of language algorithm
that searches for terms and decides what
might be conservative of all things it's
just it's out of control
well I don't know if this is more or
less disturbing but could it also be the
case that some third party that was
hired by Evergreen to boost their
reputation on the web used a trick to
get me listed somehow as an
untrustworthy news source so Google then
automatically scrubbed me because I was
told somehow I was flagged somehow well
let's let's try that a different way
let's say to the extent that there is
some algorithm out there making
decisions that have big consequences not
only for your ability to earn but for
the ability of the public to find
information that that algorithm the
existence of it creates an opportunity
for agents on the other side to game it
so if there is an algorithm then there's
a question of well what do I have to do
to trigger that algorithm to make my
detractors content obscure and some time
ago I tweeted the question I can't find
it on Twitter I don't member exactly
what phraseology I use but the question
was approximately if it is possible to
pay Twitter or some other platform to
promote your content what is to stop
those platforms from selling the right
to down-regulate
your your competitors content or your
detractors content and I think that's
where we are well we are there and we
just watched the project very test video
and one of the questions I wanted to ask
you about that
is that if you if any one of us has
given the power to shape the world such
as Google has the power to shape the
world to quote Tim Poole would it not be
a sin to not try to shape the world
the better is this not something that is
inevitable that somebody given this much
power is going to want to manipulate
reality or perception in order to
manipulate reality well I think it is
inevitable if you don't build some sort
of protection into the system and one of
the things that I find very surprising
about the present moment is that lots of
people are losing touch with why we have
counterintuitive rights like the right
to free speech after all we should all
be able to agree that certain things
that people say are just terrible and it
would be great if nobody ever said them
again right we don't need more Nazi
garbage but there is a reason that the
Constitution itself says actually even
that is protected and the reason it is
protected is because there is no way to
draw the line that protects heterodox
speech and Bars truly obnoxious speech
and because we can't draw that line
surgically the value of heterodox speech
is so great and the founders were so
clear on its importance that they put in
a protection against governmental in
fear interference with such speech now
unfortunately the founders did not see
the present moment they could not I mean
these were people who never saw a
bicycle they never saw a cane saw a
train they didn't have any idea what
world we would be living in they would
have no way of imagining a an entity
like Google that sat as an interface a
literal interface between human beings
at a mechanistic level that's something
that has some kind of crude intelligence
could be making decisions about what I
am able to say and who gets to hear it
and how likely they are to encounter it
the founders would never have seen that
coming and because they didn't they
didn't properly fear private
interference with speech so the First
Amendment is just what I said to
Congress is it's inadequate to protect
the right that the founders were
attempting to protect which is the free
exchange of ideas so are you advocating
that the government expand its reach in
order to
give more livered Liberty like control
like Liberty in order to as a liberal
there's nothing I like better than
governmental control more of it that we
have the happier I am
as basically where that falls out no
look I've said many times that the
problem with much liberal thought is
that it under rates the danger of
solution making and that as you make
solutions you are always inviting
unintended consequences and that
liberals have a blind spot about those
things so believe me I have lots of fear
about what happens if we attempt to
regulate our way out of this puzzle yeah
we could make things worse and so I also
believe we need to recognize that we are
generally just across the board we are
in novel circumstances where the
documents that we were handed that built
this flawed but great nation are going
to find themselves without the ability
to address the problems that we
encounter and that means that we have to
figure out what to do about that do you
open up a constitutional convention well
I happen to think that would be a
disaster if you did it so I'm not in
favor of a constitution what do you mean
why would it be a disaster and what do
you envision this convocation to be like
well if you opened a constitutional
convention suddenly the immense
potential to shift the nature of the
Republic in favor of one constituency or
another would be on the table and I
don't see the wisdom available to us to
do it in a way that would not be
detrimental and what I do see is a lot
of powerful players who would not resist
the opportunity to attempt to remake the
nation to their interests so I don't
favor that sort of thing but I do favor
us thinking about the fact that we have
a general problem with the novelty of
our of our systems relative to the
documents that are built to to protect
us
and we have to have a frank conversation
about what to do about that well if
these companies are so big and so
important to anybody who creates content
Twitter is absolutely essential for me
to interface with other thinkers and my
audience and grow my base and then also
figure out and grow as a content creator
YouTube has been wonderful for me
evergreen was very good for me
YouTube's been wonderful for me it's
given me a voice it's given me a contact
that I never imagined was possible so
within these frameworks is it possible
to change them is it possible to band
together to get people to I don't know
outcry it doesn't seem to work and maybe
Congress will go after them at some
point it do we have to reboot everything
or we can't reboot everything so I'm
unfortunately not quite ready to talk
about this publicly yet but I will say I
think this is the core question that we
face which is how exactly do you deal
with a mechanism as complex as
civilization has become how do you
upgrade it without taking it offline or
allowing it to collapse or any of the
things that we can't afford and I do
think there is a category of answers to
this question and the question about
what to do about the net is I think
going to be the first test case question
is the net is new enough and the
mechanisms by which we might upgrade it
so that it did not become a totalitarian
nightmare those mechanisms actually
exist at our disposal if we can think I
use a cliche but think outside the box
enough to deploy them intelligently we
have seen enough components yeah that
are available to us that actually we the
public can upgrade the net without
asking permission to do it okay right we
can effectively out-compete the
authoritarians in their own landscape
that sounds like a technical solution do
you have any ideas about
a cultural solution the way that we
interact with one another the the kind
of content that we train ourselves to
favor or the types of interactions that
we promote and demote inside of
ourselves that might be playing into the
hands of these large behemoths I am Not
sure those are different questions my
sense is if you look at for example
television when I was growing up you're
not that much younger than the year that
you're 40 years yeah I'm 50 yeah in any
case when I was growing up everybody
understood television to be dangerous
and destructive especially to kids and
about the time I was in high school I
started saying it's not the box it's the
business model the the box itself and
you know the thing that caused me to
think that was that I spent plenty of
time watching documentaries on public TV
and I didn't have the sense that I was
degraded by them in fact I felt enhanced
I was educated by them and so obviously
it came over the same box and what was
different was that the business model
was different now I don't think NPR or
PBS are a model of anything at the
moment I think they've been captured by
something quite dangerous but what I do
know is that HBO at first and then later
on Netflix and others have taken the
very same box that was delivering really
toxic content and has repaired it by
getting people to pay up front for a
service and then delivering them a
higher quality good that does not
require the content to manipulate you
into keeping in your seat okay right so
the the need to keep you coming back
commercial break after commercial break
caused bad content the HBO version where
what they do is they sell you the right
to watch some long-form narrative and
they don't interrupt it with commercials
actually you can do something very
sophisticated in that
and yeah there's a lot of garbage out
there still but the point is nothing had
to change about the tech in order to
change the narrative content and enhance
it and I think the same thing is going
on with the net where what we have are
platforms that because of the
competition they are caught in are
forced to manipulate us into sticking
around longer than is healthy for us to
staying on site as they say when our
mental health would suggest that we
should get up and turn off the computer
or do something else so the real
question is if we were to fix the net
and fix the platforms that ride on it
what would that do to discourse and my
guess and it's not a wild guess it's an
educated guess my guess is the quality
of discourse would go way up and in fact
I think I think IDW has been a
demonstration of this so what would
cause the quality to go up the the need
to no longer keep people stuck around
but give them something that they want
rather than something that they're told
they want or manipulated into wanting
yes if you fix the incentive structure
around the content and the interaction
between let's say creators and platforms
then that which was delivered the
quality of it would go up and people
would seek out that which served them
better you know in a video that you
filmed of me quite some time ago we
talked a little bit about wisdom yeah
and I argued that the the core of wisdom
was delayed gratification and it's funny
in the aftermath of releasing that video
people have pointed me to lots of other
places where other people have argued
that that's actually the core of wisdom
so I
it's a resonant idea and I think the
point is given good tools wisdom about
how to spend your time online will go up
we don't have that happening now because
we have antagonists we have very
sophisticated antagonists who are
deploying very sophisticated machine
learning
to keep us from getting wise to keep us
coming back from for the the junk food
that they're delivering well at the same
time I think we can be a little bit
generous with at least the tension the
intentionality of the Google whatever
it's called in fairness enhancement team
or whatever they have the language
itself is really telling like how they
frame all their little ministries is
just it alarm bells Rafi the the nothing
to see here move along ministry what the
hell is that but it seems like in the
project very just video the woman that
was caught on cameras higher up on some
level of the appropriations or the
appropriateness committee she wants to
change the election she doesn't want
Trump to happen like they are they're
really scared of Trump they really want
the world to be a better place so it
seems like they are acting out of an
idea of wisdom or care concern well okay
is there any way to reach them and get
them to not go down this direction
no no I'm utterly convinced there is no
way to reach them these are these are
maniacs who do not realize that that's
what they've become and you know we saw
this that evergreen yeah was there any
way to reach evergreen still no way to
reach which tells you something I think
that's a model of what's going on and
Google is incapable of questioning the
wisdom of doing what it's doing now with
respect to their point about Trump I too
think that the election of Trump is a
very frightening fact as we are staring
down the barrel of potential war with
Iran having a guy like Donald Trump in
charge of whether or not we go that
direction makes us much more vulnerable
I believe and so there is something to
be said for the question of well what
does this mean on the other hand the
idea that Google thinks it has the right
to adjust content so that he doesn't get
elected again is the height of hubris
and it carries with it of
very obvious danger which Google which
has studied artificial intelligence
should well understand which is if you
start with the conclusion which is I'd
like to live in a world in which Donald
Trump doesn't get elected and then you
start adjusting content so that it
points away from a guy like Trump you'd
arrange us you make it impossible for us
to have a nuanced conversation you have
make it impossible for us to have a
conversation in which the
counterintuitive plays an important role
because the algorithm you know it's not
artificial genius it doesn't even
deserve right its intelligence is a
stretch in and of itself
so the point is look you have to let us
have discussions and the fact that you
and Tim Poole yeah are finding
themselves on the wrong end of this
algorithm tells you everything you need
to know well what does it tell me I just
I it I just can't get my head around why
they would think I am important enough
to scrub out let me let me put it to you
this way it tells you that the algorithm
thinks that you are bad for the future
when in fact I've listened to you you
are a difficult but positive force
you're a difficult force because you're
forcing people to look at something they
don't want to see and you know it's the
same thing I encountered the problem
with the Evergreen story was that good
people don't like a story with black
bigots black bigots were the problem I
don't like a story with black bigots on
the other hand if there are black bigots
which we encountered at Evergreen you
can't decide that story is unreported
because it goes against the narrative
that you favor you have to say well
what's happened why why is that a
phenomenon that's occurring in the
present and so anyway my point would be
you and Tim Poole are delivering very
high quality material and for the
algorithm having to decided to have
decided that what you are doing is
actually counterproductive tells you
that the algorithm is not interested in
truth it's not interested in
in-depth explorations because what both
of you are doing is you are exploring
things in depth so that people can see
the horror show they can also see what's
being lost and in any case I'm against
any algorithm that would decide that you
and/or Tim Poole were on the wrong side
of history because I believe you are on
the right side of history and not in as
great company well I'm not on the side
of those who would rewrite history
we know that at this point well you have
a an inability to look away yeah it
seems like in the what you brought up
with wisdom that delayed gratification
there's also it just makes me wonder
what is that desire for us to declare an
outcome or to be outcome oriented and it
seems like an unintuitive principle to
not become outcome oriented in certain
respects with regards to they want Trump
elected they want to fix it with
evergreen they want to fix the numbers
even though the numbers were fixing
themselves they wanted to fix these gaps
between different races and their
achievements and that equality of
outcome it seems really good it seems
like a fool Szold though it seems like a
foolish wisdom do you see that it seems
like you brought that up with Google
deciding where to go and then trying to
muddy the waters to get there well there
is a way in which something has switched
sides and the desire to stamp out
inquiry at Evergreen or in the Academy
is obviously paradoxical and the desire
to I mean this is Google Google became
Google because it allowed people to
discover what was actually available in
the world it allowed it indexed it
enough that we could actually find what
we were looking for and so in some sense
Google became a kind of next-level
perceptual apparatus just like an eye to
look into civilization and what
in place and now what is that I doing
its editing what you can see it's
serving a particular brain it is it is
becoming paternalistic and it has
decided that it doesn't want you to look
at your content for example and evaluate
it for yourself it's going to evaluate
it for you and just you know disappear
it and if you really want to find it you
can but you and I both know that the
degree to which Google intervenes
between you and your audience that
adjusts your fate going forward they've
decided that they've looked at your
content so other people don't have to
and what the heck Google is gonna decide
that yeah that's like the Academy
deciding that inquiry is a form of
oppression yeah it just it's it's odd
and I tried to design as I developed as
a content creator I'm still very early
in this experiment but I try to design
content that was complex that that kind
of used that knee-jerk reaction to get
people into the door getting attention
is important the way that I kept
attention and tried to go forward and
manipulate attention or to break apart
attention and to engage intention over
the course was to be is to not feed on
those clickbait things is to actually
upset expectations and have long-form
conversations with people that you
wouldn't normally have a conversation
with and it seems like if the algorithm
is somehow miss reading me in my
intentions or reading a certain
intention into it that they that it
either can't process that level of
complexity or that level of complexity
goes against what its handlers want to
happen when I think that that level of
complexity says we're exercising right
now I don't think any machine could
actually gauge what we're actually doing
here that level of complexity I believe
it's the way forward is the way for us
to get to a place where we can disagree
and build something while disagreeing on
things or whatever we well I I've said
elsewhere that we missed the boat with
respect to the
fears about AI that we were expecting
robots and that we are actually now
living the very early stages of the AI
apocalypse and we don't even know it
because the robots aren't an important
factor that what it is is the algorithms
and in some sense the algorithms have
started it to think for us now here's a
very basic question do the executives at
Google have an escape from their own
algorithmic adjustment of reality or is
this a positive feedback where the
executives of Google are going to be
convinced by the algorithms so they
stupidly set in motion are they going to
be reinforced in their wrong think I
hate to use that term Yannick Lee here
we're the ones who are they think we're
involved in wrong thing but to the
extent that they have deployed an overly
simplistic view of what's worth hearing
and what isn't are they creating their
own echo chamber which is then going to
deranged them right in other words the
overlords have created the seeds of
their undoing and it's you know it's
very much like the scene in whatever
movie where the robots turn on their
creators the algorithms are inevitably
going to confuse people at Google who
are programming the algorithms it seems
like we everyone swallow a new video
surfaces from one of those dynamic
companies out in Boston where they have
a robot Boston Dynamics they beat up the
robot now and the robot can sustain a
beating it's still if you look at those
robots they're they're scary they're
funny but they're not really articulate
well they what Google has done is
released robots into our cultural space
which they're non-physical robots but
now they're going through our cultural
landscape are they any more adroit are
they any less clumsy than the ones that
we see in those videos yeah they're not
quite a droid they're Android oh sorry
scenario we can edit that out
he's headed somewhere though but it does
remind me so every once in a while I put
out an evergreen video and there's
always somebody saying get over this kid
you got fired from there I'm like I was
a student but you know people don't
understand but I really do think that
the Evergreen the situation maps onto
other things and what you just said
about Google kind of circling the wagons
or getting their robots to cut them off
from discourse they don't have any
accountability to the outside world and
when we don't have accountability just
like what happened with the evergreen
story recently the certain faculty we're
trying to get the faculty to have an
open and honest discussion and every
layer of authority above the faculty
which we're all supposed to serve the
faculty shut down that discussion they
finally had a little bit of discussion
and even within that discussion they
didn't want anybody else to hear them
speaking they they've when we when we
cut ourselves off from that discourse
that damages us more than anybody else
we are unable to actually look at the
world because that which which we've
designed to protect us from the world
ends us ends up creating huge blind
spots for us going forward yeah I mean
in fact the point is this authoritarian
stuff ends in a dystopia every time you
deploy it and we are now seeing every
stripe of authoritarian right we saw it
at Evergreen I mean evergreen now
functions like a little dictatorship and
the fact is the faculty don't even have
the ability to email each other right
the dictatorship decided that because
faculty emailing each other was the root
of their unhappiness they cut that off
you can't reach the Board of Trustees
without going through the presidents
right-hand man you can't reach your
colleagues it's a little it's a little
totalitarian state google is behaving
like a little totalitarian state except
it happens to be one that is now in some
amorphous way sitting right in the
center of our ability to collectively
think yeah right that's a very dangerous
process and it's not going to end well
so the question is you know a what
should we think you know this video is
going to be released on YouTube yeah
we'll the attitudes algorithm be able to
figure out will it detect that we are
actually attempting to figure out how to
defend liberal values
what does Google's algorithm think of
traditionally liberal values sounds to
me from what Project Veritas what he
frankly makes me very nervous but
Project Veritas what they captured on
their camera suggests that Google has
moved beyond cherishing lis liberal
values and it thinks it knows better and
doesn't need them anymore and you know
we all know where that's headed is there
anything that we can do then other than
sound the alarm I don't want to I'm
tired myself of sounding the alarm of
feeding into outrage I'd rather keep on
trying to produce deep good content but
it seems like we do need to come
together on some level and and organize
or get ready for moving in another
direction well I'll give you two answers
one is we need to retool the internet
which will allow us to walk away from
those who have decided to think on our
behalf
that's one level and that's gonna
require some careful technological
thinking the other level though involves
us figuring out how to reject the
diagnosis of us and this is a place
where I think IDW at least for a while
succeeded when I DW first began to form
before there was even a name for
whatever that phenomenon is it was
immediately dismissed by a wide range of
people as a conservative phenomenon and
many people including me kept pointing
out that doesn't make any sense at least
half the people who are associated with
that conversation are actually
left-of-centre not only that but
everybody involved in the conversation
is heterodox in one way or another
and broadly tolerant so it isn't an
ideological conversation now my point
though is
at first there was a lot of resins to
the dismissal on the basis that it was
conservative but figuring out how to
respond to it without becoming enraged
and saying no that simply doesn't fit
the fact you actually caused an update
to people's model of what they were
seeing so I guess what I'm saying is we
have evidence of places where stigma
that is supposed to shut down one's
access to an audience was actually
repelled because the audience is
interested and there is enough openness
to an analysis of what's worth listening
to that in fact we won at least for a
while mm-hmm
the threat of a snake the stigma will
always be popping up it seems like no
matter where any particular people
congregate they will be slandered and
and the weird thing is is that the
people there are these useful idiots
there are these these these little
gaggles of groups that just want to go
around and stigmatize people and those
are being used that that that action
itself is so easily feeds into larger
authoritarian movements because it seems
like it shuts down people's ability to
really engage with things and I wonder
maybe we won't have time to talk about
it right now but about the mechanics of
stigma and how do we see it in ourselves
and and shut it down or or use it in the
proper way well the most important thing
is that you know we I've said in many of
these places where I've been asked to
talk about the free speech crisis I
don't think this is a free speech crisis
part of the problem with the framing of
what we're facing as a free speech
crisis is that it focuses too much on
the speaker when in fact what we saw at
Evergreen on other college campuses is
an attempt to prevent people from being
able to listen to what they want to hear
right you shut down a speaker it's not
their rights that are the most important
the question is what about all the
people who wanted to hear what they had
to say who don't now have the ability to
access it so
point of the stigma is to interrupt your
ability to seek content that you want to
engage with and in some sense that means
that the solution to the stigma problem
is not to deal with the stigmatizing
itself but to make sure that it does not
interrupt the ability of an audience to
find the content that it wants to engage
with you know there is a frightening
aspect of that I don't want people
engaging white nationalist content but
the reason that the founders protected
speech the way they did is that they
trusted that the net effect of
protecting all speech is to allow
heterodox ideas to flourish when they
are right and for that we have to accept
a certain amount of speech that on the
whole we would rather not exist is in
your estimation is there forms of speech
that are so toxic that they can destroy
or corrupt everybody's mind that should
be like some sort of science fiction
novel like the the book that will upload
us all into the net or some something
very deadly or dangerous is there a
combination of words that can ruin all
of civilizations that more words can
solve you have to you have to accept a
qualified answer on that point I don't
think there's a simple answer so I'm
gonna qualify it the there is no set of
words that does that but given a
particular context there is a set of
words that will set us in motion in a
particular direction that is very
dangerous and the point i've been making
is that economic contraction the
experience of the opposite of growth
puts people in mind of who to go after
in order to restore growth for their
family for their for their kin group and
so my point is we are actually wired for
messages that will cause us to turn on
people who are vulnerable this is what
happened in Germany in the 30s and it
can happen anytime so to the
that what we have are people like I
would argue Donald Trump played on this
I don't think it's necessarily what he
is interested in but to the extent that
people's cognitive structures were
looking for evidence of somebody who was
gonna point out which group we could
turn on well he's played on
[Music]
anti-immigrant sentiment and you know
distrust between populations and things
like that it's part of how he got
elected and so we have to beware that we
live in a period in which messages that
we do not want to spread are likely to
be more resonant than we would like them
to be it doesn't mean that those same
messages would have any resonance
whatsoever were we living in a boom okay
all right so yeah the answer is usually
not just the words themselves but the
context in which those words might
ignite a large fire yeah it may be the
simple way to say it is there are no
words that will do it but there are
combinations of contexts and words that
will yeah if google goes through and
starts to banish us from certain
nutrients let's say and thinking that
these things are bad but just goes
overboard then it could lead us to a
place where on a psychological or
cultural level we're getting hungry or
needing for some sort of upheaval that
could otherwise be avoided I think
that's true but maybe at a more basic
level the thing that we should the thing
that we need most is our ability to
think collectively clearly and that
requires that nobody decide which
fraction of the information we are able
to see as bad as it is that there is
there are messages out there that people
may spread that are dangerous it is far
worse that somebody decide that they
know which messages we get to see and
which ones we don't
so that right is a very important one it
is not synonymous with free speech it's
related but it is not the same thing and
we're gonna have to figure out how to
protect our ability to think
collectively because it's quite clear
that people wielding algorithms
have set us on a very dangerous course
in bike thinking collectively it's the
opposite of groupthink in a way it sits
together alone or together against or
it's another way of framing
interpersonal communication that doesn't
come down to everybody thinking in a
rigid form but but interacting with the
opposite of rigidity sometimes yes humor
and the ugly and the unnecessary the
uncomfortable I'll immediately put it
this way there is no reason that
language would have evolved to just
synchronize people's thinking
synchronizing people's thinking is not a
very interesting phenomenon and it
doesn't would not have caused the
evolution of something is absolutely
miraculous as human language so yes it
is true that sometimes people use
language to cause groupthink but the
most interesting thing that language
does is it allows minds that are
different to compare notes and to
upgrade each other and that's what I
mean by our ability to think
collectively I'm imagining something
much more like a an analog of a brain
that exists in between us that actually
does result in us getting smarter over
time and to the extent that Google
believes that it knows what that brain
should think about stuff we ought to be
quite frightened of Google yeah again
they've put like an Android thing into
our head and an insert of some sort some
sort of Borg Ian a modifier or enhancer
that does the opposite of enhance the
world I have to say when I walk down the
street now and I see apples earbuds
hanging out of people's ears I do sort
of have a sense I'm not sure why it
strikes me as more dire than when they
had you know your phones with cords but
there is something about a large
fraction of the population walking
around with a particular conspicuous
electronic augmentation hanging out of
both ears that makes me think oh
goodness where we ended up
all right Benjamin this has been
marvelous what I'm hoping we don't live
that far apart what I'm hoping is that
you'll come down and we can have further
conversations about what's taking place
and what it means cuz it's always a
pleasure engaging with you it's been
absolutely wonderful thanks for a
terrific thanks Benjamin alright for the
rest of you I would say if you want more
content like this hit like and subscribe
and maybe hit the notification button
and we will talk more about civilization
as it develops oh and find my channel in
the description somewhere also his
channel will be linked in the
description I was very impolite of me
not to mention that but of course it
would have been and it will be and so
you can find him there if you're not
already subscribed which is what I
suspect okay
signing off
[Music]
[Applause]
[Music]