[Music]
you
[Music]
welcome back to awakening from the
meeting crisis this is episode 27 so
last time we took a look at the nature
of cognitive science and argued for
synoptic integration that addresses
equivocation and fragmentation and the
ignorance of the causal relation between
these different levels which we talked
about mind and study mind and it does
that by trying to create plausible and
potentially profound constructs and then
I propose to you that we start doing
cognitive science in in two ways first
of all just trying to look at the
cognitive machinery that is responsible
for meaning cultivation but also try to
exemplify that pattern of bringing about
synoptic integration through the
generation of plausible and potentially
profound constructs so we took a look at
the central capacity to be a cognitive
agent and this is your capacity for
intelligence and of course intelligence
is something that neuro scientists are
looking for in the brain and that
artificial intelligence machine learning
is trying to create they're trying to
create intelligence psychology of course
has famously been measuring intelligence
since it's very inception the word
intelligences has reading between the
lines which seems we'll see has a lot to
do with your use of language and etc
culture of course seems to be deeply
connected to the application and
development of intelligence so
intelligence is a great place to start
and then I said we need to be very
careful we don't want to equivocate
about intelligence we want to make sure
we we approach it very carefully because
although it is very important to us we
often are using the term in an equivocal
and confused
and therefore bullshitting ourselves an
important way and then I propose to you
that we don't focus on the results the
product of our intelligence our
knowledge and what our knowledge does
for us our technologies for example we
focus instead on the process that allows
us to acquire knowledge because that way
we have something we can use
intelligence to explain how we have
acquired the knowledge we have I then
propose to you to follow the work that
was seminal both in the psychometric
measure of intelligence Binet and Simon
and the attempt to artificially generate
intelligence the work of New Orleans
Simon and this is the idea of
intelligence is your capacity to be a
general problem solver to solve a wide
variety of problems across a wide
variety of domains and then in order to
get clear about that we took a look at
the work of New Orleans Simon trying to
give us a very careful formal analysis
of what is going on in intelligence and
I'm going to come back to those you know
those ideas in a minute or two this idea
of an analysis of formal analysis a
problem was analyzed into a
representation of an initial state in
the goal state and I have a problem when
my initial state and my goal state are
significantly different I can then apply
operations or operators these are
actions that will change one state into
another State remember me moving towards
the cup raising my hand for example and
I can have a sequence of operations that
will like take me from my initial state
into my goal state but I have to follow
the path constraints I want to remain a
general problem solver I don't want to
solve any one problem to the detriment
of my capacity to be a general problem
solver or then my solving this problem
will undermine my intelligence in
general so to solve a problem is to
apply a sequence of operations that will
transform the initial state and the goal
state while following the path
constraints and then you can analyze
that by taking a look at the
space and it was this explication making
explicit of the problem space that was
the radical and I will in fact argue
profound power in what New Orleans Simon
was doing that's what made that their
work so impactful right in so many
disciplines now there's two things we
have to note about this that are
potentially misleading right first of
all one is I didn't draw the whole
diagram out and that wasn't just
happenstance okay we'll come back to
that the second one is this diagram is
misleading precisely because it is
created from God's eye point of view if
I were to fill the diagram out you could
see all of the pathways at once and you
could see at once
which pathway leads from the initial
state to the goal state but of course in
life when you have a problem that you
are not out here having a problem is
precisely to be here and you do not know
which of all these pathways will take
your initial state to your goal state
while obeying the path constraints you
don't know that you're ignorant because
remember we're not confusing
intelligence with knowledge solving this
is how you acquire knowledge a
problem-solving method is any method for
finding the sequence of transformations
that will take you from the initial
state into the goal state while obeying
the cop constraints and you say ok I get
it the diagram isn't complete and you're
over here you can't see the whole thing
you don't know which of all the pathways
yeah so what
well here's so what when I have analyzed
this and formalized it when I've
explicate Edyta in terms of problem
space it reveals something I can
calculate the number of pathways here by
the formula F to the D where F is the
number of operators on the plying at any
stage and D is the number of stages I go
through so Keith holyoke gave a very
famous example of this right
psychologist who was instrumental in
doing important work on the psychology
of problem solving let's do a concrete
example of this and then it's a great
example because it brings
machines that we have today so let's say
you're playing a game of chess right so
on average the number of operations you
can perform on any turn that's f is 30
now don't say to me well many of those
are stupid that's not the point
I'm trying to explain how your
intelligence that's what I have to
explain it's not what it can assume okay
so there's 30 legal moves and on average
there's 60 turns that's the number of
pathways that are in the problem space
this is known as combinatorial explosion
it sounds like a science-fiction weapon
but it's actually a central fact this is
a vast number it's something like four
point two nine times ten to the 88 in
standard and sort of scientific notation
now I want to I want you to understand
how big this is how astronomically
incomprehensibly large this is okay so
one thing you might say is well you know
that's easy I have many different
neurons and they all work in parallel
and they're all checking different
alternative pathways and that's how I do
this parallel distributed processing and
there's an important element in that but
that's not going to be enough because
you know you probably have sort of
around that many neurons now that's a
lot but it's nowhere near this and you
say ah but it's not the neurons it's the
number of connections and that's
something like five to the 10 to the
15th and that's a big number but you
know what it's no it's astronomically
far away from it's astronomically far
away from this so even if it's each
synaptic connection is exploring a
pathway this is still overwhelming your
brain in fact this is greater than the
number of atomic particles that are
estimated to exist in the universe does
this is in a literal sense bigger than
the universe it's big
and what does that mean that means you
cannot do the following you cannot
search the whole space for very very
many problems the problems are
combinatorially explosive and therefore
you cannot search the dust space you do
not have the time the machinery the
resources to search the whole space now
here is what is deeply deeply
interesting about you this is sort of my
professional obsession you might put it
if I could represent it this way right
if this is the whole problem space this
is somehow this is what you do somehow
you can't search the whole space and in
and I mean you can't sir
you can't look here and then reject
because if you look at this part of the
space and reject it and then look at
this part of it then you end up
searching the whole space it's not a
matter of checking and rejecting because
that's to search the whole space what
you do is somehow do this you somehow
zero in on only a very small subsection
of that whole space and you search in
there and you often find a solution you
somehow zero in on the relevant
information and you make that
information right effective in your
cognition you do what I call relevance
realization you realize what's relevant
now this fascinates me right and and
this and and that fascination is due to
the work of new orleans simon because
how do you do that
like and you say oh the computers are
really fast even the fastest
chess-playing computers don't check the
whole space they can't they're not
powerful enough for fast enough that's
not how they play
this issue of avoiding combinatorial
explosion is actually a central way of
understanding your intelligence and you
probably hadn't thought of that before
that one of the things that makes you
crucially intelligent is your ability to
zero in on relevant information and of
course you're experiencing that in two
related but different ways one way is
your and the way this is happening so
automatically and seamlessly for you is
the generation of obvious Ness like
what's obvious well obviously I should
pick up my marker obviously I should go
to the board obvious 'no siz not a
property of physics or chemistry or
biology obvious Ness is not what
explains your behave explains your
behavior in a common-sense way but
obviously this is what I scientifically
have to explain how does your brain make
things obvious to you and that's related
to but not identical to this issue of
how things are salient to you how they
stand out to you how they grab your
attention and what we already know right
is that that process isn't static
because sometimes what you how you how
you zeroed in on things as relevant what
was obvious to you what was salient to
you how you join the nine dots is
obvious and salient to you and yet you
get it wrong and part of your ability is
to restructure what you find relevant
and salient you can dynamically self
organize what you find relevant and
salient now Newell and Simon wrestled
with this and there's a sense in which
this is the key problem that the project
of artificial general intelligence is
trying to address right now in fact
that's what I argued I've argued in some
work I did with Tim Leela crop and Blake
Richardson work I've done with Leo
Ferraro there's a related work by other
people
but New Orleans Simon realized that in
some way you have to deal with
combinatorial explosion to make a
general problem solver you have to give
the Machine the system the capacity to
avoid combinatorial explosion we're
gonna see that this is probably the best
way of trying to understand what
intelligence is people like Stan a bitch
argue that what we're measuring when
we're measuring your intelligence and
psychometric tests is precisely your
ability to deal with computational
limitations to avoid combinatorial
explosion Christopher charity act argue
something similar so what did New
Orleans Simon propose well I want to
talk about what they propose and show
why I think it's important and then
criticize them and in what in what they
mistook or misunderstood and therefore
why their solution and they I don't
think they would have disputed that why
their solution was insufficient so they
proposed a distinction that's used a lot
but the term has these terms have
slipped I've watched them slip in in in
the 25 years I've been teaching at U of
T I've seen that the terms flip around
but I want to use in the way Newell and
Simon use them within the context of
problem solving and this is the
distinction between a heuristic and an
algorithm they actually didn't come up
with this distinction this actually came
from an earlier book by polla on called
how to solve it which was a book just on
the psychology and it was a set of
practical advice for how to improve
problem-solving so remember we talked
about what a problem-solving technique
is a problem-solving technique is a
method for finding a problem solution
that's not trivial because a problem
solution has been analyzed in terms of a
sequence of operations that takes the
initial state into the goal state while
obeying the path constraints okay so
what's an algorithm an algorithm is a
problem-solving technique that is
guaranteed to find a solution or prove
and I'm using that term technically
not give evidence for but or prove that
a solution can't be found right and of
course there there are algorithmic
things you do you know the algorithm for
doing like multiplication for example
you know 33 times four right there is a
way to do that in which you can reliably
guaranteed get an answer so this is
important and I remember I said I'd come
back to you and explain why ttyl de
cartes project was doomed for the
failure because algorithmic processing
is is processing that is held to the
standard of certainty you use an
algorithm when you are pursuing
certainty now what's the problem with
using an algorithm as a problem-solving
technique well it's guaranteed to find
an answer or prove that an answer is not
fun not findable so algorithms work in
terms of certainty ask yourself in order
to be certain that you've found the
answer or proved that an answer cannot
be found how much of the problem space
to have to search so there's some a
priori things you can do to shade the
problems face down a little bit and you
know computer science talks about that
but generally for all practical purposes
and intents in order to guarantee
certainty I have to search the space the
whole space and the space is
combinatorially explosive so if I pursue
algorithmic certainty
I will not solve any problems I will
have committed cognitive suicide if I
try and write B algorithmically certain
in all of my processing if I'm pursuing
certainty and right as I'm trying to get
over to the cup Comet or explosive space
opens up and I can't get there because
my life time my resources my processing
power is not sufficient to search the
whole space that's why a cart was doomed
from the beginning you can't turn
yourself into mr. Spock you can't turn
yourself into data you can't turn
yourself into an algorithmic machine
that is pursuing certainty that is
cognitive suicide that tells us
something right away by the way because
logic deductive logic is certainty it is
algorithmic it works in terms of
certainty an argument is valid if it is
impossible for the premises to be true
at the conclusion false logic works in
terms of the normativity of certainty it
operates algorithmically so does math
you cannot be comprehensively logical if
I try to be mr. Spock and logic my way
through anything I'm trying to do most
of my problems are combinatorially
explosive and I won't solve even one of
them because I'd be overwhelmed by a
combinatorial explosive search space
this tells you something this is what I
meant earlier when I said trying to
equate rationality with being logical is
absurd you can't do that the issue these
terms are not and cannot be as much as
Descartes wanted them to be they are not
and cannot be synonymous now that
doesn't mean that rational means being
illogical or willy-nilly the ratio
rationing pay attention to this ratio
rationing being rational means knowing
when where how much and what degree to
be logical and that's a much more
difficult thing to do and I would argue
more that being rational is not just the
psycho technology of logic but other
psycho technologies knowing how knowing
where when and how to use them in order
to overcome self-deception and optimally
achieve the goals that we want to
achieve
often when I talk about rationality
people think I'm talking about logic or
consistency and they misunderstand that
is not what I've meant and that's what I
said when Descartes was wrong in a deep
sense from the beginning okay Nolan
Simon realized this
that's why precisely why they proposed
the distinction a heuristic is a
problem-solving method that is not
guaranteed to find a solution
it is only reliable for increasing your
chances of achieving your goal so I've
just shown you you cannot play chess
algorithmically of course you can and
even the best computer programs do this
play chess heuristic alee you can play
chess doing the following things right
here are some heuristics you know get
your Queen out early control the
centreboard castle your king you can do
all of these things and nevertheless not
achieve your goal winning the game of
chess right and that's precisely because
of how heuristics work
what heuristics do is they try to pre
specify where you should search for the
relevant information that's what a
heuristic does it limits the space
you're searching now what that actually
means is it's getting you to prejudge
what's going to be relevant and of
course that's where we get our word
prejudice from and a heuristic is
therefore a bias it's a source of bias
this is why the two are often paired
together heuristic bias approach look
what my chest your wrist extension I
focus on the centreboard I focus on my
queen if I'm playing against somebody
who's very good they'll notice how I'm
fixated on the centreboard in the queen
and they'll keep me focused there well
playing a peripheral game that defeats
me I played a game of chess not that
long ago and I was able to use that
strategy against someone okay there is
this is called the no free lunch theorem
that it is
unavoidable you have to use heuristics
because you have to avoid combinatorial
explosion you can't be comprehensively
algorithmic logical mathematical the
price you pay for avoiding combinatorial
explosion is you fall prey to by us
again and again and again the very
things that make us adaptive are the
things that make us prone to
self-deception now there's going to be
deep reasons later while why this is
insufficient right but if you remember
we talked about these heuristics and
biases when we talked about the
representative heuristic and the
availability heuristic the
representativeness heuristic and the
availability heuristic that were at work
when you take your friend to the airport
because you can't calculate all the
probabilities it's combinatorially
explosive so you use the heuristic how
easy can I remember plane crashes how
much how prototypical to do this how
representative are they of disasters and
tragedies and because of that you judge
it highly probable that the plane will
crash and then you ignore how deeply
dangerous your automobile is right so
the very things that make you adaptive
make you prone to self-deception now
this account I think I I have tremendous
respect for Nolan Simon right first of
all let me tell you why I have respect
and then what what criticisms I have so
first of all this idea that part of what
makes you intelligence is your ability
to use heuristics I think that's a
necessary part and the empirical
evidence that we use these heuristics is
quite quite powerful and convincing and
well replicated this is also an instance
of doing really really powerful work and
this will add one more dimension to what
it is to do good cognitive science
yes it's about creating plausible
constructs that afford synoptic
integration but there there is another
way in which New Orleans Simon
exemplified they model to us what it is
to do it well their proper properly and
again this is going to relate to the
meaning crisis notice what they've done
notice how all all of the aspects all of
the great changes that have made the
scientific way of thinking possible are
exemplified in what New Orleans Simon
are doing notice that they're analyzing
they're taking right a complex phenomena
and they're trying to analyze it down
into its basic components just like they
Lee's did so long ago when he was trying
to get at the underlying substances and
forces they're trying to do that
ontological depth perception and then
like Descartes they're trying to
formalize it they're trying to give us a
graphical mathematical representation
the problem space is a formalization
that allows us to do calculations
equations that's how I was able to
explain to you combinatorial explosion
and then what they were doing right is
they were trying to mechanize I know
that will make some people's hackles
rise but the point of this is I I've got
this right if I can make a machine that
can carry out my formal analysis because
that means I haven't snuck anything in
and that really matters because it turns
out that trying to explain the mind we
often fall into a particular fallacy
okay so you know how would you see well
here's a triangle out here and the light
comes off of it when it goes into your
eye right so that's a really horrible
eye goes into your eye and then the
nerve impulse is and then I'll
equivocate on the notion of information
to hide all kinds of theoretical
problems and then it goes into like it
goes into this space inside of my mind
wait but it's called maybe working
memory or something and it gets
projected onto some inner screen and
there there it is it's projected there
and then there's a little man in here
the Latin for little man is homunculus
and the little man
maybe it's your central executive or
something says triangle so that's how it
works right and notice notice what's
going on here it sounds like I'm giving
a mechanical excellent and then I invoke
something now what you should ask me
right away is the is the following ah
yes but John how does the little man
the little homunculus see the inner
triangle oh well inside his head is a
smaller space with a smaller projection
in the middle and there's a little man
in there that okay and so on and so
forth and you see what this gets this
gives you an infinite regress it doesn't
explain anything why this is the
circular explanation remember we we
talked about this right this is when I'm
using vision to explain vision and you
say well yeah that's stupid I get by
that stupid that's non explanatory
circular explanations are non
explanatory yes or not they are they're
not explanatory but here's what I
ultimately have to do and this is what
Newell and Simon are trying to do
they're trying to take a mental term
intelligence and they're trying to
analyze it formalize it and mechanize it
so they can explain it using non mental
terms because if I always use mine to
explain mine
I'm actually never explaining the mine
I'm just engaged in a circular
explanation what Newell and Simon are
trying to do is analyze formalize and
mechanize an explanation of the money
they're not doing this because they're
fascists or they're worshipers of
science or they're in enamored with
technology maybe some of those things
are true about them but independent from
that I can argue is which is what I'm
doing that the reason they're doing this
is that it exemplifies the scientific
method because it is precisely designed
to avoid circular explanations and as
long as I'm explaining the mental in
terms of the mental I'm not actually
explaining it I call this the
naturalistic imperative in cognitive
science try to explain things
naturalistically again some of this
might be because you have a prejudice in
favor of the scientific worldview and
there's all kinds of cultural
constraints of course I'm not denying
any of that critique but what I'm saying
is that critique is insufficient because
here's an independent argument the
reason I'm doing this is precisely
because I am trying to avoid circular
explanations of intelligence why does
that matter
remember the Scientific Revolution
produced this scientific worldview that
seems to be explaining everything except
how I generate scientific explanations
my intelligence my ability to generate
science is not one of the things that is
encompassed by the scientific worldview
there's this hole in the naturalistic
worldview that's why many people who are
critical of naturalism always zero in on
our capacity to make meaning and have
consciousness as the thing that's not
being explained their right to do that I
think they're wrong to conclude that
that somehow legitimates
other kinds of worldviews right we'll
come back to that because I think what
you need to show is you need to show
that this project yeah because this is
an inductive argument it's not a
deductive you have to show that this
project is failing that we're not making
progress on it and that's a difficult
thing to say you can't you can't defeat
a scientific program by saying 22 things
that hasn't yet explained because if
that will always be the case you can't
point to problems it faces right what
you have to do and this is something I
think that lack ratash made very clear
you have to point to the fact that it's
not making any progress in improving our
explanation and it's really questionable
and I mean that term seriously that
we're not making any progress in
explaining intelligence by trying to
analyze formalizing mechanize it that's
that's getting really hard to claim that
we're not making any progress now why
does this matter
because if cognitive science can have
give create a synoptic integration by
creating plausible constructs
theoretical ways of explanation like
what Newell and Simon are do doing that
allow us to analyze formalize and
mechanized they have the possibility of
making us part of the scientific
worldview not as animals or machines but
giving a scientific explanation of our
capacity to generate scientific
explanations we can fit back into the
scientific worldview that science has
actually excluded us from as the
generators of science itself
so New Orleans c√≠mon are creating this
powerful way of analyzing formalizing
and mechanizing intelligence there's
lots of stuff converging on it there's
stuff from how we measure intelligence
talk about it I were trying to make
machines right and and it holds a
promise for revealing things about
intelligence that we didn't know before
like the fact that the one of the core
aspects of intelligence is precisely
your ability to avoid common tutorial
explosion make things salient and
obvious and do this in this really
dynamically self-corrective fashion like
when you have an insight so I'm done
praising New Orleans Simon for now now I
want to criticize them because New
Orleans Simon's notion of heuristic also
a valuable part of the multi Optus a
valuable new explanatory way of dealing
thinking about our intelligence while
necessary is insufficient because New
Orleans Simon were failing to pay
attention to other ways in which we
constrain the problems faced and zero in
on relevant information and do that in a
dynamically self-organizing fashion well
what were they failing to to notice they
were failing to notice right that they
had an assumption in their attempt to
come up with a theoretical construct for
explaining general problem solving they
assumed that all problems were
essentially the same this is kind of
ironic we have a heuristic a heuristic
you remember charlie nostalgia we have a
heuristic of essentialism this is also a
term that has been taken up and I think
often applied loosely within political
controversy and discourse
the idea of essentialism is that when I
group a bunch of things together with a
term remember
Ockham's ideas about we group things
together just by the words we use for
them that's nominalism but when I group
a bunch of things together they must all
share some core properties they must
share an essence remember that's the
Aristotelian idea of a set of necessary
and sufficient conditions for being
something now it is of course the case
that some things clearly fall in that
category triangles have an essence all
triangles no matter what their shape or
size have three straight lines three
angles and the angles add up to 180
degrees and if you have each and every
one of those you are a triangle right
and there are also natural kinds one of
the things that science does and we'll
see why this is important later is it
discovers those groupings that have an
essence so all gold things have a set of
properties that are essential to be in
gold right and we'll talk about why
that's the case later not everything we
group together and this was famously
pointed up by Vic and Stein right has an
essence oh let's use Vic in Stein's
example first if you remember right we
call many things games now what what set
of necessary and sufficient conditions
do all and only games possess right well
all they involve competition well there
are many things that involve competition
that aren't games war and there are
games that don't seem to involve
competition like catch oh well you at
least they involve other people
solitaire oh they well they have to
involve imagination it's all the terror
but they have to involve pretense catch
what do you pretending to do and this is
Vic and Stein's point you won't find a
definition that includes all and only
games and this is the case for many
things like chair table etc remember
this was all part
what Arkham was pointing to I think so
the idea is we come with a heuristic we
treat any category as if it has an
essence but many categories don't have
essences we're going to come back to
that shortly in a few minutes when we
talk about categorization why do we use
this heuristic because it makes us look
for essences why do we want to look for
essences because this allows us to
generalize and make very good
predictions yes I can over generalize
but I can also under generalize that's
also a mistake so we use this heuristic
because it's adaptive it's not
algorithmic because there are many
categories that don't have essences
Newell and Simon thought this category
had an essence that all problems are
essentially the same that all problems
are essentially the same and therefore
they could come up with one base all I
needed to call it if all problems are
essentially the same then to make a
general problem solver I basically need
one right one problem solving strategy I
just have to find the one essential I
may have to make variations on it but I
have to I have to find the one essential
problem solving strategy
and because of this how you formulate a
problem how you set it up to try and
apply your strategy how you represent
the initial state the goal state the
operators the path constraints that's
that's trip that's trivial right that's
not important because if all problems
are essentially the same you're going to
be applying basically the same problem
solving strategy now both of those
assumptions that are driven by they were
in fact being driven by a psychological
heuristic of essentialism essentialism
isn't a bad thing at least talking about
it as a cognitive heuristic alright it
shouldn't be treated algorithmically but
we shouldn't pretend that we can do
without it
okay now if Nolan's Simon were right
about this then of course these aren't
problematic assumptions but they're
actually wrong about it because there
there are and many people have converged
on this at different times in using
different different terms but there are
fundamentally different kinds of
problems and there there's different
ways in which a different kind of
roblems I'm just I just want to talk
about a central one that's really
important to you your day to day life
this is the distinction between
well-defined problems and ill-defined
problems
seeing a well-defined problem I have a
good meaning and effective guiding
representation of the initial state the
goal state the operators so that I can
solve my problem so I take it that for
many of you that problem I gave earlier
and as there is a relationship between
something being well-defined an
algorithmic they are not identical but
there is a relationship right for many
of you that should be a well-defined
problem you can tell me your initial
state this is a multiplication problem
and that gives you useful guiding
information you know a lot of things by
knowing your initial state you know what
the the goal state should look like this
should be a number when I'm done and you
know that this number excuse me should
be bigger than this number these two
numbers the most beautiful picture of
all time of a platypus does not count as
an answer you know what the operations
are singing and dancing are irrelevant
to this this is well demand you and a
lot of your education was getting you to
practice making whole sets of problems
well-defined and part of what psycho
technologies do is they make
well-defined problems for us like
literacy and numeracy mathematics now
because of that power and because of
their prevalence in our education we
tend to get blinded and we tend to think
that that's what most problems are like
and that means we don't pay attention to
how we formulate the problem because the
problem is well formulated for us
because I Slee precisely because it's a
well-defined problem but most of your
problems are ill-defined problems and
most of your problems you don't know
what the relevant information about the
initial state is you don't know what the
relevant information about the goal
state is you don't know what the
relevant operators are you don't know
what the even the relevant path
constraints are
you're sitting in lecture perhaps at the
University and you've got this problem
take good notes okay
what's the initial state well I don't
have good notes and well yeah okay okay
so what should I do and all you'll do is
give me synonyms for relevance realized
right I should pay attention to the
relevant information the crucial
information the important information
and how do you do that oh well you know
it's obvious to me or it stands out to
me great but how how would I make a
machine be able to do that what are the
operations oh I write stuff down do you
do I just write stuff down right like I
draw I make arrows I do I write
everything down well no I don't write
everything down and I don't just what
are the operations does that mean
everybody's notes will look the same no
when I do this in class everybody's
notes look remarkably very different so
what are the operations and what does
what's the goal state look like well
good notes great what are the properties
of good notes well they're useful why
are they useful
well Beco oh right because they contain
the relevant information connected in
the relevant way that makes sense to me
and so I can use it to Sofia right I get
it what's actually missing in an
ill-defined problem is how to formulate
the problem how to zero in on the
relevant information and thereby
constrain all right
the problem so you can solve it so
what's missing and what's needed to turn
to deal with your ill-defined problems
and turn them something into something
like well-defined problems for you is
good problem formulation which involves
again this process of zeroing in on
relevant information relevant relevance
realization and you see if they had
noted this if they had noted that this
bias made them trivialize formulation
they would have realized that
there are problems aren't all
essentially the same and they would have
realized the important work being done
by problem formulation and that would
have been important because that would
have given them another way of dealing
with the issue of combinatorial
explosion let me show you so we already
see that the relevance realization that
that work and problem formulation is
crucial for dealing with real-world
problems taking good notes that's
another fun problem following a
conversation that's another fun part
well I should say things what things
well oh the relative when well you oh
it's appropriate how often well sir tell
a joke go on a successful first date
all of these are ill-defined problems
most of your real-world problems are
ill-defined problems so you need the
relevance realization within good
problem formulation to help you deal
with most real-world problems already
problem formulation is crucial but
here's something that New Orleans Simon
could have used and in fact Simon comes
back and realizes it later
in an experiment he does with Kaplan in
1990 and I want to show you this
experiment because I want to show you
precisely the power of problem
formulation with respect to dealing with
constraining the problem space and
avoiding combinatorial explosion I need
to be able to deal with ill-defined
problems to be genuinely intelligent I
also as we've already seen have to be
able to avoid combinatorial explosion
that has something to do with relevance
realization and that has a lot to do as
we've already seen with problem
formulation let me give you the problem
that they used in the study of the
experiment okay
so this is called the mutilated
chessboard example right there are eight
columns and eight rows and so we know
that there are 64 squares now because
this is a square I didn't draw it
perfectly square but pretend it is if I
have a domino and it covers two squares
it'll cover two squares equally if I put
it horizontally vertically
how many dominoes do I need to cover the
chessboard well that's easy two goes
into 64 right
I need 32 32 dominoes will cover this
without overhang or overlap
now I'm gonna mutilate the chessboard
I'm gonna remove this piece in this
piece okay so how many squares are left
here right
62 there's 62 squares left so I've now
mutilated the chessboard here's the
problem can I cover this with 31
dominoes without overhang or overlap and
you have to be able to prove the duct of
Lee demonstrate that your answer is
correct
now many people find this a hard problem
they find it a hard problem perhaps
you're doing this now because they
formulated as a covering problem they're
imagining they're trying to imagine a
chessboard and they're trying to imagine
possible configurations of dominoes on
the board so they adopt a covering
formulation of the problem a covering
strategy and they try to imagine it that
strategy is combinatorially explosive so
famously there was somebody one of the
people in one of the experiments one of
the participants trained in mathematics
and was doing this topographical
calculation and they worked on it for
like what is it 16 to 18 hours and
filled 81 pages of a Hillary notebook
and they didn't come up with a solution
why because if you formulate this as a
covering strategy you hit combinatorial
explosion
this the problem space explodes and you
can't move through it and that's what
happened to that participant not because
they lacked the logic or mathematical
abilities in fact it was precisely
because of their logic and mathematical
abilities that they came to grief now
you should know by now that I am not
advocating for Romanticism oh just give
up logic and rationality that's
ridiculous you've seen why I'm critical
of that as well but what I'm trying to
show you again is you cannot be
comprehensively algorithmic okay so if
you formulate this as a covering
strategy you can't solve it let's
reformulate it you can't quite see this
on the diagram but you'll be able to see
it clearly in the panel that comes up
right these squares are always the same
color on a chess board in fact that's
not hidden in the diagram and and what's
used in the actual experiment clearly
that's clearly visible these squares are
always in the same color you say so what
right that's the point you can see them
but they're not salient to you in a way
that makes a solution obvious to you
they're not salient to you they're there
but they're not standing out to you in a
way that makes a solution obvious to you
but let's try this if I put this Domino
on the board if I put it horizontally or
vertically I will always cover a black
and white square always there is no way
of putting it on the board that will not
cover a black and white square so in
order to cover the board with dominoes I
need an equal number of black and white
squares I must have an equal number of
black and white squares that must be the
case but these squares are the same
color is there now an equal number of
black and white squares there no because
these are the same color there is not a
number an equal number of black and
white squares I must have an equal
number of black and white squares I know
for sure because these are the same
color I do not have an equal number of
black and white squares therefore I can
prove to you that is an impart it is
impossible to cover the board with the
Domino's if I go from
replicas from formulating this problem
as a covering strategy which is
combinatorial explosive to using a
parity strategy in which the fact that
they are the same color is salient to me
such that now a solution is obvious no
it's obvious that it's impossible
I go from not being able to solve the
problem because it's combinatorially
explosive to a search space that
collapses and I solve the problem this
is why the phenomena we've been talking
about when we talked about flow and
different aspects of higher states of
consciousness is so relevant this
capacity to come up with good problem
formulation problem formulation that
turns ill-defined problems into
well-defined problems for you problem
formulation that goes from a
self-defeating strategy because of
combinatorial explosion to a problem
formulation that allows you to solve
your problem that's insight that's
insight that's why the title of this
experiment is in search of insight
that's exactly what insight is it is the
process by which bad problem formulation
is being converted into good problem
formulation that's why insight in
addition to logic is central to
rationality and in addition to any
logical techniques that improve my
inference I have to have other kinds of
psycho technologies that improve my
capacity for insight and we've already
seen that that might have to do with
things like mindfulness because of
mindfulness capacity to give you the
ability to restructure your family its
landscape
so we're starting to see how problem
formulation and relevance realization
are actually central to what it is for
you being a real-world problem solver
avoiding combinatorial explosions
avoiding ill-defined Ennis we're going
to continue this next time as we
continue to investigate the role of
relevance realization in intelligence
and related intelligent behaviour like
categorization action communication
thank you very much for your time and
attention
[Music]
you
[Music]
you
you