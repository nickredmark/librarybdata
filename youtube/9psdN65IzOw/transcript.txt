howdy this is Jim rut and this is the
Jim rut show
[Music]
this is the gym rut show and I'm your
host Jim rut
today's guest is Daniel SH mutton burger
Daniels an independent thinker focusing
on the future of civilization the
sensitivity and potential of our current
situation and how we may navigate the
path forward he's also director of R&D
and co-founder of the neuro hacker
collective welcome Daniel thanks for
having me Jim and looking forward to
this conversation yeah I followed your
work for some time and while I keep my
eye on several thinkers who are thinking
about the future of our society your
perspective is perhaps both the most
dire and the most hopeful interesting
that you can be both yeah I call that
kind of a hard fork hypothesis I like
that it's a good way to describe it you
know on the dire side you know you say
pretty explicitly you believe Humanity
is going to end relatively soon we don't
address some of our fundamental design
issues in our social operating system
yeah I basically say that when we look
at history we see that most of the
previous civilizations obviously they
don't still exist and they underwent
internal decay that led to how their
collapse occurred and we can look at the
way that Tainter studies this oh the way
Jared Diamond did or the way that kind
of Straus how or Baudrillard or
different models of civilization will
collapse describe it but they're just
like people have a life cycle there seem
to be these life cycles of civilization
and there are certain things in common
that lead to their breakdown the
difference now is that we have a fully
globalized civilization and rather than
just causing local environmental harm
that can lead to a limits of growth
issue we can affect the habitability the
biosphere at large
obviously we didn't use to have weapons
of mass destruction so there's a total
difference of the capacity for warfare
etc rates of Technology both the
globalization and technology have
changed the magnitude of the issues in a
way where the change of magnitude
actually becomes a change in kind and
yet we haven't figured out not
civilizational collapse so if we
forecast all of the different possible
catastrophic risks or existential risks
there's a lot of them and what I would
say is that they all are the result of
some under
common generator functions and so as a
result if we just tried to deal with a
particular AGI scenario or a particular
climate change or a particular
biodiversity loss or World War three
scenario we don't buy ourselves that
much time before another scenario
emerges because the situation is
basically over determined so we actually
have to address the generator functions
we have to address it categorically
rather than just instances and if we do
that that becomes the kernel of a new
civilizational model that is radically
different than any civilizations
heretofore which is the more optimistic
picture and this is kind of like a hard
fork between very different scenarios
yeah that was I was gonna say on the
hopeful side you're basically trying at
least to define a new social operating
system and at least for me and my kind
of naive way of looking at things it's
still a very rough sketch but I can see
that if you are able to fill this in it
may make human life vastly better and
more humane than it's ever been before
before we get to your specific so I
would like for our audience and keep in
mind that our audience are smart people
I hope but they're not necessarily
experts on the way you and I and Jordan
and some of our friends talk so I want
to make sure that neither of us get too
far afield in jargon and that we make
sure that we bring substrate issues up
before we dive in deeper specifically
I've heard you talk in the past very
eloquently about how human created
technology is a fundamental change in
the dynamics of the world and that
technology I invented technology is
fundamentally different than evolution
and produces fundamentally different
dynamics we'll talk about that a little
bit before we jump into the more
specifics of where we're at yeah it's
definitely a kind of central thing for
us to figure out especially when if we
don't realize this we try and use
evolutionary biology and evolutionary
theory to model human systems like
reifying theory of markets based in
evolutionary theory and social Darwinism
writ large and that actually my
assessment doesn't work a lot of this
insight on the fundamental difference of
and evolution and highlighting it with
something Forrest Landry helped me
understand but model goes like this in
evolution in evolved systems we can kind
of think of evolution is defined by
three primary characteristics which is
mutation occurs and then selection
occurs but selection is two things does
the agent survive and does it reproduce
so survival selection mate selection and
then obviously that is survival and
mating with in evolutionary niches now
something to understand about that is
that the mutation pressures that are
affecting everything in an ecosystem
there's a kind of evenness of the
distribution of mutation pressures
whether we're talking about gamma rays
or oxidation or just copying errors or
viruses they're affecting all of the
Lions pretty similarly and the Lions and
the gazelles and the plants so we don't
have radical mutation occurring in one
place and no mutation occurring
somewhere else and so as you have a
mutation that would make a lion faster
or any predator faster you have similar
mutations that have a distribution and
the fastness and slowness of the prey
animals so then of course if you get a
little bit faster in one and they say
the lion eats the slower gazelles then
the fastest gazelles reproduce and that
leads to doubling down on those genes so
that's the next part is not just a
evenness in the distribution of mutation
but also Co selective pressures and so
the advance is anywhere lead to a pretty
strong symmetric coupling of power
across the whole system and so this
leads to a situation where you do have
rival risk dynamics in nature you do
have something like individual agents
doing self maximization of course it's
not purely that we have a lot of
symbiosis we have animals that are
paying attention to their yog and
animals that wouldn't survive it's not
for the whole group of animals that you
can model individual self optimizing
agents and get a certain successfulness
if you have the cemetry of power so you
have this line in this gazelle are in
rival risk dynamic but all lions and all
gazelles are symbiotic with each other
meaning the Lions would die without the
gazelles the gazelles would die without
the Lions and as either one makes an
advancement it drives the other one to
make an advancement so this is kind of
where when we think of social Darwinism
we think of the idea that
competition drives innovation and
advancement and those types of things
the difference when tech comes about is
so again these changes in the animals
are happening mediated through genetics
mutation of the genes and then survival
and then recombinant parts of the genes
so the genes are physically instantiated
pattern replicators when technology
technology I don't just mean physical
tech I also mean language I also mean
social tech coordination tech but so
techne and the Sanskrit sense of
consciously mediated methods of doing
things basically things that come from
the capacity for abstraction and
creating abstract pattern replicators
the abstract pattern replicators can
change much faster than the instantiated
ones can and they can change and with an
uneven distribution so when we think
about tool making starting with you know
Homo habilis and stone tools right which
is very different than a chimp using a
rock that it finds but not whittling
sharper you know we're chipping a
sharper rock which is the chimp or the
bird or whatever it is that's using
something can experientially notice that
this thing is better at doing what it
wants than this thing is in the moment
but it can't understand that between all
three rocks why this one is better at
cutting the thing is because of the
abstract principle of sharpness and then
say oh I understand what mediates
sharpness and I can design something
with more sharpness that abstraction
capacity seems to be part of how we
define early humans and then got double
down in Homo sapiens and it's a
different process than evolution of
bringing new stuff into existence it's
not occurring through kind of random
mutation and just selective dynamics
it's occurring through an agent that's
actually understanding something
abstractly and intentionally creating it
and so if you think about evolution as
the stuff that emerges there wasn't a
conscious choice to have something
emerge it emerged as the result of
complexity dynamics so it's unconscious
it's radically parallel it's radically
distributed it's radically combinatoric
it's slow almost everything fails but
you get a interoperability of everything
so what makes it through or very
self-stabilizing complex systems with
technology it's actually consciously
created
it can happen in a local way not
everywhere so it's not radically
parallel and decentralized it happens
more in a serial fashion and it creates
parts that are not necessarily in
equilibrium with whole systems and so it
really is mathematically almost an
opposite kind of creative process and
the thing is if you have an evolutionary
agent like a human that has evolutionary
motives but is now able to say human
operating as apex predator can increase
its predatory capacity orders of
magnitude rapidly faster than the
environment can increase its resilience
to that predatory capacity now we have a
fundamental problem this is a lion
getting a thousand times faster in a
hurry without gazelles being able to
make a mutation in adequate time and
lions eat all the gazelles and then go
extinct and so we have a situation where
technology has broken the power cemetry
that is what is necessary for the meta
stability of evolved systems and so you
see that not only is there cemetry of
power between the line and the gazelle
there's also a symmetry of power between
lions and lions and gazelles and
gazelles
the most badass lion is only you know 2x
or one and a half X more than the median
lion but if we look at putin's killing
ability or Trump's compared to yours or
mine it might be billions or trillions
of times more and the same we could say
for economic capacity and if you look at
sapiens writ large compared to the rest
of the biosphere it's similar and so
when you think about like you know one
lion just even if it went rogue and
didn't just kill to survive to start
killing everything it could it has such
limited destructive capacity and that's
not true and especially as we get into
decentralized exponential tech one actor
or a small group of actress has really
radical amplification of agency so if
you keep having rivalries agency
rivalries basis for agency but with very
high power relative to the overall
playing field you end up getting a basis
for fundamental instability and of
course it's not always all about
destruction either you know two data
points that jump out at me that we are
doing
things that we think of as constructive
that have to be getting well near our
limits are you know for instance the
fact that of the large mammals on earth
it's now thought that the majority of
the biomass is humans plus our
domesticated animals and when it comes
to birds it's even more radical it's
thought that the domesticated birds
represent 70% of the biomass of all
birds on earth and so nothing
destructive specifically destructive
about catching and killing but we've
essentially engineered a technology
which is co-opted a majority or 70% of
the energetics and biomass of the biome
and it's continuing to grow
exponentially which strikes me as a very
strong signal which is very little
talked about yeah so this is you know
kind of a limits of growth thing as
opposed to say a warfare or terrorism or
you know intentioned destructive thing
so think about this we think of apex
predators they evolved to fit a niche
and because they're adaptive capacity is
mediated through genes through concrete
pattern replicators they don't do very
well outside of that knee and so polar
bears don't leave the Arctic right and
cheetahs don't leave the savanna and
orcas don't get out of the ocean but
because our apex predator capacity was
mediated by tools and we could make
different tools including different
coverings for ourselves and in different
environments when we would overkill an
environment rather than have our
population stabilized we would just move
to a new environment to become the apex
predator there and so we went and became
apex predator everywhere over hunted and
over farmed environments everywhere over
fished etc that is really different than
every other animal and like again if we
think of the examples you were just
giving this like total biodiversity loss
and the relationship of total animal
life in domestication versus wild if you
think about an apex predator like in
Orca or a great white shark in the ocean
and how many fish it can kill in an hour
and then you think about a ocean trawler
with a mile long drift net it's just not
even like obviously we aren't apex
predators they can't destroy whole
ecosystems they also can genetically
engineer new creatures so we have to
stop modeling ourselves as apex
predators
competing with each other to be better
apex predators and take the top because
the destructive capacity even of not
intending to destruct just of intending
to extract is well beyond the replenish
rates of the system yeah and on top of
that and on our first episode with Simon
today oh we talked fair amount about the
rate of social evolution is accelerating
the rate of invention of new
technologies new capabilities is way
faster now than it was just 30 years ago
and if we're already approaching the
limits probably exceeded the sustainable
limits of our society and we have social
evolution that's going exponential and
we still have a rising world population
last I saw projected to top out 11
billion with many of those people
expecting a increase in their lifestyle
quote unquote towards the American and
European one looks like to me a
trainwreck coming at very high speed
right and so again this idea that we
didn't start over hunting an environment
and then it became harder to eat and
breed so then we came in to sustainable
population with the environment we just
moved to another environment there is
this kind of rebound effect that we see
with humans and we see it in all of
evolution right like our friend bred why
interesting we'll say if there's an
evolutionary niche it will get filled
with something right so in the similar
sense though with humans we don't have
to wait for a genetic mutation we can
have a memetic mutation to figure out
how to exploit some new niche and so
this is where we get rebound effects
where it increases in efficiency don't
lead to us being more sustainable the
environment they lead to us figuring out
how to have profitable exploits on more
area and so you know when you look at
something like the jebin's paradox or
other abstractions of it if I give a 20%
increase in energy efficiency we don't
just use 20% less energy we find whole
new markets that weren't open based on
now the what's gonna be profitable we go
exploit those and in the abusing more
net energy as a result and so when you
look at like trying to figure out a
steady-state population steady-state
population doesn't actually work
it doesn't work the way that we like to
model in evolutionary biology with the
way that humans continue to advance
increases in capacity and efficiency and
then exploit all yeah and you've spoken
quite a bit about you combine
exponentially increasing technology with
the core rival risks win-loss dynamics
of at least our economic system and a
goodly part of our social system you
talk a little bit about how the coupling
of those two together are spectacularly
different than either by itself yeah so
this is I mentioned earlier that all the
catastrophic and existential risks have
underlying generator functions what I
mean by that is that so like let's say
we're looking at wanting to stop or take
your kind of environmental destruction
or war or whatever it is well we can
look at why are those things caused and
we can find some things that seems
special to specific instances but some
things that are part of a causal set
that are true across all of them so
obviously we can look at something like
perverse incentive and so with the
environmental destruction if the wild
birds aren't worth very much to us in
the wild but domesticated ones and farms
where the farms take over the wild areas
are if cattle are worth something to us
when domesticated and then killed and
not when they're free and of course we
have an economic incentive to exploit
everything and the same would be true if
we have a for-profit military industrial
complex where war is more profitable
than pieces and so the underlying idea
here is that you can't prevent a harm
well there is a very strong incentive to
cause it because that incentive is kind
of an evolutionary niche for a
particular and way of getting ahead and
it will end up getting filled so we try
to make law to bind that but as we know
strong economic power ends up being able
to influence law pretty heavily so the
thing that is designed to bind the
problems of the incentive system ends up
getting corrupted by the incentive
system so we can get into that more
later but this is an idea of something
like perverse incentive that isn't
unique to one issue it's underneath lots
of issues so if we want to abstract and
say what are the generators that give
rise to all of the possible existential
risks in the future the first one is the
one that you just mentioned first one I
would identify is that if humans are
running rival risk games and by right
wrist games I mean some in group that is
seeking to get ahead in a way that can
occur at the expense of an out group
and/or the comments so whether that's a
person or a company or a country if it
can beat someone else via a war or it
can exploit an environment and get ahead
or it can corner the market or whatever
it is it's playing a game where it's win
is going to require or at least reserves
the right to be at the cost of something
else
if we run rival risk games but we're not
limited in our rival risk capacity the
way animals are because we can innovate
new ways of winning and rivalry via
abstraction ie tech but then the moment
we deploy some new asymmetric tech
everybody sees it reverse engineers it
makes mutations on it and so we keep
ratcheting up power then we get an
exponential power equation but we're
we're using power in ways that
inexorably cause some harm to the total
system when you you can't actually run
exponential harm in a finite playing
field and not have more entropy than the
system can handle so rivalries games
multiplied by exponential tech
self-terminate and right now exponential
tech is inexorable we cannot put the cat
back in the bag we can't stop it so
either we figure out rigorously anti
rivalry systems or the human experiment
as we know it is finite in duration but
the thing is to say rivalry systems
that's a big deal because separate
nation states are the basis of rivalry
systems and so our private balance
sheets and so the changes that we're
proposing are very very fundamental ones
they're ones at the level of the axioms
of what we think of as civilization but
that's why we have to start by saying
all previous civilizations also failed
we actually have to change things at a
deeper level right we're not talking
about just making a new civilization
where this is similar to the
Enlightenment for the Renaissance or the
founding of America or the beginning of
Sumeria it's it's actually different in
kinds in each of those changes because
each of those changes have been an
ratcheting of rival risk capacity some
new coordination capacity or
technological capacity that led to more
capacity to win rivalries games against
an out-group I'm basically saying now
humanity as a whole with no out group
has to figure out how to do
trailers games as you know I'm
interested in this and have worked on
some of it and thought about a little
bit but I'm gonna play the cheerful
skeptic here for a moment if you don't
mind and offer a possible argument that
says maybe we don't have to go that far
and again I'm not gonna say this is my
actual belief but let's say this is a
well-established argument for a less
radical approach which we might call
Democratic liberalism and you know in
passing talked about the fact that our
legal system our political system has
been hijacked by our economic and
financial systems we could in theory fix
that it may require an amendment to the
Constitution and some other things but
it could be fixed secondly the depletion
of the Commons the Democratic liberal
argument is if we priced the
externalities correctly we could defend
the Commons we also look at Ostrom
theories of managing the Commons and
those are assumed to take place in a
world with rivalries economics around
them well how would you respond to those
who say rather than changing the jet
engine on the airplane while it's in
flight we'd be better off attempting to
be smart about fixing our Democratic
liberalism by breaking the hack between
money and politics and by rigorously and
probably initially very conservatively
meaning expensively pricing
externalities I will say that that is
formally impossible and explain why but
there's a few aspects to it so well like
this we'll take a minute take us what
stop me feel like this is really
important I would start by wanting to
just be clear on the fundamental
difference between a market and a
government and the relationship between
those because what you're talking about
is a government regulating a market yes
in fact that would call that the modern
Democratic liberal synthesis that
started in the 1920s was fully in
existence by the 1930s and was locked in
in its modern form in 1948 great so what
I would say is that there are certain
architectures within markets that lead
inexorably to certain issues other
within governments and I'm gonna try and
abstract us at the most abstract level
that works which is this will be true
for any form of government whether it's
a two-party system or a three-party
system or has a parliament or doesn't do
too simply the nature of it being a
top-down imposition of law via monopoly
of force and the same is true for
whether we're talking about any
different version of how one might think
of a market so if we think of a market
you can actually think about theory of
markets like pure lays a fair theory and
try and model it via evolutionary theory
and people do and this is where social
Darwinism kind of comes right which is
these three things mutation survival
selection and then mating mating
selection are what define the success of
markets so you have an environmental
niche which here would be called demand
people need real stuff and so then that
creates a impetus to try and figure out
how to fit that niche which is supply it
will make some product or service to try
and do it but they'll make slightly
different versions that equals mutation
the one that actually meets people's
needs best of the best value is the one
that will make it through survival
selection and then if a few of them have
different properties that are all really
desirable they might mate and meaning
you know merger and acquisition or IP
trade or whatever and you get a
recombinant oriole dynamic and that's
main selection and that's the idea right
except as we mentioned that's true but
you don't get the meta stability of an
evolved system because of the a
symmetries are gonna be intrinsic to
abstract replicators that aren't
therefore instantiated replicators so if
we think about a market as a bottom-up
coordination system and bottom-up
meaning that we aren't we don't have
long term central planning of what we're
trying to do everybody's not trying to
agree on something we're just
interacting with each other via supply
and demand dynamics and stuff gets up
regulated so that basically the society
is all emergent properties of the
bottom-up interactions so that's one
kind of thing and we can really think of
as having certain characteristics of
just the bottom-up math of it one thing
I would say then and this is a critique
of libertarian ideology free-market kind
of ideology writ large
is that without regulation markets are
going to have multipolar traps that they
cannot resolve and by a multipolar trap
it's a generalization of weather it's a
tragedy of the Commons or an arms race
or any kind of race to the cliff a race
to the bottom these are scenarios where
somebody can do something that is bad
for the whole over the long term but
very good for them over the near term
and provides so much competitive
advantage that without law to bind it
people will still buy the thing they
will still be able to get employees
right like the market forces won't stop
it and so then everyone else has to
compete to do the same thing or they
will just lose by default in the short
term so now you have everybody competing
to get the cheaper material that is
comprehensively damaging the environment
or racing to cut down the trees faster
than they actually need them because if
they don't the other guy will cut down
the trees anyways or one guy makes a I
weapon so everybody has to make the AI
weapons where they're going to lose by
default
and so multipolar traps in the past when
we had limited power could lead to boom
and bust cycles where we start polluting
the water because say everybody else
isn't polluting the water my pollution
of the water doesn't make it that much
worse but not having to deal with my
pollution properly increases my margins
because I externalize some of the cost
so I'm getting ahead then other people
say it that guy's getting so much
more ahead everybody starts doing it
eventually the water is so polluted that
everybody is doing worse because the
fish are all dead so then there's now a
new market for selling water purifiers
and so we start doing that thing until
you know then there is a new scenario
for the pollution to occur so you get
these kind of best you get a race to the
bottom and then some new market
opportunity race to the top with
exponentially more people and
exponentially more power per person more
moreover you have situations where the
bottom can be so bad that it's
unrecoverable let me jump
but here you're drawing the classic 19th
century Adam Smith quasi-libertarian
model suppose though we take a more
modern social democratic perspective
where we assume it is the job of the
legal political government side as
instantiated through democracy to put
limits on the market and when I call
what I've called in the past parametric
social democracy where instead of a
bunch of fine grained regulations used a
dozen or so very powerful settings on
the gravitational attractors within the
game itself I'll just throw out two
examples which I've talked about the
past in some detail one would be a high
and rapidly rising carbon tax let's say
$50 a ton to start rising $10 a year for
15 years to $200 a ton which would send
a magnificently powerful signal to stop
using carbon would empower alternative
energy production in a very major way a
second one much simpler one of the hacks
we know that our current system does is
you psychologically informed advertising
to invent demand suppose we put a two
hundred percent tax on all advertising I
have ten more I could throw out there so
why can't a list of powerful parameters
tame the market without having to
undergo the radical shift that you're
talking about forgive me I was starting
with an unregulated market because I
wanted to establish something about
theory of the markets which is why we
can do just a libertarian thing and why
there is a good case for a regulated
market now once you then do a
construction on what's wrong with
governments and then I want to do a
construction on what's wrong with them
together because I have to refer to
what's wrong with each one individually
before I can do the combined test all
right you go right ahead okay so
basically anything that has bottom-up
coordination only but abstraction
mediated capacities like markets is
going to fall to multipolar traps
multipolar traps with exponential tech
will be catastrophic ly bad that's that
then this is at least of the story of a
major reason why we justify creating
states which is okay we don't want
everybody to cut down all of the trees
just to store them as lumber because if
they don't do
I will and were left with no trees and
yet how do we deal with this we have a
real coordination problem well we need
to create some entity that has the
ability to stop everybody from doing it
and so that entity needs some kind of
monopoly of force to be able to actually
uphold an agreement so we want something
like rule of law we want the ability to
come up with good laws and we want the
ability to enforce those laws so we
agree to bequeath to a government a
legitimate monopoly on violence which
internal is a police force without which
law doesn't actually exist right the
thing that we think of as law doesn't
exist and then externally a military
force so that the freedom for us to do
this thing is upheld against other
groups now we can say why do we create
States well one reason is to unify
groups to be able to win Wars and defend
themselves and the other is to solve
multipolar traps ie create rule of law
so that we can coordinate better and
arguably the actual reason is to
consolidate power even more but that is
not the answer that is given it when
justifying it so if we think about a
government the government is now not a
bottom-up system it's a top-down system
meaning that there is some centralized
rather than decentralized body that can
actually make choices whether it's a
monarchy or a oligarchy or democracy or
whatever so it's one person or it's a
majority of people there is some process
to be able to say okay this is the law
we're going to do and here's then how
that law will be upheld via the agency
of that central body in its monopoly
force now we can identify things that
will end up going wrong with top-down
systems and we're trying to bind the
problems associated with incentive and
yet the agents who are mediating cuz the
government isn't actually an entity in
and of itself even though it's acting
like it it's run by people who are all
still agents within the economic system
that all still have incentives
themselves to the judge and the
lobbyists and the lawyer and the
politician all still have their own
fundamentally still largely rival risk
basis for wanting increased status power
it is yeah the famous economic problem
of agency risk right every company has
that problem right every employee in
theory is out for their own good and so
they have to build structures so that at
least to a first-order approximation the
company achieved some level of good for
the shareholder so yeah this is a common
place of any social structure yeah
because the corporation is also a
top-down system like a government is and
so we can see similar issues that occur
and so this is public choice theory is
basically the critique of the wrongness
of the incentive structures of
government agents associated with
markets and it's a classic libertarian
critique of the regulatory process on
markets but so let's look like this some
examples so unless I have a fully global
government I'm gonna make a lot the
level of say about a carbon tax or
whatever at the level of us say a nation
state and if anyone doesn't make that
the nation states are still caught in a
multipolar trap with each other so I can
have multicolor trap at the level of
individuals or corporations or countries
or trading bloc's and so then anybody
doesn't do the thing and they
economically get ahead in the short term
even if what they're doing is totally
unbelievable aw on everyone else and
this would be true for things like AI
arms races this is why we tried to make
a UN after World War 2 is recognizing
that national only governments won't
stop World War so we wanted some
supranational force to be a monopoly
force for everyone except when
individual nation states have
catastrophic level capacity ie they have
nukes what we find is that there is no
monopoly of force that can be exerted
over them because to have the monopoly
force work you have to be able to exert
it so the UN can't tell a member country
that has nukes you have to get rid of
them because they're like we have nukes
 off what are you gonna do invade us
and this is one of the big problems is
that the Nopalea force only works when
you can exert it that's why it obviously
doesn't work for nuclear deep
proliferation it's why it doesn't work
for a lot of global issues but it's also
why even as a national
with the evolution or the emergence of
decentralized exponential technologies
where small groups and non-state actors
and even individuals can get
catastrophic capacity through gene
drives and drones and whatever if I have
a gene Drive pandemic type weapon
connected to a Deadman switch there is
no rule of law that can be exerted over
me and we're not that far from those
types of things being possibilities so
this represents an emergent breakdown in
the capacity for rule of law writ large
and less you run a perfected
surveillance state that doesn't allow
anyone to have capacities which is a
China strategy again I'm gonna argue
here the moderate ameliorative position
even though it may not actually be mine
let's take the example of the carbon tax
that other countries want to freeride
and defect from right which you can
easily see there being pressures to do
so free riders and defections are the
essence of game theory and at least in
my mind you're multipolar trap is slight
generalization of the concepts of
predatory game theory so there is a
personal fix whether it's enough or not
I don't know which would be to have an
implicit carbon tariff on imports so
let's say the Chinese want to defect and
not collect the carbon tax we don't
really care to the degree they don't
collect the carbon tax that we do care
but at least partially we can penalize
them by putting a tariff equal to the
implicit carbon tax that we would have
charged for the equivalent amount of
carbon in a product and in a worry
especially in countries like China and
increasingly India which are very
dependent on trade this is at least a
partial way of raising the cost quite
significantly for those who defect or
attempt to be Free Riders how would you
respond to that yeah so let's say the
u.s. agreed to do that but then let's
say Brazil under its new presidency says
 that all buy the stuff from China
and they have some capacity to and say
Russia does say some other places do
China is still growing in its GDP
externalizing cost and those other
places are and now we're losing relative
to them now you get increasing citizen
pressure to revoke that law so this is
again the essence of a coordination
problem from the view of it
make sense if we all did the good thing
right in the prisoner's dilemma if we
all coordinated would be good but if we
don't have the capacity to ensure the
coordination anyone can defect it
becomes very easy to have the strange
attractor be everybody default to
defection yeah the answer the prisoner's
dilemma as we all know is you have Tony
Soprano right that if you defect I'll
kill ya yeah which is basically you know
some kind of even worse punishment than
the original thing was its outside of
the scenario and that ends up being how
we do it right which is underneath our
tariff situation we're willing to go to
war to uphold a lot of these things but
now let's come back to even within a
country so we know that right now
someone's ability to get elected has to
do with largely their access to not just
capital but also a lie ship so that's
going to affect how other
representatives support them and how
much they can do campaigning and media
they can get and all those kinds of
things and we know that we don't have an
educated citizenry and so you have a
situation where people are going to get
elected proportional to really the
incentives of the system more than
anything else and because people can say
stuff that isn't true and people still
believe it and they can do Russell
conjugations to give people the wrong
sense of things and appeal to emotional
triggers and in-group defection dynamics
and stuff like that so let's say that we
try to make a law then of course
everyone who has financial interest that
would be damaged by that law supports
the other candidate so then we have to
do something like campaign finance
reform but who is gonna bring the
campaign finance reform through this
isn't of being one of the key things is
that the lobbyists are paid for by
somebody the people who are working to
change the laws continuously are paid
for by somebody and whoever it is that
would the ability to get money to
someone who is campaigning also is very
easy to hide through offshore banking
and through third party entities and
think tanks and whatever so because we
don't have something like perfected
transparent accounting if
tried to bind incentive using law
everyone who has the incentive to change
that law has more resources than those
that are trying to bind it and they end
up basically winning and the gist there
is that economics is deeper than law is
in the stack of power and so you can use
law to bind economics to a limited
degree but let's say again the company a
country tries to put some law forth it's
particularly bad for a multinational
company the multinational company says
I'll move headquarters to another
country that doesn't do that I'll give
them the taxes rather than you guys and
we will you know support whoever is
campaigning against you and we'll put a
 ton of lobbyists on changing the
law this is all the critique of public
choice theory is that the incentive of
the agents in the system doesn't align
with the well-being of the whole and the
government is mediated by agents in the
system and we don't have the right
coordination dynamic so each actor doing
kind of a utility maximization function
each actor doing what makes the most
sense for them in the near term
rationally creates a maximally stupid
whole because of the misalignment in
agency of the various actors and the
inability to coordinate effectively
across them and this gets worse with the
more we can corrupt accounting the more
we can actually hide that these things
are occurring and the larger the system
is the easier it is to do that because
who can actually monitor all of the
things that are happening in the system
actually a lot of this was prefigured
and talked about in a very
underappreciated book by Mansur Olson
called the logic of collective action I
don't know if you ever read that if you
haven't I would strongly recommend it
he's more well known for the it's the
rise and decline of nations but the
deeper book is the logic of collective
action really as it lays out the fact
that strong small groups that have a
strong interest in an issue are very
likely to dominate against a much
broader community to have small levels
of skin in the game and it you know it's
a pretty strong critique and it does
exactly public choice but it's close
that's okay let's deem that it's both
who has the most incentive we'll work
hardest and smaller groups can
coordinate better than larger groups and
this is why if I had two groups two
countries say they had an equal number
of people in an equal number of total
dollars to begin with and one of them
tried to create a law that bound
economic inequality so the richest
person couldn't have more than 10x more
than the poorest person the group that
didn't bind economic inequality would
win over the group that did in any form
of warfare if the group was fairly large
because if you end up getting a
power-law distribution of wealth where
three guys own almost everything and
everybody works for them the one guy who
has almost all the resource can
coordinate with himself better than the
million people can coordinate with each
other at least so far and I think
there's an interesting possibility to
think about what comes next you know
really all these are coordination and
signaling problems right and we are
operating on a single relatively low
dimensional signaling and coordination
system that has given rise to the system
that we have today what I often call the
money on money return signal right molds
our world so presumably if we're gonna
get past this we have to think about
multi-dimensional signaling and
multi-dimensional coordination this is
exactly the centre of what I'm focused
on is that the problem is fundamentally
the inability to coordinate between
agents where their basis for agency
intrinsically has Delta's right there's
a what's best for me in the current
system of a private balance sheet and
money and those types of things which
best for me is not what's best for you
and best for the comments even though it
would be over the long term over the
short term it doesn't seem to be and so
everyone is doing utility maximization
functions but with again unlike
evolution with asymmetric power relative
to the environment and supply-side
relative to demand side and things like
that and this then ends up creating a
situation where it gets worse like this
actually very important point if I have
true information about the nature of
reality that is a source of strategic
competitive information so I want to
withhold that information we call this a
trade secret or classified or
confidential information or intellectual
property but I don't just want to
withhold that I also want to make sure
to throw anyone else that would figure
it out off the scent trail so I want to
do not just withholding of information
with disinformation and we have a
situation where everyone is incentive to
do withholding of true information and
signaling of disinformation and then we
have information technology that's
exponential information technology where
I can do customized disinformation for
different persona types and all the way
down to individuals we get to a world
where we stop being able to parse signal
from noise because there's so much
radical disinformation and we have a
situation where a coordination actually
becomes impossible because of these
agency issues everywhere it's supposed
to be the two different intelligence
agencies within a country perfectly
coordinate with each other to support
that country because they're all on team
country right Team USA against the
Russians and the Chinese whatever but
really those two different intelligence
agencies are also competing against each
other for a larger percentage of the
budget and then even to different
departments within that organization and
even to different people competing for
the same promotion will withhold
information and maybe even dis inform
engage in corporate politics corporate
politics is where someone's optimizing
their own bonus structure and their
fealty relationships at the expense of
what's actually good for the whole
because they're not actually coupled to
the whole effectively and so you get a
situation of fractal defection everybody
defecting on everyone to some degree
while signaling that they're not doing
that and this basically means a
catastrophic breakdown in the sense
making necessary to make good choices
while having an exponentially increased
amount of choice making power and if we
think about that exponentially
decreasing quality of sense making
relative to the overall situation with
exponentially increasing choice making
power that's another way to think about
inevitable collapse yes certainly recent
evolutions in our information
infrastructure have raised even higher
the power of bad faith discourse and
there's nothing else it's very
substantially reduced the cost of bad
faith discourse right and if we talk
about
as we often do in our world sense making
the idea of sense making and then the
bigger issue of choice making in a world
of predatory disinformation and bad
faith discourse leaves us in a very
dangerous situation yeah exactly that is
the central thing for us to solve all
right let's stipulate now that there's
no way out within the present game what
do you suggest we do next
okay so I would say that the
consideration that rival risk games are
necessarily causing harm to some other
agent or to the Commons but that's when
they are multiplied by the leverage of
technology that that harm becomes larger
than the ecosystem can handle if we take
that as one generator function of X risk
we know we have to have a situation that
creates an anti rival risk basis for
coordination that is necessary but not
sufficient there are a couple other
generator functions of X risk that we
also have to address because we can show
that all of the catastrophic risk this
would take longer to do than we have but
we can show that all the environmental
degradation issues pollution issues dead
zones and ocean ocean acidification
biodiversity loss species loss climate
change all of those issues all of the
what would cause world war three or
large-scale war and all the exponential
techne da 'td issues like gray goo or
AGI scenarios or biotech scenarios and
all the things that would cause collapse
grid collapse economic collapse that all
of those have a few generator functions
in common and we could actually do a
construction where we put forward these
three generator functions and prove that
set is actually some some t'v that there
are no risks that are not a result of
those things so then coming up with a
solution to those things is solving for
the class of what creates all of them
rather than instances that becomes the
kernel of a new civilization system and
we can say is both necessary and
sufficient requirements for a non-self
terminating civilization so complicated
systems subsuming their complex
substrate increased fragility and
evolved systems not the technology
systems we talked already about
evolution
being different because of the nature of
the metastability of evolved systems we
get antifragility so if I burn a forest
it will regenerate itself if I cut my
body it will heal itself if I damage my
laptop it won't heal itself I burn my
house down it won't heal itself so
humans take the antifragility of the
natural world and turn it into fragile
stuff we turn it into simple and then
complicated stuff so we turn a tree
that's anti fragile and complex into a
2x4 that is simple and then a house that
is complicated but both fragile but we
don't stop at a certain place we
basically have complicated systems
subsume the complex system so we're
creating an increasingly higher
fragility to antifragility ratio that
we're then trying to run exponentially
more energy through an exponentially
increasingly fragile system and this is
a way of thinking about what Tainter
said in the collapse of complex
societies which is the relationship
between the complex and the complicated
as we continue to grow the
complicatedness of the scenario ends up
breaking down and so it's important to
know humans only know how to build
complicated stuff we don't actually know
how to build complex stuff and we also
don't know how to limit our growth
that's what I was saying whenever
there's an increase in efficiency we
just exploit more stuff so this is
another kind of generator function is a
we both have to learn how to build stuff
that is either anti fragile itself or in
a fundamentally different kind of well
to some degree we have to build stuff
that's more anti fragile and we have to
not exploit all exploitable areas and so
this is really different than everything
we have ever done this is kind of one
way of speaking about it the other thing
that we can say is a generator function
of X risk is that it's much easier to
break stuff than it is to build new
stuff just from a kind of entropy or
thermodynamic perspective second law of
thermodynamics the one law that you
can't repeat all right and so from a
information theoretic perspective on the
second law one way I would say it is the
problem I'm interested in solving is
that the way humans solve problems tends
to create worse problems so whether
we're talking about us coming up with a
and logical solution or a government
solution or a kind of social ideology
solution or an economic solution for the
solution to solve the problem that means
it overtakes the problem the solution
has to be larger faster somehow bigger
than the problem was but the solution
typically is to solve a very narrowly
defined problem so we're defining a
solving one metric or two or three
metrics and yet it's gonna interact with
complex systems that affect lots of
other metrics where we'll end up having
harm externality but there will be
larger than the original thing so the
plow solved the problem of local famines
but ended up causing desertification and
species extinction and all these things
writ large globally right the internal
combustion engine solved the problem of
too much horseshit in the cities and the
difficulty of horses but climate change
and oil spills and wars over oil and the
destabilization of the Middle East are
all the unintended externalities of the
internal combustion engine
and we can see the same for like the
value of Facebook then compared to the
unintended externalities it created or
Twitter or whatever it is and so in
general it's because I can define a
problem in a narrow way but that's
actually not the problem right that's a
little part of it and this is the same
with biotech right it which is I can say
the problem is one biometric that I'm
trying to address LDL or whatever it is
and I can give something that lowers
that but it might also do a bunch of
other things that are negative which are
the side effects of that thing in the
overall system which is why that
approach is not a really good approach
to medicine and so to formalize this
even further what we can say is that the
information and the computation the
information processing that it takes to
come up with a new piece of tech is
orders of magnitude less than the
information processing it takes to
ensure that that tech won't have any
externality in its long-term application
and it's not just orders of magnitude we
can say that the safety analysis is
gonna end up being np-hard relative to
the work that it takes to come up with
the tech being expressible as a
polynomial yes that's absolutely right
one of the things I've learned in my 17
years of rolling around in complex
system Sciences the truth of the matter
is the ability to project the future
evolution of a
complex system is way less than most
people think if only for the very simple
reason of dependency on initial
conditions we know from the very simple
Lorenz Ian strange attractors that
surprisingly simple systems are
effectively impossible to predict
because they're highly dependent on very
small differences in initial conditions
and when you add into that strategic
agents the problem becomes I would say
effectively impossible so what's the
answer that basically says don't ever do
anything yet we can't do that and this
is the tricky thing so this is kind of
why I say there's a something like a
hard fork hypothesis which is if you
look at the history of humans the
recorded history that we have at least
nobody would consider us very good
stewards of power we've used our power
to do some lovely things and we've also
used our power to torture and oppress
and kill and destroy environments and
whatever and everybody's done that and
the few that didn't do it got killed in
war by those who did do it and so let's
say there's a Gaussian distribution on
the goodness or badness of our choices
the rivalry or non-rivalry of how we use
our power if we have beings that are at
all like the beings we have been for a
long time and you exponentially increase
the power of those choices itself
terminates so you can't get the power of
gods without the love and wisdom and
prudence of gods to guide it and have
that be a sustainable scenario so we
actually need humans to be safer vessels
for power given the amount of power that
we're coming into and we have no idea
how to do that and what that means is we
need a different basis for human choice
making than we've ever had to have the
level of choice making power that
exponential tech is bringing about and
so then we have to really get into well
why is it the humans are making the
choices that they do and what is it that
is conditioning the rival risk basis of
those choices to basically have us suck
with choices yes so we can talk about
what are some systems that we could
suggest get there but I would say that's
the core of the thing that we're trying
to address is how do we create a system
in which any agents that are making
choices are making choices that are not
directly causing or indirectly causing
harm to the system because that leads to
the
ratcheting of others doing that and that
leads to self-determination and we're
too powerful to do that so how do we get
something like on the consideration of
the agents leading to any positivity of
choice making sounds nice but how do we
do it in a world where with the ability
to project in a complex systems
environment the impact of any change is
well nigh impossible I would also add
another thing I'd love to hear your
thoughts on this one of the things we
know from human anthropology is in
essentially every society on earth
somewhere between 1/2 of 1% and 2% of
humans are sociopaths right and I'd had
in my experience as a corporate
executive that that number may go up to
10% or more in the c-level Suites and
probably higher than that in the world
of finance so we have this problem how
do we evaluate the impact of a proposed
change in a complex system which is
inherently not very predictable a little
bit predictable but we lose our ability
to see quickly and that some noticeable
percent of the actors you say 1% of
sociopaths doesn't sound that bad that
means in the United States there's 3
million sociopaths right and they
gravitate towards power and a lot of
them are pretty damn good at
manipulating people how do we get across
those two traps yeah if I look at all of
the cluster B personality disorders in
the current DSM I would say they're all
pretty concerning so you know not just
to see Apogee but narcissism and etc but
the most current stats I have seen were
3 to 5 percent of the general population
in the developed world tests for
sociopathy and 30 percent of people in
the c-suite of fortune 500 companies I'm
gonna share a thought on this that I
don't have all the data to back up but I
don't think would be hard to come up
with so why do we get so much
concentration of sociopathy in the top
of fortune 500 companies and politics
and then especially things like finance
well because they're basically systems
to attract reward incentivize and
condition sociopathy because to get to
the top
the power game it's going to be people
who are attracted to power and people
who are good at winning a bunch of
win-lose games because at each step they
move up the ladder they're winning
against somebody else usually the
involving things like disinformation and
defection and whatever it is and so if
you think about the nature of what a
government or a corporation or any
top-down power system are it is
basically a strange attractor for people
who want to have power over for people
who are running power dynamics and this
is why you know let's try and save that
I have a benevolent dictator well
there's a reason that we don't get
sustainable benevolent dictators is
because let's say I have a benevolent
dictator and we can get this in a
corporation from great founder Theory
sometimes because if the founder holds
the you know majority of stock in
whatever but it never out lives them and
usually they end up getting kicked out
so let's say I have a benevolent
dictator all the people who are one step
under them are doing things that they
require to be able to stay as a dictator
because it's pretty easy to kill
somebody or to oust them or whatever so
if I'm at the top of a top-down power
system I have to keep everybody under me
preferring me to be above them rather
than overthrow me which means that
rather than do what's best for everybody
I have to do what's best largely for
those who are right near me and they
have to do that for those who are under
them and that ensures a kind of power
law distribution of power and again
there's like a multipolar trap on
corruption if anyone's willing to do a
really up thing to try and
overthrow me I have to be able to play
at the game of up things where I
get overthrown so we can see how
top-down power systems are going to both
attract condition reward incentivize
things like sociopathy and so then we
end up having a world run by sociopaths
which is not a good thing for anybody
but now let's think about something like
a tribe and I'm not gonna over
romanticize here I'm just kind of
thinking through the dynamics in a first
principles way if I've got 40 50 70 up
to
our number of people living in a tribe
there's an extraordinarily high degree
of transparency that is forced in that
scenario everybody pretty much sees
everything that's going on with
everybody and everybody knows everyone
everyone has fealty relationships with
everybody in the tribe so sociopathy is
not gonna be advantageous you're not
going to have an evolutionary niche in
that environment for much in the way of
conspiring and lying because it will get
found out and it will get punished and
so the forced transparency creates an
accounting system where you don't get an
evolutionary niche for somebody
the other people in the system and so as
soon as the system starts to get large
enough then one there's anonymous people
so I can harm people who I don't really
know and care about as opposed to
everybody who is in the system as
somebody that I know and care about and
two I can do stuff that people won't be
able to see they can kind of have a
corruption of the accounting in the
system now we get an evolutionary niche
for rather than participating with the
system doing internal defection I'm not
externally defecting and leaving the
system I'm internally defecting and
playing the system and that's what most
everyone inside of a corporation or a
government is optimizing what is good
for them and their direct fealty
relationships rather than what's good
for the whole and nobody can tell and
this is a particularly hard scenario but
the reason I'm saying this is because we
do our social science inside of a world
where these systems have become a Bic
with us and then we assume that those
properties where there's ubiquitous
conditioning are intrinsic to human
nature and I think we have to be very
careful about that I think a lot of them
are not intrinsic to human nature they
are a result of the ubiquitous
conditioning and we could create
conditioning environments in which
things like sociopathy are just not
advantageous and so they don't get up
regulated the answer probably just seem
to find sociopaths the varying ratios
that they find them at a least half a
percent ratio pretty much every place
and in fact I've thrown a challenge out
some anthropologist so they've not been
able to reject it one of the big
questions and anthropology is how did
human society transition from chiefdoms
to early States and
my conjecture has been that it's based
on the arrival of a sufficiently
charismatic sociopath and that's the
story right and they've pulled their
beards and that's an interesting theory
here's even some ways to measure it so I
think if we're gonna design a social
operating system we're gonna have to
assume some levels sociopathy and have
some defense mechanisms for saying well
so let's go ahead and do the analogy and
say that sociopathy within a social body
is like a cancer cell inside of a animal
body which is not cancer cells inside of
a human body are doing something that is
good for them and good for the other
cells around and good for the whole
simultaneously and they have an evolved
coordination system to be not in rival
risk dynamic with each other the heart
and the lungs are not rivalries with
each other they're not competing to
extract scarce resource and order
they're in this you know kind of
radically necessarily symbiotic
relationship now a cancer cell realizes
that it can actually consume and
reproduce faster if it defects on the
agreement and that happens all the time
but that cancer cell is only able to
affect the cells immediately around it
and so then they're able to either fix
the cell or kill it and limit its
effective action if the cancer cell
could broadcast uncle genes to all cells
in the body simultaneously because it
had something like technology to be able
to leverage what it wanted to do we'd be
 and so when we think about the
world today and the capacity that
exponential technology gives for anyone
to have a much stronger coupling to the
whole system not mediated through having
to have that flow through a bunch of
other agents where error correction can
occur this is one of the things that's
really problematic with the world today
is it's even small numbers of people
that become sadistic sociopathic
whatever can really the whole
system up and so you actually have to
have something that creates
antifragility for this particular thing
and so we can say to have a system that
doesn't have catastrophic collapses
eminence it has to be able to limit this
and one way of doing it is the China
strategy which is a bit of surveillance
and anyone does anything that looks at
all concerning and there
hours removed from them and I would
argue that that system will also
inexorably collapse because even though
it won't collapse because of multipolar
traps it'll collapse because we noticed
that markets are much better at
innovation bottom-up processes are much
better at innovation than top-down
processes tend to be if you control the
bottom-up processes that rigorously you
won't end up being able to innovate
enough to keep up with changing
environments and you'll fail too Red
Queen dynamics that's my prediction for
the China strategy but what I would say
is that a tribe is actually like a
family and a tribe or a village is
actually a really good method for being
able to do surveillance and I mean a
very healthy rather than a up
type of surveillance it's not a top-down
one-to-many surveillance
it's a many-to-many and where the goal
does not prevent someone from doing bad
things but actually caring about people
and so rather than the sesame credit
version or the Institute a religious
idea where everyone shames everyone out
of fear of God version this is a have a
situation where no one can actually be a
shut-in right we noticed that when
somebody goes and shoots a bunch of
people up with ar-15 typically they
weren't in interaction with a lot of
other humans they were able to because
of modern society they were able to live
for a while where afterwards and
interviews their neighbors say we never
saw him he was real quiet he kept to
himself he never came out as we have
increasing technological capacity to
agents we can't have agents that can
evolve in their psychopathology
unchecked we also can't have situations
where they are interacting that they can
hide the results so we need something
like both real accounting of what's
happening and everyone having to
interact with other people in local ways
that ensure the health of people and if
not actually take care of them so that's
one of the first things I can talk about
is that as long as the defect on the
whole is more advantageous just two
things one is as long as the defect on
the whole is more advantageous than
participate with it it will happen and
so you have to have the kinds of
accounting that keep that from occurring
and the other thing is as long as
individuals can
become psychologically damaged and have
that not be noticed and still have
access to power that's also a problem so
there is a process by which the
psychologic health of people has to be
noticed and the process by which the
social system has to be more
advantageous to participate with and to
defect against you have some ideas and
how we might structure this sound like a
cell network essentially where people
are assembled at the Dunbar number or
below in an intense solid way and
presumably with minimal ability to
migrate because we all know that the
stranger in town is a much riskier
character than the person's that's been
around for 30 years talk a little bit
about how that might actually be
accomplished I am gonna go somewhere
that's gonna be really bothersome I
don't know of any model where that's
accomplishable as long as there's
private property okay we certainly have
alternatives such as syndicalism which
is quasi private property but not in the
same sense we have here and then there's
an RG which is another similar model so
I don't think we have to keep private
property on the table so I would
entertain any proposal that you think
could implement this theory
I think if organs believed that they
could live at the expense of the other
ones and that a famine might come so
they needed to hoard resource because
they wouldn't be able to get it from
other ones and they were actually in
competition for scarce resource we'd be
 right the body would break down
very very quickly and so you don't see
the coordination dynamics of cells or
organs or tissues involving something
like private property you have a
situation where things are stored
wherever they're stored the calcium
stored in the bones fat cells are so
really they are for the utilization by
any part of the system that needs it as
it's needed so you don't have a
situation where any cell or organ has a
Delta between what's good for it and
what's good for the whole cuz it depends
upon the rest of the whole I do believe
that we have to create a similar thing
in the human systems and specifically my
ability to increase my own private
property ownership my own balance sheet
increases my quality of life not only
can ID couple that from you or the
Commons I can ante couple it I can
directly the Commons or you
and get ahead in that way
that becomes the basis for misaligned
agency and I think we assume that basis
for misaligned agency kind of across the
board and of course I'm not going to
present something like Marxism but I
think if you actually study something
like how the resource provisioning of
something like a Body Works
it is obviously neither socialism or
Marxism or capitalism it's a much more
complex system with different underlying
axioms and so let's say that rather than
you possess a good in order to have
access to it your capacity to access it
is to be a possession but your
possession means that I no longer have
access to it and the scarce or something
is the more value we give to it so then
we also have a incentive to create
artificial scarcity because abundance
makes the stuff not worth anything and
you also then have an incentive to
possess more stuff than you need
especially when you get compounding
returns on the stuff that you have so
your incentive is to extract as much it
is possible to drive scarcity in the
system to hoard information to cause
disinformation all of those things
associated with the private ownership
type advantages so then anything that
you own that I no longer have access to
I'm not stoked on you owning stuff right
I'm actually don't want you to own the
stuff I want to own the stuff if instead
you have access to something that is
part of a common wealth resource where
your access doesn't remove my access via
possession like shopping carts at the
grocery store because there is enough of
them for peak-time everybody doesn't
have to bring their own shopping cart
which would be a pain in the ass take a
lot more resources and you know
obviously be more difficult so you
having access to smother me a dog
doesn't live in my access we start to
say how many places could this be the
case and we see that with the sharing
economy we could replace transportation
comprehensively with common wealth
shared resources rather than possessed
resources have just enough for peak time
plus maintenance which would be
something like a twentieth of the total
number that are there now have them be
higher quality for everybody and
obviously lower accidents higher quality
much lower cost to civilization because
you don't have a bunch of grotesque
duplication and you don't have
having to go to marketing budgets and
financial services it just goes to
product developments you don't have
designed in obsolescence you have
modular upgrade ability built right into
the system so you can see a much higher
quality of life for everyone with a much
lower load on the system and you also
then remove the destructive competitive
dynamics in doing so now let's say that
rather than have a central company like
an uber whatever mediating that which
now still has a misalignment of agency
we use something like a blockchain type
system to be able to make that actually
a common wealth resource where the money
that would be extracted from the system
doesn't need to be extracted from the
system you start to see oh we could
actually create things that are like
Commonwealth access based dynamics were
you having access doesn't decrease my
access that it's actually better than
that that would just be non rival risk
rival risks is your access mediated
through possession decreases mind so
 you
rival risk is an T coupled your
well-being and mine are actually ante
coupled non-rival risk is just uncoupled
which all argue is not strong enough
ante rival risk is rigorously positively
coupled your well-being in mind go up
and down together so in a situation
where you have access to the
transportation and access to other
Commonwealth resources it actually
increases your capacity to be creative
now you can also get to the maker studio
into the art studio to make art and
music and your motive isn't to get money
by selling the art because you already
have access to all the things that money
would normally give you so getting stuff
doesn't confer advantage and also
doesn't grant identity your identity is
now only gonna come not through what you
get out of the system but by what you
create and contribute to the system and
we don't get the same zero-sum dynamics
on contribution to a system through
creativity as you do through getting
stuff because it's much harder to
compare a Salvador Dali and an MC Escher
than it is dollars and dollars right the
creativity ins of being non fungible
yeah very high-dimensional right and so
now if I have a system where if you
don't get stuff you die and then if you
don't get stuff you don't breed and then
if you don't get stuff you don't self
actualized at every level of Maslow's
hierarchy you have to get stuff and
you're getting stuff involves other
people not having stuff that's the best
way to condition greed jealousy and
sociopathy and everybody
and then call it human nature if I have
a situation in which having access to
those things is a given and it's utterly
boring and the only way that you
actually have self-actualization is
through that you create
but as other people are more creative
the Commonwealth that you live in is
better and you actually have access to
more stuff then you both have a much
better basis for real creativity that's
one master not two masters and you're
also incentive to support everyone else
to sell factorize because your life is
directly better when they do so in a
world where you have access to the
transportation and the maker studios and
whatever then I get a listen to better
music and have access to better so
this is one part of it is how we move
from rival risks through non rival risk
to anti rival risks is we have to have
situations where we are actually
coupling our incentive and our agency
rather than having it ante coupled and
so there's much more to say about it but
this is one example now here's the key
part I will buy that this would be great
if we could do it in fact Jordan green
Hall and I and some other folks cooked
up fairly naive political program
several years ago and we identified
maximizing self-actualization as the
highest goal and we weren't as
structured as this thinking but we had
some things that were moving in this
direction which eventually became a
concept called game B but game B at that
point at least failed because it
couldn't convince any of us or at least
that critical mass of us that there was
a reasonable way to get from here to
there you know the current system is
pretty damn optimized for doing what it
does and how do you get people to switch
from the current activities that they're
engaged in which are relatively
economically optimized to this new
alternative system that's the hard
question and I would put to you that
that transition from game a to game B is
the part that so far many of us have
never seen a reasonable path yeah so
first I think an adequate blueprint for
game B has to become clear and so we
have to say that we have a set of
architectures that mean necessary and
sufficient criteria otherwise
know how to reverse engineer then yes
there has to be an implementation path
first I want to say that I don't think
the current system is close to
economically optimized and this actually
a very important point let's say that
I'm one of the richest people in the
world today and Bill Gates or Warren
Buffett or whatever there's really
important stuff that the world could
produce that it can't inside of
capitalism that I don't have access to
and this is actually kind of everywhere
and it's really basic the best phone the
science could make involve some
intellectual property owned by Apple and
some owned by Google and some owned by a
few different companies and the same is
true with the best laptop in the best
car and even with ilion's of dollars I
can't buy that thing and all the things
that I can buy are produced by someone
where not only do they have limited IP
but they also have whatever designed and
obsolescence and desire for proprietary
stuff so you use the rest of their
ecosystem stuff so it's not
interoperable I have to deal with that
shitty sub optimality even from the
richest guy in the world
goddamn apples the perfect example right
at one level they have some beautiful
engineering nice integration but on the
other side they're you they're
 you the at you all the time
right it's amazing
 you and the environment and
people and all kinds of things right and
so then I go to things like okay let's
take a look at and this might be more
controversial but I don't think it
should be let's take a look at biotech
and health research there's a whole
bunch of that makes sense to
research where there's just no money to
research it so we did so much work in
small molecules because they were
patentable and it was really critical
they were patentable because if I had to
go through FDA trials that cost a
billion dollars and I needed to make
that money back I had to be able to have
the patent on the thing so that people
couldn't undercut me just on cost of
goods so we were only gonna research it
was patentable the patentable stuff was
only gonna be synthetic stuff because
you don't want people to be able to
patent intrinsic parts of humans or
nature so that means that anything that
was a part of how my body worked when I
was healthy doesn't get to be something
I do research on because I won't be able
to ever make the money on that research
and a synthetic molecule that wasn't
part of the evolutionary environment it
wasn't part of how my body worked when
it was healthy it doesn't even make
sense that that would actually be a real
cure and that's the only shortened
research and of course I live in a world
where war is more likely in the
environment as factual reasons that even
from the richest person in the world I
can't control and where near-term
catastrophic risk affects everybody
including me so I think today even the
wealthiest people if they are willing to
think about it can recognize that the
world that we are discussing if it was
possible as comprehensively better for
them and the current world is the mature
I believe that but I try to sell that to
Peter Thiel yeah so I won't name names
but I have had conversations like this
with many people of that class and both
in the face of the inexorability of
catastrophic risk and the incapacity for
this system to produce some really
important stuff and they would care
about a lot of people are increasingly
capable of recognizing that they just
don't feel like they know how to
initiate the new system either well
that's good news actually and of course
you know I think ecocide is at now
becoming the forcing function anyone who
is really thinking seriously about this
stuff has to realize that we are have
either already overshot or are about to
overshot the carrying capacity of the
earth and that alone ought to be a
pretty strong argument to go on a
different road but as we talked about
before people are locked into these
rival risk structures and their fractal
in their nature they're a goodly amount
of their self definition is about where
they sit in this complex multi-leveled
pecking order that's a big lift to get
three hundred and thirty million
Americans let alone a billion people in
the world to retreat from the game a
hierarchical fractal structure and move
towards something else yeah everyone is
stuck in a kind of multipolar trap
regarding incapacity to coordinate
better because let's say I got a
billionaire and they say okay well that
makes sense but I have no idea how to
build a new system and I have no idea
how to get people to participate with a
new system and as long as other people
are doing the thing then it doesn't
seem like there is any other game for me
to play it's kind of like there is
really only one game in town so if we
can even take like let's say kilo and
musk as an interesting example where
okay argue
one of the highest agency people in the
world currently right and after he came
across boström stuff he became very
concerned about existential risk from
AGI created open ai to work on it and
then when you saw him on Joe Rogan a few
months ago he was saying I spent years
trying to get the world to understand
this AGI issue and to create different
you know safety protocols and their own
incentive to be their first first mover
advantage whatever is such that I can't
do anything about it and I basically
have kind of given up on being able to
protect against this risk and all we can
do now is just hope that the risk isn't
terrible and try to mitigate it so if
even the most agentic powerful people
feel like they actually don't have the
capacity to do anything in the presence
of you know multipolar trap type dynamic
since like alright how do you do it this
is the transition question well one
thing is the what is the new thing you
transition to has never been adequately
specified so we have to be able to
specify something that meets the
solution to these generator functions
and again that's a longer conversation
but we could go further we're starting
to lay some of the ground work and as
far as transition goes I'll share one
example of a way to think about it I'm
not saying this is how it will happen
I'm saying this at least provides a
thought experiment first there is no
such thing as sustained competitive
advantage from a single innovation
because if I have an innovation whether
it's better extraction tech or economic
tech or social tech or warfare tech the
moment I deploy that capacity then
everyone else will see it
reverse-engineer it you know make their
own kind of innovations on it and so
sustained competitive advantage is an
ongoing innovation competition which is
the up ratcheting of rival risk power
which is the dynamic that we're looking
at here and so there's this question
most people get stuck in which is like
okay well the current system seems to be
self terminating so if we need to make a
new system that outcompetes this system
what source of asymmetric advantage over
the current system is it gonna have and
how does that not just is that not just
part of the same power game because
we're used to thinking in terms of
outcompetes
and so like if you think historically
that there were less violent cultures
that invested less in military and more
in quality of life Arts and Sciences and
humanity and lived in more
harmony with the environment and lower
population they just got slaughtered by
the warring cultures and then when the
warring cultures intersected the most
successful one subsumed these successful
parts of the other one and there was
this basically distillation of
successful warfare capacity then we're
like okay well we don't want to try and
beat Tibet in the presence of China
again or any of those scenarios so I
can't make some nonviolent thing that
will simply just get killed and yet
whatever else I create if that isn't the
case seems like it's still just
competing at the game of power so
what is the option so there's a question
of what could provide increased capacity
that can't be weaponized that's a very
interesting question we could say that
every technology that increases capacity
can be weaponized meaning can be used by
some agent to increase their capacity
relative to other agents or the commons
except if we had a social technology
that was anti rival risks but it
actually produced increased coordination
capacity you actually can't weaponize it
because it is the solvent for weapon
ization itself it is actually the basis
of how agents interact in a way that
doesn't incentivize weapons and so for
anyone to instantiate that thing they
are actually changing the nature of
their agency so in the current system
again private balance sheet I'm in a big
corporation I'm gonna do the thing that
optimizes my bonus structure and my
status and the company even if it
other people in the company and the
company as a whole and that might
include spreading disinformation
withholding information etc well let's
say I could create a situation where I
couldn't get ahead of the expense of the
whole so I had both the right kind of
transparency and accounting systems and
access to Commonwealth resources where
only as the Commonwealth does better do
I do better and things like that then we
can have a situation where no one let's
just say if we could invent a situation
in which no one had an actual incentive
to spread disinformation or to hoard
information if they shared true and
maybe they'd be wrong but they at least
had the incentive for full earnestness
and full transparency if you had a
situation where that was the incentive
you figured out how to do that and I
will say there is a way to do that I
believe there's a way to do that then
you would get a situation where you had
an information ecology that was actually
intact at a larger scale that would lead
to radically better capacity to
coordinate and innovate better since
making the current system has in that
system as a whole would be more
effective at producing all of the
metrics that matter relative to total
resource per capita than any current
system would be and I only need a small
number of people relatively small number
of people who get that and want to
instantiate it as a new full stack
civilization to create a new strange
attractor or a new attractor Basin where
anyone else looking at it says well
quality of life is higher on every
metric there and they're also able to
innovate us on a bunch of things they're
figuring out solutions to that we
don't have well then why don't we just
kill them well because they aren't
trying to win the game of power against
us they aren't building militaries or
signaling or narrative warfare to try
and beat us and actually they're
exporting solutions to us that we need
to the rest of the world because if they
have increased capacity to innovate and
solve problems because they can actually
coordinate better because they don't
have disinformation information
withholding then they can look at what
groups that would otherwise have enmity
with them actually need develop those
solutions and create dependents rather
than enmity relationships while
simultaneously saying if you want to
know how to do this as well we've
actually open sourced it it's a social
technology you're welcome to use the
social technology but the social
technology will fundamentally change
your basis for agency if you employ it
so obviously there's a million things we
would need to dig into there but just
the thought experiment goes fast the
doctors build a new ground-up system
where the new ground-up system becomes a
new attractive Basin and you know that's
a way of thinking about that I don't try
and if I have to shift at the level of
axioms I can't retrofit
current system I have to build something
but if the thing that I build is
fundamentally more attractive ground up
then I only need fast adopters to
understand it in concept to have medium
adopters understand that after seeing
its implementation I really like that
and in fact when you were talking about
the lack of sustainable competitive
advantage from any single innovation I
was thinking there's a soft counter
example it's not good forever but it's
what we call network effects right and
if we spend what you just said a little
bit suppose we were able to create a
strong beneficial Network effect to
people who played by positive generative
rules and did so in a way that was not
directly threatening back to people who
didn't play by the rules but because
these people were better sense makers
and choice makers they actually could
create things to trade back to people
who aren't on the network and of course
as we know the early adopter a types
will come and join the network and once
it's proven to be more successful per
unit of human effort at both well being
but also importantly actual creation the
next layer of people will come in if
only to hang out with the A's and then
you make that as you said I think this
was the brilliant part that I hadn't
thought of before you make the ground
rules such that anyone who becomes a
member has essentially committed to a
doctrine which is subversive of the
previous paradigm but in a subtle way
not directly challenging at just a value
orientation and a set of rules for
dealing with each other and this again
gets very much back to the original
naive spirit of game B where one of the
things we did was gave ourselves all the
title of peer we always said that when
you're dealing with another game B
person you have a moral obligation of
considerable power to deal with them as
a peer irrespective of any other
different other dimensions of power
differences and so if this strong
beneficial Network effect system had as
an example that anyone who's a member of
it is within the constraints of the
system at least a true peer that would
be very interesting yeah so I can only
compete on a define and narrow metric
right so if we're competing over who has
more money or who's taller who can run
then we can just have a straight-up
competition but how do I compare dolly
techer it's a up thing right you
actually kind of can't do that in a
meaningful way and any way that you try
to say well here's a metric or some set
of metrics with which to assess that
you've actually reduced the thing to
something it isn't and so you could
imagine that an usher and a dolly could
interact with each other in a way where
they both acknowledge that each other
are bringing something to the world that
is actually enriching the world and
beautiful that they aren't bringing and
that they're stoked each other doing it
and there's no hierarchy intrinsic in
that and I'm not saying there are never
healthy hierarchies but I'm saying in
general rather than a competition on a
very narrow metric which is inherently
information reduction we are seeking
self-actualization of rich creativity
and that intrinsically can't be
holistically compared in the same way so
that's one big part of it and the other
part of it is you know that you and I
had a conversation the other day Jim
where you said something and you and I
are just getting to know each other and
like I instantly loved you because of it
because you said anyone who would abuse
people with a below 90 IQ I want to beat
their head and with a baseball bat or
something like that and you wanted to
see that those who have more
intelligence are actually protective of
rather than exploiting of those who
couldn't compete so then the question is
what made you that way and how do we
create social systems where to the
extent that anyone has obviously
increased capacity over anyone else
they're actually oriented to steward
everyone else rather than use that in an
exploitive way and I think this is
conditional both at the level of social
values and at the level of the way
values are codified in a value equation
ie the economics and the social system
Wow I think we should wrap it here we
could go on for three more hours but I
like to thank you for an amazingly
interesting conversation this was a
delight
[Music]
production services and audio editing by
Stanton media lab music by Tom Muller at
modern space music com
[Music]