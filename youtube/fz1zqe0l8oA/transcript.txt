howdy this is jim rutt and this is the
jim rutt show
[Music]
this is a current episode currents are
shorter and less heavily produced than
our full-length episodes and generally
focus
on a single topic as always links to
books
articles and organizations mentioned are
available on the episode page at
jimrudshow.com that's jimrutshow.com
today's guests are melanie mitchell and
jessica flack
melanie is professor of computer science
at portland state university and
external professor and co-chair of the
science board at the santa fe institute
melanie's also held positions at the
university of michigan los
alamos national lab and the ogi school
of science and
engineering it's the author or editor of
seven books and numerous scholarly
papers in the fields of artificial
intelligence cognitive science and
complex systems
including her latest artificial
intelligence a guide for thinking humans
jessica is a professor at the santa fe
institute there she directs santa fe
institute's collective
computation group also known as c4
jessica was formerly a founding director
of the center for complexity and
collective computation
at the wisconsin institute for discovery
at the university of wisconsin and she
was a graduate student at emory
university and was associated with the
famous yerkes national primate research
center
she's been my go-to person for questions
about primates
and monkeys and i guess monkeys are
primates aren't they yeah
uh so both of them are returning guests
melanie was on ep 33
where we talked about her book
artificial intelligence
uh and jessica's been on twice once when
we talked about complex systems
dynamics and she did a covet extra where
we talked about what opportunities
do kobit 19 and the changes that it will
cause in our society
open up so it's great to have you both
back
good to be back yeah it's great to see
you jim thank you for having us
yeah today we're doing a current episode
which are our shorter forms and less uh
highly structured and essentially we're
gonna start as our talk
our starting point uh very interesting
essay which caught my
eye uh when it was published i don't
know a month or so ago uh
called uncertain times published on the
aon
website that's aeon dot co
if you google it uncertain times flac
and mitchell or
aeon.co uncertain times you'll find it
uh it's really quite good it's a call it
a
practical guide to how to think in terms
of complexity
about the problems of our society and i
i would strongly
uh uh recommend that people actually go
and read the article uh it'll be it's
well worth your time
so let's start off with the uh opening
paragraph or so
from the paper and then or the essay and
then get you guys thoughts on that
uh you start off by saying we're at a
unique moment in the 200
000 years or so that homo sapiens have
walked the earth
for the first time in that long history
humans are capable of coordinating on a
global scale using fine-grained data on
individual behavior
to design robust and adaptable social
systems
the pandemic of 2019-20 has brought home
this potential
potential that's a good word never
before has it been a collective
empirically informed response of the
magnitude
that covet 19 has demanded yes the
response has been ambivalent
uneven and chaotic we are fumbling in
low light
but it's the low light of dawn
so what do you see that's hopeful in
humanity's response to covet 19.
um i think for me the thing that stands
out and i keep returning to
is this observation or this convergence
and the convergence is um
incredible microscopic data you know
actually at
all levels of organization and science
molecular all the way up to to human
societies
that we just have not had before coupled
to
the development of machine learning and
ai
and really great pattern detection at
least
um and the flourishing science of
micro to macro that's been coming out of
the santa fe institute and other places
and it's the sort of convergence of
these three factors
plus the fact that we can communicate
you know over vast scales of light speed
now
because of the internet that have made
the possibility or have given us the
capacity
to designed empirically informed
you know responses to perturbations like
covid over global scales
now i say capacity and that's a very
important word because as a number of
people have pointed out to me in
response to the essay
we're still not very good at this but
the pieces are all there for us to put
together
and i think it's the first time in
history that we've had this capacity
and so for me it's extremely exciting
and i want to see
i want to see us move in the right set
of directions
melanie your thoughts on on this well i
agree with jess of course i think that
in a way this whole pandemic and
the response to it has
kind of hit home for a lot of people and
realize
made people realize that complex systems
are
really important to understand made us
realize
how complex a world we're living in and
how little prepared we are to make
predictions
and to sort of do the optimal thing
at all times and that's really a lesson
of complex systems in general
so i think this is something it's kind
of a change of a mindset
as much as a change in our capabilities
to do the kind of science we need to
understand and
uh make the kinds of decisions that we
need to make in these
uncertain times as the title of article
says
indeed you guys talk about the fact that
kind of the default
human mind is fairly linear
simple cause and effect reasoning and
that kind of reasoning will get you into
trouble when you're dealing with complex
systems
maybe talk a little bit about how some
of the manifestations of covid since
it's an example
we're all still familiar with uh
exhibited what we might think
of non-linear or non-simple cause and
effect
uh relationships one of the best
examples of that is it's still going on
but it was particularly
problematic early on say you know march
when we were
had early we were in early days of covet
modeling
and models wouldn't you know would make
predictions about the number of deaths
or so forth by weak x
and then that number would either not be
met and
you know what are the reasons for that
well one reason is that the model isn't
very good or the information
the input into the model isn't very good
that's another reason and the third
reason is that our
our interventions change the outcomes
and that is you know that's about
feedback and
that point even though you know in
saying it in this conversation
makes it seem so obvious it was is very
easily forgotten
and i think that's an example of how our
minds default to like linear reasoning
we forget
to factor in these feedbacks yeah let me
add one thing to that um i think
one really good example of the effects
of linear thinking
is this uh thing that people talk about
in
in terms of how infective a virus is and
that's that
are not which is the number
of people you're likely to infect if you
yourself are infected and so people
think about are not and they talk about
are not across the country or across a
state or across you know
some region but are not of course is an
average which is a very linear kind of
quantity
you know you add up all the parts and
you get an average
uh but it turns out that infectivity is
really very
much more clustered that we have these
super spreaders
who will infect a huge number of people
and whereas most of people
are not infecting anyone at all and so
it's not a
real kind of linear system in which you
can
talk about these averages in any
meaningful way and i think a lot of
people got misled by
focusing on these averages like are not
in terms of making models and that's one
reason why models didn't really reflect
reality yeah that's a wonderful example
because i've uh
i did pick that up actually from the
data that wait a minute here
it's not as if we're all clustered
around some are not
mean right it's as you say there's a few
people that are spreading to 25 or 50
people while lots of people spread the
zero
or or at most one often a person in
their household
and if you model it assuming it's all
clustered around r naught you'll get a
very different
uh configuration of spread than if you
assume that it's
uh a relatively small number of super
spreaders a
really good a really good point uh
let's see another uh topic you guys talk
about
and how a complexity perspective of
thinking helps one
deal with solutions in a non-obvious way
is
you talk about how basically
noise oddly enough can actually help
organization you give a very interesting
example about uh
schooling of fish maybe talk about that
example a little bit
yeah so i mean i think the um you know
it's sort of well known in the theory
literature that noise has surprising
effects but for most of us we think
noise is something to be eliminated
you know we want to maximize the signal
minimize the noise
and that's you know understandable but
um this
what the fish study in particular it's a
type of cichlid fish
these researchers found that um
the fish copy each other to decide sort
of which direction to move in
and the the copying behavior is often
thought to be the
driver of these collective states like
schooling
but in the case of these fish actually
small
um noise in their copying behavior
feeds back on itself and when it
happens with a big enough effect it
actually
induces a transition to schooling to an
ordered state
so the noise in the copying behavior is
really important for producing this
organized collective state and i think
that was that's very surprising to a lot
of people and of course there are other
examples so the
sort of canonical example of of the
importance of noise comes from
you know stochastic resonance which is a
phenomenon where a signal that is
sort of normally too weak to be detected
by say a sensor or an agent in a system
is boosted by adding white noise to the
system to the signal
and um they're also so that i guess the
point is there are all sorts of ways
that noise
what all sorts of ways the noise plays a
role in generating the sort of
collective states we see and sometimes
those states are
are good and sometimes they're not but
we want to be aware of that and
um what one you know one example in the
kobe case where
i think it's important to be aware of
these things is saying
in the enthusiasm
for contact posting apps you know where
you
you trace the number of the contacts
that an uninfected individual had
and thing with the thinking there is
that you can by by knowing where the
infected individuals are
and avoiding them that you know will
will be safer
and the and when you couple the sort of
noise point to general understanding of
synchronization and collective behavior
you know that you need to be wary of
that conclusion because often surprising
collective states can be generated so we
might actually end up in a situation
with those contact tracing apps where we
where we are putting more infected or
asymptomatic people next to each other
than we thought we were going to be
doing
right so you get these counter-intuitive
results and only with thinking about
noise and complex systems and
synchronization
do you realize that this is a pro that
this is a potential concern
yeah this is one of the things that i
personally found most
fascinating about biology versus
sort of human engineering is how much
kind of nature has sort of
decided that noise is unavoidable and
noise i think of as synonymous with kind
of
randomness and it's just
something that cannot be engineered out
and so instead what evolution biological
evolution at least
seem to do is to embrace randomness as a
way
to deal with uncertainty that these
systems as jessica
pointed out for instance with this fish
schooling all of these biological
systems are
are just embedded they're just noise is
ubiquitous
and they they embrace it and they use it
because
the environment is so uncertain and that
just contrasts with
our normal thinking about how to
engineer
behavior how to engineer control is to
kind of get rid of all the noise as much
as possible and try and make our
predictions as precise as possible
but that's not the way nature does it
and it seems like in
our complex world that's not the way we
should do it either
interesting there's another good example
about noise in fact it was involved with
the
research i was involved with when i was
a researcher at the santa fe institute
with
doane farmers group which is
surprisingly enough you can think of
stock markets
as having a significant amount of noise
in them
and it turns out that the noise is what
allows the system to function the way it
functions
uh in our case we define noise traders
as people who had some specific
reason to buy or sell for reasons that
nothing to do with the market so they
needed to sell some stock to pay for
their kids uh uh
college education or they were buying a
long-term position
for their uh retirement account they
believed in the buy and forget
uh strategy and so they bought and sold
for reasons not particularly determined
by the current action in the market
uh while many of the biggest market
participants are essentially strategic
investors on
various time frames we'll talk about
varying time frames here in a
minute and if you don't have uh
noise investors to essentially dampen
the system the system can get out of
control
in a hurry as the strategies
interoperate with each other in ways
that are very very very hard to predict
and say we'd actually have considerably
less stable financial markets if there
weren't
noise traders isn't that interesting
well actually in a sort of a complement
to that jim is
is the idea that in march with all that
volatility in the stock market
the market was much more became more
inefficient than it had been
and hence um offered um potential an
edge to s in savvy traders long-term
investors
and and the reason for this that's been
proposed and i don't think it's well
studied yet but it's i've seen it
proposed in a variety of sources is that
um essentially speculators more
speculators entered the market
so these are also kind of noise traders
and they were coming from you know the
reddit community
and from the robin hood you know app
that enabled
sort of the everyday person to trade
more easily with zero fees
and also from the sports bettors who had
nothing to do no sports to bet on
so these three sort of communities
entered the markets
and introduced potentially because they
were making
possibly poor decisions or were
motivated by other reasons a lot of
inefficiency to the markets
so then so noise there not only as in
your example sort of
dampens um things or keeps things under
control
by balancing out strategies but can also
create opportunities for others to
exploit
exactly that's the cool thing about
stock markets you can actually think
about them as food sources right a dumb
investor is a food source to a smart
investor
however a smart investor when he takes
advantage of the
uh called statistical arbitrage is
actually polluting his own environment
so that the amount of food that's
available goes down it's actually very
very
interesting and the noise the noise
trader are is a very important part of
the ecosystem and you're right you get
enough noise traders in
uh and it can uh indeed produce uh you
know changes in the underlying name of
the game and i
i love that fact that you guys uh quoted
in your article that the this theory
that
uh well part of it was uh sports bettors
with nothing better to do
possible again actually that's a very
interesting uh
uh thing example of what we'll talk
about a little bit later is the coupling
of systems
who would have thought that because
there was a virus running around loose
sports bettors would jump into the star
stock market and change some of the
fundamental dynamics of the marketplace
talk about a peculiar linkage that
uh would have been pretty hard to
anticipate in advance
yes a nice example of a second order
effect or maybe
at least second i would say maybe easily
third right
now let's talk about another one of our
favorite topics
at the santa fe institute which is
complex systems seem to be especially
vulnerable to
events that don't follow normal or bell
curve type distributions
what we call fat tail distributions we
can argue endlessly about whether
they're power laws or just approximately
so
it doesn't really matter what it means
is that uh large scale
outcomes can happen more often than you
know the equivalent of
calculating uh the results from flipping
coins you know how many what's the
probability of five
heads in a row etcetera you all talk a
little bit about that
about how uh how the complex systems
seem to have
a special uh affinity shall we say for
fat dale distributions
and what that means about uh about
planning
well the example i gave earlier about
the
are not that's an example of a fat tail
distribution if you ask you know who
who is spreading the virus and most
people
who have the virus are not spreading it
but
a small number of people who have it are
spreading it to a huge number
of other people so you know we might
call those people sort of
hubs in the network of spreaders
and this gives rise if you kind of plot
the frequency of
spreading you know how many people uh
you spread it to uh you can you get this
kind of fat tail distribution
uh so so this is this is a very this is
kind of a signature
of a complex network of of interactions
um and i think that
it affects the kinds of models you want
to use
to predict what's going to happen and to
understand what's the dynamics of the
system
yeah i mean i might add to that that one
of the
reasons i find them so interesting these
heavy tail distributions
is because um in certain cases in some
systems when you get these
rare events which are hard to predict
you know in the heavy tail distribution
then you get sort of second order events
in the tail
generated by those first so earthquake
gyrus you know aftershocks are an
example and then the the subsequent
gyrations in the stock market after
a crash are are other examples and what
happens in
we think in the case maybe of markets is
that the rules that you were playing by
once there's a really precipitous drop
change again
and those when the rules change the
second time that makes
even these these um even even lower
probability events
more likely and so what is initially
almost impossible to calculate
as as you know or forecast
um now you know becomes more more likely
and what that says to me that's that in
and of itself is fascinating to think
about but what it says to me is that
we want to move a little bit away from
forecasting and more towards
scenario planning that's an old idea
it's been around a long time but really
important and complex systems where
you know you you consider both using the
past and your imagination
you know principled imagination what
possible scenarios could unfold
and you don't spend so much time trying
to assign probabilities to them because
the probabilities are probably really
low
and then you just you hopefully can
design some general mechanisms
or general solutions that will work over
a variety of those
low probability scenarios exactly
what i recommend to people trying to do
that kind of planning is to
you know create models create various
models and then generate a large
ensemble of trajectories and as you say
don't try to get too smart about picking
which trajectories are likely or which
ones aren't but look at the aggregate
statistics over the ensemble
and that will often show you that these
fat tailed
distributions are likely to be more
common than you think
yeah yeah there's a great um
uh so my my main field is artificial
intelligence
rather than you know like epidemiology
or
or any of the things that we've been
talking about but there's a great uh
kind of analogy
in the field of artificial intelligence
which is that right now when
when we're talking about sort of
deploying these ai systems like for
instance self-driving cars
what people try and do is they try and
plan for every
possible thing that might happen by
either writing rules or trying to
learn uh from data and so
you know you can have all these really
unlikely situations that might happen
in driving like you might have you know
you know like like a
fire truck stopped in the middle of the
highway okay
or uh you know you're on a road and
uh there's a tumbleweed that
crashes into your windshield or you know
all these different unlikely things but
the the way that we humans actually
drive is we don't plan for all these
individual events
we plan we have more of a general kind
of
commons what we call common sense uh
approach where we take each
each we kind of have a general strategy
for dealing with
lots of different low probability
systems and i think that's kind of what
the goal of this emergent engineering
idea really is is to not try and
precisely predict everything that's
going to happen because that's
impossible
but to have strategies that will be
adaptable and workable
across many different situations
yeah to build on melanie there i mean
emerging engineering
stresses sort of a known story process
over specific outcomes
designing for robustness and
adaptability finding solutions to
unanticipated challenges through
collective computation what i work on or
collective intelligence very closely
related
and i want to hammer home before i sort
of say a little bit about the sort of
three
levels of immersion engineering as i've
been thinking about it
um an important point and that is that
emergent engineering in its sort of
strong form
is quite provocative in a truly
ee capable system there's no i would say
like i would argue this there's no
commitment to any particular outcome and
that could be quite frightening to
people
so the objective would be to let good
solutions be they policies or social
structures organizational design
to the challenges that a system faces
emerge through
say collective intelligence and this is
a fundamentally different strategy and
philosophy than we embrace now
a somewhat weaker version would be to
build an ee capable system but constrain
them so that they respect certain
principles and values we collectively
deem important so
while not guaranteeing for example a
form of governance we might
um which we might let emerge as
appropriate given some environmental
challenge we would guarantee a high
minimum quality of life that would be
like a weaker form than
i started with and then the weakest form
but still non-trivial to design
and which draws heavily from ideas in
biology as
melanie mentioned earlier is is the idea
you know
again we find designs of stress process
over outcome robustness adaptability
scenario planning
it but it i would say the one of the
biggest pushes and the weakest form is
that
it proposes building tuning mechanisms
into systems that control how fluid and
responsive a system is
so you add levers that allow for
adjustment i know we're going to get to
this gym of time scales
to control time scale separation and
adjustment of say
mechanisms that allow you to tune the
distance from a tipping point
that's kind of a novel concept some of
this may sound familiar
these ideas have been long discussed at
sfi and you know we have some progress
on levers already implemented in applied
settings like markets or
financial systems fed adjustment of
interest rates a circuit breaker
and so forth um but the idea that
that's sort of different is that we can
optimize for robustness and adaptability
by tuning
time scale separation or distance from a
critical point doesn't have many design
precedents that's really a new design
idea yeah it really is and i'll just
make i'll make it a little bit more
concrete by returning to the fish school
and then let's then let's talk about it
and so um some fish do school and by
schooling i mean they form
they form um they swim they're all
aligned and they can move fast
to escape a predator right that's
essentially what schooling is
and uh most of the time these fish at
school are in what's called a shoal and
in a shawling state they're loosely
aligned and they're sort of aligned
just enough so that if one of the fish
sees a predator that information can
spread across the group and they can
rapidly shift into the schooling state
so the shoaling state in the shoaling
state they're essentially sitting at a
critical point
this is still under investigation the
biological literature but you know we'll
simplify a little bit
this conversation so they're essentially
sitting at near a critical point by
sitting near that critical point
they can make this rapid change and
notice one thing about this already so
you know this is obviously
beneficial for the fish to be able to do
this and often in the popular literature
tipping points and critical points are
presented negatively so that's something
just to keep in mind for a future
discussion
so just a couple things to keep a note
about keep in mind about this example
the fish have two states or two
scenarios rather to come back to our
scenario planning
the predator scenario and the foraging
scenario they have strategies for both
shoaling while foraging
and schooling when the predator's around
right
the critical point the level of
alignment to simplify essentially allows
them to shift states fast
and there's uncertainty in this system
because they don't know when that
predator is going to appear but they do
know what to do when it does
so that comes back to our earlier points
about scenario planning and you might
not be able to predict
the probability of some event but you
know that if it happens this is a good
strategy for dealing with it
and of course the last thing i want to
point out is that there's a robustness
trade-off so if the fish incorrectly
if one of the fish incorrectly detects a
predator
then then that might he might that fish
might transmit this information
to the rest of the fish and they might
inappropriately change state which has a
cost because
you know they should be foraging and
instead they're switching to schooling
so tuning how sensitive the system is
how sensitive the fish are
to the likely presence of a predator
would be
an extremely beneficial strategy we're
not sure the fish can do it we do have
evidence from some a primate system
and some other areas of biology that
these tuning mechanisms exist this but
this is kind of
new it's something we could exploit in
designing ee capable systems
very good when i was reading about the
tipping points
i had a thought which i'm almost going
to run by you
which it might be useful to distinguish
between
uh easily reversible tipping points like
switching in and out of schooling
and tipping points of the sort that you
alluded to in
climate discussions you know people
listen to my show
regularly know i often talk about the
distinction between
homeostasis and hysteresis you know
systems that
can return to their previous points and
those that don't
and putting both of those in the same
bag may indeed be misleading i know you
were
trying to kind of wave people off don't
think about the climate tipping point
when we're thinking about switchable
tipping points so maybe some new
terminology
so that uh tipping points that are
easily reversible
uh are distinguished from those that
aren't
yeah so that's absolutely an active body
of research and
a totally critical point jim you're
right um i wanna i wanna emphasize
though that so
so in the fish case there's still
different states it's just that in the
examples you're giving we're going from
an organized to a disorganized state
and in the fish case we're going from
kind of the loosely line to a more
organized state
so you know these are all active areas
of investigation
but even in the case where you're going
to the disorganized state it is not we
should not place a judgment on that a
priori
sometimes if the the distribution of the
environment
environmental states are fundamental if
it's fundamentally changing
then we then the strategies that we have
at present will be
fit or overfit to the past to
and right and they're not they're very
unlikely to work under this new
distribution
this new environment and so in that case
we may actually want
to um be in a system where
the tipping point is not so to speak
reversible and where
we move to for a short period of time at
least a disordered state so that we can
explore new scenario
new solutions frankly that's my view of
what's needed in our social economic
political operating system
uh you know these things were not
designed to operate in a
world of hard limits that were
approaching very
rapidly and so it strikes me we have to
uh
you know set off into the unknown and uh
make some transition through probably
disorder till we find what's on the
other side so a very good point
there are times when we actually do want
one-way tipping points and
sometimes you may not survive if we
don't find them and that's exactly the
sort of goal of emerging engineering in
a way but maybe to do it in a
um you know in um a somewhat safer
with a somewhat state with some safety
mechanisms to design you know e-capable
systems that's the sort of second
form i mentioned not the strong form
where you
you're free to explore any new outcomes
but this weaker form where you might
build some constraints
of the state space that the system can
explore the sort of governance systems
and so forth
you might build some in but then within
that constrained space you leave it open
yeah yeah uh another way to address that
was one of the things that we're dealing
with in our game b
socio-economic political design work is
operate at different scales for instance
if you have a theory
about uh money or governance you know
try it at the level of a village before
you inflict it on the whole world right
i think that i would add that to your ee
tool kit
uh you know can you find small-scale
low-risk experiments that nonetheless
will uh provide confidence on the core
principle never certainty of course
because as we know
more is different uh but at least that's
one
way to you know get some experience
without uh you know large-scale
uh costs from unpredictable uh ee type
experiments
you know there's a very interesting idea
in biology called um and david krakauer
worked on it long ago and i forget who
the main guy is i'll think of his name
in a second
called arena selection and the idea of
arena selection is that the body for
example
will try out certain competitive
strategies in an arena within the
organism
and then the strategy that wins in this
sort of you know artificial arena
is then sent out to the world yeah good
there's a great example of that in
immunology i know which is where
your immune system cells like your b
cells are grown in the the
bone marrow and tested to see if they
recognize
the self or not if they do recognize the
self
they're they're destroyed because you
don't want your immune system attacking
yourself
and if they're they don't recognize the
self they're released
and so that's a great example of an
arena where the body's trying something
out
before it releases it and in fact i
think that idea was
a melanie that's a great point
originally developed in that context in
fact david might even have written about
it
okay yeah there's another example too
which close
at least is the you know pandemic theory
of what's interesting that we're using
uh pandemonium theory sorry
pandemonium theory of cognition right
marvin minsky and then it was uh later
extended a little bit by daniel dennett
some other self selfridge
yeah yeah suffrage originally you're
right absolutely that you know that uh
there's competitions in the brain for uh
unconscious thoughts that are
essentially competing to become
conscious and
to turn into uh you know perceptual
objects or
uh you know affordances etc so this may
be a general pattern that we should be
looking at
yes absolutely yeah uh
okay another topic you that we that we
alluded to let's
go into a little bit more detail here is
time scales
and you gave uh a pretty good example i
sharpened it up a little bit
nice and i uh would restate it a little
bit
uh by saying uh with respect to covet 19
you know pandemics happen on relatively
short time scales weeks to months
while normally building hospitals take
years
as you guys suggested that gaining the
ability the planned ability
to build hospitals in weeks uh would be
a significant game changer in how we
would adapt to pandemics
yeah that's absolutely not not just
hospitals but
all of the kinds of infrastructure that
we're lacking right now
you know all the all the ppe
and the um when we finally get a vaccine
all the
um you know things that we need to
distribute the vaccine the
glass vials and whatnot all of that
infrastructure takes so long and that's
really the bottleneck
so if we had some way to be more kind of
um
nimble to be more
ready for many different
possible scenarios as jessica said you
know we could
we could really alleviate some of these
problems
of course this gets to the fundamental
problem of robustness in a capitalist
economy
who pays for it uh you know uh things
like for instance having
extra capacity to build glass vials for
distributing vaccines
uh you know normally no vaccine company
or no vial company has any economic
extent of incentive or receives any
economic signal
uh to have extra capacity it's just a
deadweight investment
uh which probably you know in any time
frame that a ceo's worrying about is
bonus i.e no more than three years
uh they're not going to do it uh so
again as i was reading the paper i three
or four times wrote down
cost who pays for it uh very seldom
can you get robustness for free any
ideas on
how we should think about as a society
setting up a higher order set of signals
such that
uh robustness uh does emerge
so biology is the same problem this is
like your point about
incentivizing investment and robustness
mechanisms is a huge
area of research in biology how nature
does that
because you know this the same logic
applies in
in two ways one often the perturbations
are hard to predict or
or you haven't experienced them before
so it's hard to build a strategy
when that's the case and the second is
is that if there is a maintenance
problem so
even if you have a gene that's say a
duplicate and one gene
the gene for which it's a duplicate is
destroyed or damaged
um maintaining that when there's no
perturbation
given you know that
given the costs is hard and so one and
again this is an active area of research
and there's a lot of controversy around
it
but one idea is that um the way nature
solves our genes solve that problem
is to have genes with multiple functions
and there so there's partial overlap in
a network of genes instead of just two
that are duplicates of each other and so
the the pressure to
sort of diverge is maybe less or the
cost that you pay
is maybe less and so we have to think of
strategies like that
and i would also add and we talked about
this last time jim and you know maybe
in certain communities this isn't a very
novel idea but i don't understand
why um this kind of equipment in the
human case
ventilator parts vials and so forth
can't be 3d printed so we can develop
technology that makes
for a more fluid production system and
of course we don't want to generate a
lot of
garbage so we want the materials we use
in this more fluid production system to
be
recyclable or biodegradable or something
but that seems like an obvious area
you know in which to invest as melanie
pointed out earlier you know we have
these general purpose solutions
that apply to a wide variety of
scenarios more fluid production
mechanisms
is seems to be one of those yeah that
certainly could help though i
always point out i was involved with 3d
printing from the very beginning
uh and unfortunately there's material
science
problems at the intersection of 3d
printing
and lots of products i always tell
people as an experiment next time you go
to lowe's or
home depot look at your basket when
you're checking out and say how many of
those things could have
been printed on a 3d printer and the
answer is usually not very many of them
because the
uh you know the materials aspects of
what you can actually manipulate
in today's 3d printers at least doesn't
solve an awful lot of problems not clear
to me for instance how you'd
print a a mask for instance though in
the future they can probably design ones
that can do that so it's certainly an
area
that would be worth researching and
investigating and planning and maybe in
investing in you know again social
investing that's maybe what it comes out
to in our kind of capitalist society
that we have to at a higher level
say socially we are going to allocate 10
billion a year to building out the
robustness in our systems
because no individual business person is
going to do it so socially we have to
make the decision
to do it of course if we're going to do
that we have to have damn good judgment
about where to invest that money
or again maximize that sort of general
purpose
yeah flexible response flexible response
yeah absolutely
well let's get to a final topic here
we're getting a little uh along here on
our time
which is uh when i think about this and
when i hear
hear you all write about and hear other
people talk about it i go
damn thinking about these complex
systems
as a human is really hard as an
individual human
uh you know our cognitive ability was
not evolved to do this
really we lived in a world that had
certain amount of complexity but it was
relatively stable
with occasional switches as you pointed
out uh jessica
uh but we're not individually very good
at this
and if we're gonna solve these problems
we've got to get good at what you talked
about
in the paper which is collective
intelligence
what can you both say about what we know
about collective intelligence and what
we need to learn about collective
intelligence
if we're going to manage this transition
into a high complexity world that
doesn't self-destruct
um well let's see i think the first
thing the first remark i want to make is
that
i suspect a lot of people think we have
a better understanding of collective
intelligence than we do i think
personally that
our understanding is nascent and um
one of the things that i i do feel we
have sort of got our heads around is
that there are two parts
to collective intelligence there are two
phases if you like there's the
information accumulation phase by agents
or individuals in the system when
they're sort of
looking at the environment and trying to
figure out what the regularities are and
then they have opinions about that
and then there's the aggregation phase
when those opinions are pooled or that
information is shared
and some collective output is produced
and hopefully it's you know it's useful
given the environment
and that's when when it when it's useful
given the environment is when we say
broadly that it's intelligent
um but what we don't understand
is what the best way to do that
aggregation is
and the the current problems we have
with our voting system the electoral
college and the popular vote are a good
example of the challenges
of aggregation information aggregation
in many places information aggregation
is talked about
just like that it's basically a black
box it's black box and markets
how that happens how price is discovered
and so forth
um so you know totally open set of
questions and i think though
we can focus our questions a bit for
example
if we know that individuals have certain
biases in the way they collect
information
we might be able to compensate for those
by designing algorithms
that are sort of you know compensate for
those weaknesses
correspondingly if it is very hard for a
system and this comes up maybe more in
biological systems for
an algorithm for a particular algorithm
that might be ideal from an
optimization perspective um it's hard to
evolve that or hard to discover it
we might be able to compensate by
building smarter components
so the information that they extract
those components extracting the
environment is better
so there's a we know i guess the point
i'm making is that there's this
we can trade off costs we can either
invest more in the agent so they're
smarter and gathering better information
or maybe they're gathering we're
maximizing the differences in the
information they gather that's sort of
the diversity point that you sometimes
see
made in a collective intelligence
literature or we can
or we can invest in the algorithms for
sharing and pooling that
that information and and potentially
play those off against each other so
there's a lot
there's a lot to do and the last point
i'll make and
is that we have now a new journal on on
this topic on collective intelligence
that both melanie and i are involved in
um that will be
it's it's in progress now the launch the
sort of submission
the first the first papers will be
accepted probably in january
but it is is dedicated to finding to the
empirical and theoretical foundations of
collective intelligence from
you know adaptive matter physics
approaches all the way through to human
organizations and hybrid ai human
systems
so really transdisciplinary dedicated
exactly to these kinds of questions
so we can improve both understanding in
basic science and application
melanie wow that's hard to follow i mean
that
you know that was kind of a theoretical
uh
description of collective intelligence
but i think
i think i'll just say two things one
from from more of a personal standpoint
i
i think you're right that that we we we
don't easily
think in sort of complex systems
ways we're much more linear thinking
even those of us who work in the field
but it's possible to train oneself
to to um think
in a slightly different way to
approach these things in our own lives
in a slightly different way
and i think that's possible
and i try to do it i don't always
succeed but i also think that one of the
biggest
problems we have today for all of these
systems is that
people who aren't scientists often don't
trust science
they don't understand science they don't
know what it is they don't know how it
works
and they don't trust the recommendations
that scientists give
and they don't even know how to judge
sort of the reliability of what
scientists say we see this like with the
whole debate about wearing masks
and that's a huge problem that i hope
is something that complex systems will
address as to how to
get people to better understand what
science is and how
when and how to trust it because i think
that is one of the
biggest roadblocks we have to solving
some of these problems
that's getting to be a damn big problem
uh and you know just the crazy you
see on the internet uh you know
some people fifty percent of americans
are now skeptical about the
uh covet 19 vaccine when you know how
many americans have died from vaccine
problems since 1950 take a guess
i can't guess a hundred yeah i mean
there's a lot of examples of
this mistrust of science that are really
impeding our
our health and our well-being and our
environment
and i see that as one of the biggest
problems that scientists themselves have
to face
yeah let me make two remarks on that and
be like to take the other side just a
little bit
not anti-science but add some nuance to
this
so the first is that i've been wondering
how much fake news
and you know mistrust is
greater today than in the past and i've
seen some reports indicating for example
that like the use of propaganda in rome
was astronaut you know ancient rome is
astronomical
i'd love to see a study that addresses
this question of
whether there is an increase because of
the internet or other reasons
the increase in in misinformation or
disinformation even
that's the first point that we should
hit on a little bit and then the second
is
just you know whether there are many
issues around vaccines that
in addition to death and so forth and
one is just whether they work
and how much money goes into you know
producing the vaccine
possibly based on faulty science and one
of the things i do worry about with
covid is because there's so much
pressure to produce this vaccine
and there's so much financial incentive
to be the company that does so
that the sun and we already know that
biomedical science suffers from a lot of
replication problems and
effect size issues you know we do have
to worry about
sloppy vaccine production and so what
can we do as a society to incentivize
their owners there yeah i think that's
uh clearly a good point and that uh not
only thoroughness but document the
thoroughness and make sure that people
understand that the protocols have been
followed and that
a certain uh who'll remain
nameless didn't jam the thing through
a week before election day exactly yeah
we need not only good processes but
transparency about the processes
so that people have uh you know good
cause to be confident
i think that would help yeah that would
help melanie's point about trust
yep a good good question it's an
interesting one about
are we actually in a worse world for uh
fake news and misinformation than we
used to be i hadn't really thought about
that
but think back to the 19th century
literally the era of the snake oil
salesman guy coming to town on a wagon
uh you know selling his uh his nostrum
that'll cure a long list of diseases and
literally it was snake venom
and probably some alcohol right and uh
yeah people bought it
uh you know the the press in the 19th
century was mostly partisan
we didn't even attempt to have uh
nonpartisan newspapers typically
all newspapers were associated with one
of the political parties or the other
and were amazingly vicious go back to
the election of 1800
uh thomas jefferson against john john
adams and the
personal attacks were you know almost as
bad as
what we're seeing today maybe maybe
sometimes worse compared to
the norms of the of the time so it's an
interesting question i don't know how
you'd get the data
on whether our uh memetic space is more
polluted than that in the past
yeah well maybe it doesn't matter if it
was more polluted in the past or not it
may be because of what we were talking
about that we've now emerged into a
world where global complexity
are the issues that has to be managed
that we even if we had
shitty memetic uh hygiene in the past it
may be that we're in a point now where
we can't survive that maybe that's the
real argument
you know jim the other thing that sort
of the other element of this debate
that's so important is
is um humility and analytical skills
so and these points apply you know as
much to
you know someone's grandmother as they
do to some of our very esteemed
colleagues
it's amazing to me how much certainty
people have
about their positions or their solutions
that they suggest or even you know the
workings of their model scientists
and or people reading about these things
i just i can't
i personally to make it you know
personal point i personally
cannot get my head around it and i think
one of the things we need to do
is to you know not just as everyone's
been arguing teach more probability in
school
and and and you know and the importance
of
informed reasoning and so forth we also
need to teach people
that science is fundamentally about
uncertainty and and we need to teach
people it's like a little bit
you know related to our essay to to
embrace it
right and um and and to have a little
bit more humility
and that applies like it's amazing that
you can go through
your your coursework all the way through
the phd through the postdoc
be a professor for years and you still
don't have this humility
you know you can hear finding quotes
every day and you somehow they still go
in one ear and out the other
and i say that's particularly true with
when you're dealing with complex systems
the words i happen to i use a lot is
epistemic
modesty uh you know our ability to
really predict a complex system
especially if we perturb it in a major
way not all that strong and people claim
that they can
uh you know make solid predictions uh
one should be
skeptical and as you say that needs to
be somehow
uh part of our baseline education to
realize that uh particularly with
complex systems you know uh that we need
to not
over claim and not over believe
absolutely
melanie some any final thoughts
oh well yeah i i totally agree about the
humility part
and i think that's really important but
we have to kind of
know we have to know when we don't know
something but we also have to have
confidence in some of the things that we
do know
and i think that um it's
a wrong message to tell people that all
science is uncertain you know different
amounts of it or different
types of it are more certain than other
things and that's something we have to
we have to let people know what they can
trust and what they can't
and i think that people right now people
a lot of people think you can't trust
anything
yeah the problem is we don't have any
authorities that are respected
across the board you know it used to be
walter cronkite said it was true in 1965
then it was probably true for most
americans but there's
there is no uh source of authority like
that anymore
yeah each each bubble has its own
sources of authority
i mean it's also though that like you
know as i always tell my students every
paper has
errors and can be improved and of course
you want to do your best to not make
those errors but that's just part of
science
but where trust comes in or where more
authority comes in is over time
it's a collective consensus that
develops over time you know
about some results or um set of
questions
and that's subtle but you know it's it's
that time
that that gives that confidence and
sometimes we have to speed it up
admittedly like in covid but
that's point it seems to be lost on a
lot of people like
every paper is errors if we're if we're
living in an
epic of exponentially accelerating
change we may not have the time do we
have the time to convince people
uh that uh that anthropomorphic climate
change is real
we might not uh at least not the uh the
typical
you know you know uh thomas kunian a
couple of generations i don't think we
got that kind of time so we got to find
some other way
to reach uh collective intelligence that
results in
reasonable assumptions about what's
going on difficult challenge
yeah absolutely well i think on that
note i'm gonna
wrap her up i think this has been a very
interesting conversation
thanks melanie mitchell and jessica
flack thank you jim thanks jim
[Music]
production services and audio editing by
jared janes consulting
music by tom muller at
modernspacemusic.com