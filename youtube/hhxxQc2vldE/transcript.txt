howdy this is jim rutt and this is the
jim rutt show
[Music]
listeners have asked us to provide
pointers some of the resources we talk
about on the show
we now have links to books and articles
referenced in recent podcasts that are
available on our website
we also offer full transcripts go to
jimrutshow.com
that's jimrutsshow.com
today's guest is joshua bach he's vice
president of research at the ai
foundation
previously he's been a research
scientist at mit and harvard
he's the author of the book principles
of synthetic intelligence
psy interesting kind of joke at multiple
levels
an architecture of motivated cognition
and he's published
many papers i should also point out he
has one of the most
interesting and entertaining twitter
feeds i know of
at plens p-l-i-n-z check it out
this is the second time we've had yoshan
the show last time we talked
quite a lot about ai we talked a little
bit about his microsci
project today we're going to kind of
split to the
very high side and then get down to some
details on microscience i think we're
going to start off
talking about the biggest of questions
or one of the biggest
questions in this field is how does mind
arise from brain and can it arise from
an artificial brain
yosha i think it can
obviously and so the question is of
course what is mind and
there sometimes we need to clarify our
terms not so much to absorb them but to
make sure that we are talking about the
same thing
so uh typically when i say mind i refer
to essentially the software that runs on
the brain
and that enables everything else and
what is software
i think that software is best understood
not as a physical thing
as something that has an identity but as
a
physical law it's a very specific
physical law that says
whenever you put things together in the
universe in this particular arrangement
the following thing will happen and the
following thing is a description in
terms of certain macro states that have
a causal structure and in this sense you
could say that for instance the text
processor in your computer doesn't have
an identity
it's a physical law and the physical law
says that when the
gates in your computer are in this this
arrangement they can be described as a
text processor
and when you interact with it the
following thing will happen when you
when it's currently in this in this
state so the same
category of things is mind it doesn't
have an identity
it's a principle it's a software that
runs on your brain
and it doesn't uh run on your brain
because uh it
is corresponding one to one to a
configuration
of atoms in your neurons but because
there is a coherence
causal structure emerging over the
activity of the neurons that you can use
to describe it it's a lens to look at
the activity
of many neurons and there is not a
reason why this should happen
should not happen in other substrates
that are under the same functional
constraints and can
implement the same principles in the
same way as we can implement
software on many many different types of
computers as long as brains are turing
complete
you can build mines on different
substrates
if you are implementing the same clause
of principles
of course people would argue that human
mind the human
consciousness we talk we'll make a
distinction later about consciousness
and mind but let's for the moment keep
them together
is strongly embedded in its bodily
substrate
and that in fact some people like
antonio demacio would argue that the
the actual root of our conscious being
is deep in the brain stem and is more
related to our body
actually than it is to our higher brain
and if if that's the case
then while we could create artifacts
that were analogous to the mind in some
sense
they essentially can't be the same if
they're not embodied in the same
kind of structure that the human mind is
embedded in
if i change the interface that you have
to the universe so you
are situated different way for instance
you are not
no longer located in your body but you
are connected to sensors all over a city
and your incentives are aligned with the
incentives of the city and you also
identify with these goals and so on you
might
turn into a city at some level right and
this
still means that you have a mind even if
i change your affordances in the same
way if i
limit your affordances to things that
are internal to your own mind as it
happens for instance during dreams at
night it's not that you lose your
consciousness in that moment
and i think that you can also be
perfectly conscious uh while playing
minecraft and
even if you are embedded in a vr that
only gives you access to minecraft
that probably has enough complexity to
without loss of generality be sufficient
to be conscious and and to form a bond
to an
external world and we can take minecraft
and implement this on a chip
we can implement this on neural tissue
in principle at least and implement
this within the brain itself so you
never need to leave your brain and go
into your physical body
in order to have the experience of the
body this is
your embodiment can be entirely virtual
what you need to have is an
implementation the implementation needs
to
have a realization on the physical
substrate layer of the universe
but uh this doesn't mean that you would
need to have a physical body that is
exactly human-like you only need to have
a human similar
uh affordances if you want to end up as
a human-like mind
yeah the old brain in the bottle
argument right but particularly your own
work has put a lot of emphasis on
emotional states and emotional valences
etc
and you know there's a substantial
school of thought that says that
the reality is that the physical
reaction of emotions such as
heartbeat and respiration skin
tone etc actually happened before the
feelings i.e the cognitive states
associated with emotion so you'd have to
also
essentially have inputs that you know
directly
at least for humans if you want to try
to extend them to a non-body state brain
in a bottle
you'd also have to essentially fake out
the physiological emotional responses
wouldn't you we
probably noticed that consciousness is
not in charge when we control our
interactions with the environment
some meditators say that consciousness
is like
this little monkey sitting on top of an
elephant and it can direct the attention
of the elephant by prodding it
but eventually at the end of the day the
elephant is still going to do what it
wants
and if the monkey thinks it's in charge
then the monkey is often in for big
disappointments when it notices that it
makes decisions but the elephant is not
reacting to them
and this elephant part of our mind seems
to be much older especially
with respect to the high level concepts
that the monkey is developing to analyze
its own behavior
the attention control system is old but
the
analytical systems that the monkey
employs as a result of its analytical
and
attentional reasoning and so on they are
rather young and i think that feelings
are a way
in which the emotions and motivational
impulses of the elephant are accessible
to the analytic monkey and
so in this sense you could argue that
there is a lot of stuff that precedes
the feelings because there are a way
of communicating between subsystems in
the brain it's the perceptual system
that does the majority of operations in
something like a distributed neural
network
with nearly continuous dynamics and then
this analytical grammatical engine
how do you interface these two systems
and you basically need to
take the features that are being
computed in this distributed perceptual
architecture
and translate them to the localist
discrete analytical model and you do
this by projecting them into a space
and the only space that is consistently
available
is the body map so feelings are
projected into the body map to
disinvigorate them
you could also take the perceptual space
just outside of the body mat but this
changes all the time and we would not
uh self-assign it we could also have a
specific emotion space that is distinct
from the body man why
why don't we have feelings outside of
the body
it's a weird thing and i suspect it's
because feelings have been
implemented as an after thought and
evolution so they had to be mapped into
an existing brain region
so when you uh feel love in your heart
anxiety in your solar plexus is not
because your gut is involved in these
computations
your gut is completely occupied with
hurting bacteria
i think that's simply a projection that
happens
and if you are a paraplegic and you
don't have
access to sensations in your body you
still feel emotions in your body
yeah the linkage between emotions and
feelings is interesting
and at one level you could say they they
go both ways you know again there's been
some very interesting
psychology lab experiments where for
instance i think one of the
more famous ones is a person who walks
across a dangerous bridge
versus a non-dangerous bridge and then
meets a attractive member of the
opposite sex who asks them some
questions for a questionnaire and the
probability of a male
to ask for the questionnaire person's
phone number to ask them for a date
is way higher if they go across the
risky bridge than if they go across the
not
risky bridge so in sense the bodily
sense of
fear or challenge operating
unconsciously well below the conscious
mind
through the body itself seems to program
the mind itself into a different state
yeah it's interesting to speculate why
that is if it's simply
that an achievement to deal with a
subjectively life-threatening situation
uh leads to
a higher sense of competence as the uh
theory would predict and this uh
basically would lead to greater
risk-taking behavior
in the case of that agent but to see if
that is actually the reason we would
need to look at into this in much much
more detail
i've read about these experiments myself
and i haven't really made up my mind
what the actual cause is and what uh
which systems crosstalk and and so on
why is it that we uh fall more easily in
life
after we have been in a life threatening
situation i don't really know
even though i can easily come up with a
few hypotheses which it just did
interesting
yeah exactly well let's do it come up
with one hypothesis love to hear
the yoshi bach take on on that famous
result yeah so the easiest
hypothesis would be if you and uh
basically
master a risk then your willingness to
deal with future risks
increases momentarily because you have a
higher
self-description of competence it's also
the case that you put lesser value on
the perception of risks that you would
normally
fill your attentions basically you
normalize risk
if you are for instance find yourself
with cancer in a hospital
and you are threatened with possibility
of death
then all the things that normally would
give you existential fear
like losing your job or losing the
friendship of a person you don't
particularly like
and so on certainly are no longer
important and as a result you might
start ending relationships that you're
no longer interested or
asking somebody out that you would never
dare asking out because the risk is just
not that high
compared to the actual existential risk
that you have just been facing
so it's basically a rescaling of your
perception of what's important and what
the valence of the important things is
that makes a lot of sense actually and
again i know in your architecture in
other architectures those
states decay relatively rapidly so and
that's why it may
manifest in that particular experiment
where more or less immediately after
having a
challenging experience the test is given
if you came back two days later
might not be the case yeah so in some
sense
the prediction would be that for most
people there is
a range of emotions that adapts
to this situation that the agent is in
so you have roughly the same emotions
and roughly the same proportions as long
as you don't suffer
physical pain or actual threats day to
day
that put you under a real stress as long
as you are existentially safe
you feel roughly the same things at most
of the times
and your emotions will adapt to the
range of events that happen to you
right so it's a normalization that
happens in this way
and if you introduce new events
into this stream of events or if you
change the stream of events
then for instance the amount of anxiety
that you experience about things
might still be the same even though the
events are quite different
and which means you assign a different
different valence to this
same events if they are in conjunction
with others it's probably an interesting
lesson there for organizing your own
life so for instance uh
many people suggest that you always make
sure that
in all ages you introduce a lot of
novelty into your own life so
you always remain young you always store
and new
experiences and information and put
value on them
and that you will undergo frequent
changes of your environment
yeah i think i've been pretty good at
that in my life i'm always getting into
some or other right i never
i never stand still right
congratulations
let's see what we're going to talk about
next get your thoughts on some of the
other
theories of mind i'm sure you have them
one theory that was prominent i don't
know 20 years ago is that mind was
essentially a brain wide
set of interlocking frequencies some of
them
phase locked and some of them rhythm
locked any thoughts on that theory
so when i was confronted with single
theories about that that consciousness
is something like a frequency in in the
brain that was also adopted by
uh christophe cork i didn't understand
it
and uh mostly because it didn't make
functional sense it didn't
explain how this is necessary and
sufficient for producing the phenomenon
i thought that oscillations in the brain
are necessary because
neurons are not able to be in a constant
state and make that constant state to
each other they need to fire
if they are connected in some causal
structure they need to fire in synchrony
right there
will have to be a wave of activation
that passes through the brain this
wave will have to be periodic so you
will look at
a cyclic activations in regular
frequencies and these regular
frequencies that
if you can pick them up on eeg it means
that large parts of your cortex are
firing in sync
so they don't disturb each other and you
can see a common signal
but this signal would be the result of
the synchronization that leads to
consciousness it's not that the
synchronization itself causes
consciousness
and there is on another hand some
interesting insight from the perspective
of a neuroscientist who thinks about how
is it possible that neurons solve the
binding problem
how is it possible that they talk to
each other at all and then you can think
of
neurons as something like for instance
like a neural lattice that is
acting like an ether and the signals
that are being broadcast to the brain
are
moving like electromagnetic signals
would move through an ether
this is a model that you can use as a
crutch to imagine what's going on
and if that happens the question is if
the signals propagate with this neural
lattice
how do the individual neurons tune into
the different programs
that are being played out in the brain
in parallel and it's tempting to think
that there is something like
rm or fm encoding basically some
encoding where the neurons know at which
frequency to tune in
to become part of a certain computation
and maybe this is a viable model
so it's a viable model for how the brain
solves the problem of signal
transmission and synchrony of different
processes over large distances in the
neural cortex
it's probably one of the mechanisms that
plays a role but it's not necessarily
the best metaphor or the best
engineering principle for an
architecture that we would implement
in a digital computer because in a
digital computer we can have random
access where we can relate everything
regardless of
a spatial proximity in the computer
because we can have a bus with a very
high throughput of data
and the individual memory cells in the
computer can
hold arbitrary values without any need
for oscillation
yeah i always think that's an important
point when you're trying to map from the
biological to the machine you know
mother nature
solves problems in a very odd way you
know a teeny step at a time through
evolution over billions of years
and it's amazing the stuff works at all
and if we're going to design one from an
engineering perspective
in many cases we would make very
different decisions that we might get
some functionally similar results back
to
you know brainwide phenomena one of my
favorite cognitive models and you know
he
very honestly says i have no idea how
the mechanism works
is bernard barr's global work space
theory where he believes that the
representation of the sense of
consciousness for instance the
censorium that we live in the movie that
we live inside in
is somehow broadcast to wide areas of
the brain and the various functional
areas of the brain are then able to
process that information
what are your thoughts about bars and
his global workspace theory
even though he himself admits he has no
neurological
argument to support it i think it's
partially born from
intuitions that are the result of
introspection and i think that
introspection is not given enough credit
as an important tool in neuroscience and
philosophy of mind
and psychology there is no real
methodology for introspection i think
it would be great if he could develop
that further and it does exist in the
different
uh meditation schools of course is an
important tool
i think that we don't distribute
consciousness
across the brain into the different
areas but it needs to be the other way
around
the core feature of consciousness is
that we remember what we paid attention
to
if we don't uh remember that we paid
attention to it
then we are not conscious of it in
hindsight
right so it needs to be integrated into
a common protocol
where it can be accessed later on and
this integration
means that it's somehow local so it's
the localization of information that
before existed in a distributed way in
the brain
so it's the protocol where that pulls
from different regions
of the brain it's interesting to
contrast this and to compare this
with the notion of attention in machine
learning that is
currently gaining in prominence yeah
that is interesting and in my own work
that i do in the area of scientific
study of consciousness detention has
always been
absolutely key in my own model and as
you say it's quite interesting that
in the newest neural net architectures
they're using something they call
attention it isn't quite the same but
it's at least analogous there is
something that is very close to the
attention that we have in
our own mental attentional learning the
difficulty is
how can you train a system that is not
organized into neat layers our brain is
not a system that's organized into neat
layers so we could uh train it as a
whole using break propagation with
stochastic gradient descent
and even if we could it would not be the
right way to do it because it's not very
efficient
right it takes enormous amount of time
to train a system many many operations
uh to get it to do the same thing that a
human being can do so
arguably um a human being is much much
quicker
in converging on a model of
interpretation of visual stimuli than
the neural network is
yeah in fact i've used that as a very
important probe in my own work which is
the way the human brain does it must be
rather different
than gradient descent or other similar
methods that are used for
learning in neural nets because i may
have mentioned this on the last show one
of the things that really got me
interested in thinking about this
problem of
learning mechanisms that's when i was
playing a very
advanced and difficult war game i don't
know this was about
2013 or 14 and i realized that i was
able to
learn the game well enough to beat the
pretty good ai really quickly like after
playing seven
games and i realized i was using
transfer learning from the other
times i'd played war games of different
sorts and i started adding it up
how many times had i actually played
relatively sophisticated war games to a
conclusion of a game in my life
and the highest number i could come up
with was 5 000
and probably the real number was
something closer to 2500
so the remarkably tiny number of
examples
of analogous games that i could
presumably mine for transfer
learning and then apply it to this new
game and then learn to play it
at a level good enough to beat the ai
after seven games
and we know that today's artificial
neural net architectures
not even close even the the new good
stuff like
alpha zero still take hundreds of
thousands to millions of plays to learn
even a very stereotyped game
chess or go or something like that and
these games are vastly vastly higher
dimensional space than those games so
high you can't even contemplate
how high they are i figured at least 10
to the 60th
move possibilities per turn just to give
a rough sense of it
so yeah i think that the next frontier
in thinking about
learning and cognitive systems and what
we can learn from humans is that
the rate at which we learn as animals
and not just humans of course
animals learn very rapidly as well have
to be somehow
fundamentally different than what we're
seeing so far from the
world of artificial neural nets we can
learn things super fast if we
can pay attention right the difficulty
is how can you learn how to pay
attention in the right way
there is a famous video on
youtube where a coach trains uh somebody
who doesn't know how to play tennis
to play relatively decent tennis uh
within
the space of half an hour and this is
because he's able to direct the
attention
of the subject in this very great acuity
and tells her exactly what to pay
attention to
so she quickly updates her behavior in
the parts that count
and if you don't know what to pay
attention to you have to in some sense
brute force the problem
by uh applying the other function very
broadly in your system
and hoping that the errors accumulate
eventually in those parts of the
architecture that make the biggest
difference
but it's a very wasteful way of doing it
when i was in new zealand in the 90s
i worked at ian britton's laboratory
it's the same
one in which ben gertzel studied for a
time in shane lack of deep mind
which is a happy coincidence we never
met there but
ian written i think has a great and
underestimated influence
on modern artificial intelligence he's
the father of
arithmetic coding and he takes a data
compression perspective on cognition and
while he
never prominently took a stance in terms
of cognitive science
his main motivation was to understand
how minds work when he studied these
issues
and so when i was working for him he put
me in the lab
and asked me to find structure and
language automatically
so what i did was first look at engram
statistics and i realized that
uh adjacent words in english language
there are so many different words in the
english language that
you cannot really do good statistics
over for instance trigrams or
quadrograms or pentagrams
mostly are restricted to bigrams to
pairs of words
and this means that for instance you'd
lose the predictive power that an
article has for a noun if there is an
adjective between the article and the
noun and if you have multiple adjectives
between the article and the noun
the earlier adjectives are not going to
predict the noun anymore so you forget
you survey most of the structure and our
own minds don't work like this they do
identify
the structure over the entire sentence
so how can i discover the structure how
do i do the statistics
and i started using ordered pairs of
words that didn't need to be adjacent
and tried to go beyond that it was very
difficult because you
have such large statistics that you need
to do and in a way
you need to do curriculum learning like
our own learning does so
we give children very short and simple
sentences
that are short and don't require a lot
of pointers to maintain
so the child knows what to pay attention
to and then we go to the next one
and the child dismisses sentences that
are too complicated to understand for
the child
and if you try to do this in the
learning system you typically don't have
these nice data sets where a human being
interacts with the system and teaches
that language
as we teach our children and make sure
that the problem is learnable
so instead we need to have a mixture
where the system is trying to
have candidates for meaning from
complicated sentences
and then builds up from there and back
then the memory
uh that i had in this computer and the
cleverness of the algorithm that i had
available
were very very limited i was able to
discover grammar eventually
but i was not able to discover style in
the way as gpt3 can do this
and when i looked at the transformer
algorithm that underlies gpt3
it was fascinating to see to me that
they basically found a solution to the
same problems that i
had to deal with in the 90s and couldn't
solve by myself and this is
to basically make statistics over all
the parts
in a working memory and find out which
ones of those are related to each other
and it's still too simplistic because
it's a fixed working memory window it's
not able to
throw things out of its working memory
and put things in it
instead it has 2048 adjacent tokens in
the working memory no
more not less in this implementation
that they use in gpt3
and so for instance you can use this
algorithm to interpret images but only
very very small images
so those that don't have more pixel
elements
than those that fit into this fixed
working memory
and so this algorithm in its current
form is not able to comprehend large
images or video
it's not able to relate the early parts
of a book to a late part in a book
it's only able to keep two pages in
memory at a time and relate
concepts within two pages to each other
using massive computational power
yes i played a little bit with gpt3 and
it's both remarkable
and frustrating right you go wow
what it can produce in terms of you know
emulation of styles and plausible
completions
etc for you know as you say you know
it's within a small domain no matter
frankly i see it not working well if you
try to get it to generate 2 000
characters of text you're pretty much
out into garbage land
pretty quickly but you know in a shorter
frame two or three sentences
it's remarkable and yet and yet
it really doesn't have any language
understanding it's just
it seems like it's just the biggest so
far collection
of associative statistics i think we
have to give a little bit more credit so
i wouldn't say that it's a real shot at
egi
at least not in its present form but it
is able to understand certain things or
at least consistently act as if it
understands it which means i can give it
a task
the way that i give it the task is weird
right it's all autocomplete so i give it
the beginning of a text about the
completion of the task
and then it's able to continue that text
so for instance i could say the
following is an
extraction of sentiments from paragraphs
then i've given two examples
and now now i give it new paragraphs and
it's going to extract the sentiment from
these paragraphs
and if that is simple enough the system
is quite reliable
so i can ask it for instance to of one
of
six key emotional categories in a part
of speech
and whenever i prime the request to it
with uh
telling it that it's currently
continuing a text that is extracting
these sentiments from paragraphs
it's going to do that just fine and this
in some sense a semantic operation it
does understand at some level
what it means to extract a sentiment
from a paragraph
it's only not uh related to a global
model of the universe a global
sense of meaning that we have right when
you and me understand something
it means we have found its place in the
universe
of that thing of course the universe
that we are talking about here is not
the physical universe which you and me
probably don't really understand
physics doesn't really understand it yet
or at least those physicists which don't
understand it yet have not found a
majority that lets
everybody of us understand it in the
same way and
so what we mean by the understanding of
the universe or the universe itself is
our model of the universe that we have
in our own mind
and this model of the universe means
okay there is this
roughly three dimensional world that has
gravity in it and
four forces and most of the interesting
juicy stuff is electromagnetic
including light and sound and it's all
organized in
aggregates of matter that we can
interact with in a certain way and it
implements us and we are contained in it
and it's implementing the following set
of mechanisms more or less
right and in this big interconnected
model that connects everything with
everything
about the universe that we are part of
we find a relationship
a causal structure that explains how
that thing comes into being in a certain
way
and gpt3 is not doing that it does not
have an idea about the universe that
it's part of
instead of it's just babbling but it can
create plausible universes to some
degree it's not fully coherent at some
point the covariance falls apart
and much faster than it does in our own
minds most people are not fully coherent
right
i think maybe no human being is fully
coherent but the incoherence of gpt3 is
much much more blatant than ours
maybe we can improve this by putting a
coherence loss
on its learning instead of just a
surprise of minimization loss
maybe but of course what i think you're
talking about here
is the famous symbol grounding problem
gpt-3
doesn't have its symbols grounded at all
no it has them grounded in language
yeah as you say the red self-referential
back into language it's not grounded
into
yes it's only language but it does have
a proper grounding in in language for
many of the operations that it performs
so when it's able to do a two-digit
arithmetic quite reliably
there is a in some sense a grounding by
treating the
symbols that it manipulates as symbols
that are subject to arithmetic operators
that are properly evaluated right so as
a
functionalist mathematician you should
be satisfied it's not
mapping this onto the same understanding
of exomatics as
proper mathematicians do it but arguably
not all mathematicians do have the same
understanding of
of mathematical axiomatics and this
doesn't make them completely impotent as
mathematicians
yeah though of course we know that gpt3
while it does fine on
two digits starts to fail at three yeah
then again it's
it's trying to predict likely text right
there are not that many human texts
that have a good arithmetic over long
numbers because we don't write texts
about this it's not a human activity
and so it would be inhuman to do that
yeah yeah it does not understand for
instance the idea of the algorithm to do
the arithmetic
right i one time as i think it was just
for fun i wrote
the algorithm to do multiplication
manipulating
text strings right just because i wanted
to make it clear in my head how to do it
it took me like a day to write that it
wasn't that hard but gpt3 doesn't have
anything like that it has no ability to
generate anything like that
if you ask a measure learning system to
find a decently short state machine that
explains all the arithmetic that we
throw at it
then uh the system is quite likely to
discover
the operations that we wanted to
discover it quite quickly
there are deep networks which are able
to do better integration and
differentiation than mathematica and
able to solve things in a short amount
of time or things that can
that mathematica a symbolic system that
is handcrafted
using proven mathematics cannot do
right so it is able to learn things that
mathematicians can do but mathematicians
don't yet know how to do
in the right way and it can learn a few
things that mathematicians maybe cannot
do yet
and dpt3 is just not trained for doing
this and the implication might be that
carl fristen is wrong
that the free energy minimization which
comes down to surprising minimization
translated into the terms of physics
is not the right principle to build a
mind
it could be that you could still say
that you can
minimize surprises better if you are
able to assign the right value to your
meta learning algorithms
but you cannot make those proofs if you
are a simple algorithm
and i think that's the reason why simple
algorithm organisms
are not using a single principle to
organize themselves but have multiple
needs
and these act as reflexes that satisfy
many many dimensions of needs of the
system in the environment and they are
evolved
and we can probably supersede most of
them
they are reflexes and though
interestingly and i think this is
important when
thinking about how to get the agis one
again one of my own little design
principles
is that when you look at things from a
symbolic perspective at least
attempts to solve these high dimensional
problems that even a very
relatively simple organism has to solve
inevitably run into the combinatoric
explosion of options problem
one of the things about these
simple-minded algorithms is they
essentially collapse all that and i'm
relatively convinced that our attention
algorithm
is essentially a hack to get around the
combinatoric explosion of options
problem
let's move on to another topic we're
talking about ways of thinking about
how mind emerges from matter another one
that's become popular over the last
eight or ten years
is to noni's integrated information
theory and you know christoph cook has
also
been a supporter of that you know it's a
head scratcher it's kind of interesting
at one level but
it's relatively easy to create high ii
scores that are clearly not
a mind what do you think about the
integrated information theory with
respect to
mind emerging from matter i think if you
go to
a workshop of the integrated information
theorists
it's a little bit like going to a
climate denialist conference
the fascinating thing is you look at the
conference program of the people that
don't believe in global warming is that
they don't agree with each other
there are some which will argue that
there is
no global warming others will say that
global warming is not man-made
some will just point to arrows in the
way that
the mainstream of the scientific
community talks about global warming and
so on
and they all accept each other's papers
why is that
even though they are so fundamentally
not on the same page there is much more
disagreement between them than
there is this agreement that they
basically have with the mainstream
and it's because they are defined by
their opposition to the mainstream
and the same thing happens with these
workshops about the iit
theory that is the information
integrated information theory
they disagree about how to compute phi
for instance this
measure for integrated information on
what the status of
phi is uh on how relevant it is
on how to interpret uh the concept of
integrated information in the physical
universe and so on
they are mostly opposed to functionalism
and they try to find an alternative to
functionalism
and i suspect that's the main driver for
the popularity within the iit community
within the physics community it's
probably uh
the reason that max tag mark has decided
to make this one of the
planks in his boat that tries to
integrate uh over everything in the
universe from the perspective
of a physicist and so in some sense
the adoption in physics that this is
taken seriously is probably a little bit
political i have great personal respect
for tononi
he basically is a neuroscientist that
earns his money and respect as a sleep
researcher
and he is also a philosopher and an
autonomous intellect
so it's somebody who is not part of a
particular school in philosophy
and as such would be a hard time being
accepted in philosophy
he has a new solution to an age-old
philosophical question
and if that is the case it's usually bad
news because all the good
answers that you can find without labs
have been around for
a very long time you just need to find
and translate them
into the modern language or into your
own concepts
and so if he has found a new solution uh
the question is
what is the solution for what does it
really express and the suspicion that i
have
is that the core of the theory is not
really being published it was also the
impression that i got from personal
interaction
the core of his theory is not phi it's
not this measure this measure was
introduced
as a need to produce a theory with
a quantifiable statements that can be
mapped to
experimental predictions because that's
somehow seen as the gold standard in the
sciences
but not in philosophy for him it's more
an attempt to
find a theory that explains or that
talks about penn psychism and
reintroduces it and it's
mostly because he doesn't see how
functionalism can solve the problem of
consciousness
and he does latch onto this idea
of a distributed information in the
brain but the distributed information
that happens in the brain is
probably not the same thing as it
happens for instance in quantum
mechanics
and i don't think it's non-computable
and it's a little bit ironic if you try
to make a
information theoretic theory and phi is
an information theoretic measure
for consciousness that is not
functionalist because functionalism
information theory
are strongly intertwined it's an
oxymoron to make an anti-functionalist
theory
using information theory i think it
would be helpful for audience if you
could describe
what functionalism means i could try it
but i think you could do a hell of a lot
better job than i
so a very simply put and very cursory
is that functionalism treats a
phenomenon
as a result of its implementation so
for instance what is a bank a bank
is a thing where you can have an account
and you can have an interface to it you
can store money in it
you can extract the money from it it is
conforming to a certain legal interface
it's giving
you certain guarantees that are
compatible with the legal and monetary
system and so on
and if an institution is fulfilling all
these principles then it doesn't make
sense to not call it a bank
and dennett uses this as a metaphor to
explain his opposition to the concept of
a philosophical zombie a system that is
identical in all its features except not
having phenomenal experience
to us and zombank would be a bank that
is basically a thing where you can store
money and
retrieve it again and you can ask for
your account level and
so on but it's not a proper bank because
it lacks the essence of a bank it's a
true bankness the
thing that you cannot really touch and
that has no
causal influence of its interaction with
the outside world
and this uh we would reject this notion
of a zombank as
nonsensical it doesn't make sense to
distinguish between a bank and a zone
bank because there is no essence
of a bank beyond its functional
interface
and uh why would this be different for
consciousness is there some kind of a
hidden essence
and so in some sense functionalism is
the rejection of the notion of a hidden
essence of something
that does not have causal properties
that we can observe
everything can be explained in terms of
its causal properties
and all causal properties ultimately can
be explained
as functions that are implementable
which in my perspective means
computable realizable in the physical
system
yeah i must say when i read dennett's
consciousness explained while i didn't
necessarily buy
his pandemonium theory i did find his
rejection of philosophical zombies
reasonably convincing what's your
thought on that
the pandomian theory by the way goes
back to selfridge and has strongly
influenced
minsky who was selfridge student and has
led to the society of mind and i think
it's a very beautiful theory it says
that the mind is basically a bunch of
agents that implement different
behaviors
and you can entrain your mind with new
demons
and demon is is a good metaphor in
computer science it's
a program without a user interface in a
way without a user facing front end
but it's an automatic behavior that
basically
can be instantiated can run multiple of
them they can interact with each other
and produce combined behavior in your
computer
and in this pandemonium theory you have
a stage where you have the active
behaviors that are currently
populating your working memory and
perform certain tasks
and there are others that are sitting in
the audience and
uh can basically evaluate what's
happening
on stage and they can pull others on
stage or boo some
off stage and those that are on stage
can also
call up their alleys elite behaviors and
get them on stage to enact a certain
scene
and so it's i think a very powerful
metaphor to imagine
how the self-organization of behaviors
in the brain might work
it's not not doing much more than this
it's not yet an implementation
but it's i think a good start to
basically see
a self-organizing system that is
adapting itself to a variety of
unknown situations in the world by
composing a team
of behaviors at any given time so this
is the power of the pandemonium theory
for danette's theory of consciousness
himself i was always wondering why
dennis seemed to be so ineffectual among
philosophers
and among philosophy students a lot of
philosophy students don't like danette
very much
and also a lot of philosophers don't
like dana very much or analytical
philosophy for that matter
and i suspect it's because danette seems
to
miss the problem that people try to
explain he is not talking about that
problem very much
it's not because he cannot explain it
but because it doesn't seem to
think that phenomenal experience is that
important at all it doesn't take center
stage in his philosophy
and i think that could be because janet
is such a nerd
maybe dennis doesn't have that much
phenomenal experience maybe dennett is
somebody
who is extremely constituted on the
conceptual side
and i can relate to that because i am
also very constituted on the conceptual
side it's only that i started observing
this difference in people who are
constituted on the side of feelings
that are constituted in the site of what
the people of science mean
are intuitions maybe pre-scientific
intuitions that
scientists are very very off
i think that a scientist or a true
philosopher is born
as an aberration it happens when a child
is so desperate
that it decides to permanently trust its
ideas more than its feelings
and this is often the case when you are
a nerd you have the best of intentions
you have very pure feelings about how
you should interact with the world
you have compassion for your environment
maybe but you might have poor empathy
because some of the wires in your brain
are not uh wired properly during your
development
and so you cannot guess the mental
states of others you don't have a sense
for the mental states of others it's
difficult for you to figure out
what you should be believing that you
should modify your beliefs to fit in and
so on
and it's maybe repulsive to you to
modify your beliefs just to fit in
or to pretend that you modified them
because you don't like the innate sense
how important that is to play ball
with most humans and so as a child you
fail in your social interactions with
non-nerds and because nerds are few and
far between it's
probably less than six percent of the
population
are on that spectrum you learn that you
cannot trust your feelings when you want
to interact with other people
you fail if you do that right so what do
you do you need to build rational models
for interacting
and i suspect that's one of the reasons
why so many people that are
very very good at rational analytical
models are nerdy
and end up in the sciences and are not
very good at intuition
and at intuitive empathy and at
the resulting social interactions right
it's almost a trope
that uh good scientists are poor in
social interaction
and it's a disaster i think that we are
cherishing
scientists as a lifestyle archetype and
is the goal of the educational system
that every child should somehow become a
scientist
no a proper scientist is very useful to
society
but is a defective human being if there
are
trusting analytical truths which is very
brittle and hard to prove
more than they trust their feelings and
intuitions right science works like this
science works by always finding
analytical truths and only
believing in what you can prove but
this is not viable for life because
almost everything in the world is more
complicated than you can deal with human
logic
right so uh science is able to deal with
the edge cases
but it's not as good in dealing with the
mainstream
of problems that you have in life
scientific theories don't help with most
of the everyday problems
they only help with the difficult edge
cases where your intuitions fail
so in some sense science exists to deal
with our darkest emotions in a very
literal way because uh or
darkest feelings it's those feelings
that are extremely difficult to
disambiguate that's why they're dark
they don't help us they're our feelings
in these darker regions
they don't tell us what to do and this
is where we need logical reasoning
and so i do think that scientists are
important they need to be protected but
they are the result of a particular
mindset
and this is also true for people like
dennett then it is not able to
talk to people or very successfully in
the same way as deepak tropha does
because deepak tropa
might not be analytical completely clean
and pure
but he's able to resonate with people at
a very deep level
where he can tell them what they what
they really care about
what they want to have explained in
their everyday life
so in some sense if we want to make
computationalist philosophy attractive
to
the mainstream we have to explain to
them
how functionalism is dealing with
intuition
this phenomenal experience this uh
the sense for the greater whole with our
sense that we are not confined to a
single self
in a single organism but that we stretch
far beyond that
that we are somehow distributed in the
universe experientially
that's true for normal people it's
probably not true for most scientists
most scientists are confined to their
own intellect at some level
including myself yes and i mean i know a
lot of scientists
and certainly in the scientific
community the kind of folks you're
describing are overrepresented
in fact probably the greater ones are
even more overrepresented but
it's by no means a hundred percent
probably not even 50 percent
probably the greatest scientist i
personally have met and spent time with
was murray gelman and he's an amazingly
social character
right he has social intuitions you know
he knows a lot of things that aren't
about science and he can weave them into
an extraordinarily interesting
conversation
unfortunately he's now passed he was a
great guy out at our santa fe institute
but
you know he was certainly an amazing
scientist who nonetheless was a quite
complete human being so
i would make sure we don't over oh
absolutely well i agree
statistically it's true so these
geniuses that are very good at all the
fields
they they do seem to exist but they're
very rare and uh
far between it's basically people that
are able to integrate so well
over so many areas that they reach that
stage of development
in all the areas right i also would not
say that scientists are
in a moral or exponential sense
incomplete human beings
they are just different from your uh
run-of-the-mill homo sapiens or many of
them are
even somebody like uh noam chomsky who
will very deeply respect
or marry minsky there are people that
have very specific minds right there are
very good at some things and there are
other things that they don't specialize
in
basically they have indications of
aspergers of a mind that is
hyper focused on some areas at the
expense of others
and there is the suspicion that this
hyper focus is the result of a
compensation
that you get super good at uh writing
uh books and uh chomsky is probably one
of the greatest minds of his generation
and also in terms of writing if you ask
him something he's going to
respond with a complete chapter
including footnotes and references
most other people that i know only think
in paragraphs
and actually it's rare only good
thinkers can think in whole paragraphs i
know some that do
so let's get back to the philosophical
zombies and denet
that's an interesting perspective that
dennett doesn't see
the problem and you know maybe the real
payoffs you go one step beyond
philosophical zombies and
go to david chalmers hard problem which
then it also rejects as sort of being a
non-problem
and i think that's relatively close to
his rejection of philosophical zombies
what's your position on chalmers claim
of the hard problem
i suspect that uh charmers in
a part of the time sees ways
out of the heart problem but he's still
mostly on the side where he doesn't
his current philosophy is often focusing
on the question that we don't need to
explain
the heart problem itself we need to
explain why people think that there is a
heart problem
right so we need to explain the
psychological certainty and we can come
up with theories that explain their
psychological certainty so we don't have
to explain
the phenomenon how a physical system can
have conscious experience
we need to explain why we think that we
have conscious experience
that's interesting right and i think
that this
goes in the right direction there is
something that struck me when i was
looking into parapsychology
and i in some sense grew up with a part
of parapsychology for instance
in the 70s and 60s when
uh lsd was around and still not illegal
a lot of people at the cia experimented
this lsd and uh incidentally during the
same time
there were a lot of experiments that
were similar to if you've seen the show
stranger things
the amca ultra program and related
programs we're looking also into
a clairvoyance and into a
far sensing where people would focus
their mind on different parts of the
world
and would use out-of-body experiences to
sense what's going on there
and that number of papers and books came
out of this
by people that were not completely loopy
and that had proper state funding
and when i read this stuff i concluded
this
is probably incompatible with physics as
we know it it's certainly not compatible
with the standard model because we need
more than the four forces
that are compatible with the standard
model to explain what's going on here
and the quantum non-locality
explanations that come
up here are not explaining it because
quantum non-locality does not allow
the transmission of information that
normally would require a photon to send
right it's uh it might be possible that
there are different regions of the
universe that share state
but you don't know which regions of the
universe these are
so you would need to have a classical
back channel to that region
to know about the entanglement between
these different regions
and so it's not obvious that there is
some kind of quantum mechanical
explanation for psy
phenomena and as a result either
significant parts of physics that work
extremely well in the lab are wrong
or these phenomena are not correct you
know our mutual friend ben gertzel is a
fan of
these psy type things yes he is also
incidentally a big fan
of psychedelics yep i'll confess to have
done a little psychedelics in my day
though not in
40 years and they are an interesting
altered state
so there is a correlation between
psychedelics and
the ability to look into the future
without winning the lottery
right there's a weird thing about sci
phenomena they don't seem to change the
physics of the universe
or the statistics of the universe very
much if we
could evolve the ability to reliably
far sense or look into the future
we should see a lot of animals that do
this in predator prey dynamics
we should have a small subset of the
population at least
that quite reliably wins the lottery
without cheating
yet the banks still win how is that
possible it's a an argument that for
instance has been made by stanislav lam
and
i think suma technology and one of his
purely philosophical books
that don't make a concession to the
reader if it's a very beautiful one and
where he argues against psy in this
regard also had a very good friend
at my time in harvard she still is a
good friend i hope
she had prophetic dreams every night
lucid dreams
it's very difficult to deal with this
because
she was often able to look into the
future during the streams
and she started writing this down and
she noticed that when she was
experiencing things
that were costly relevant that basically
would be the equivalent of winning the
lottery that would change the future in
any way
she was unable to write them down and
it's like the men in black basically
prevented her from doing that and i
think there's only one good explanation
for that the explanation is that your
memories are changing
retroactively so you don't remember when
your memory changed
you don't remember when your
construction of reality changed she was
not able to write it down
because she didn't know it at the time
that these lottery numbers would come
these lottery numbers come and together
with the
knowledge about these lottery numbers
you instantiate the memory
of having foreseen what these lottery
numbers were
right this is the easiest explanation
yeah
and in which case you actually did not
know the lottery numbers right you had
the memory of knowing the lottery
numbers not actually knowing them
yes but there's a deeper phenomenon here
so if the
uh spiritists and the psi theorists and
parapsychologists are right
and i'm not completely ready to dismiss
them and turing was also not doing so
right it is if the same is 1950 papers
makes explicit
and affirmative references to the higher
probability that telepathy is real
so he even asked the question could an
ai system be truly intelligent if it's
not telepathic
or would this be a sufficient
intelligence if it's not telepathic
there is a deeper implication that he
doesn't discuss
if telepathy is real if there is a
possibility to use
unknown physics to send information
across
minds that are not in any kind of
known signal in relationship to each
other so there are adjacent so you can
observe the other one
and entangle yourself with their own
vibrations in their mind just
using your visual sense or other known
senses right
if if that is true if there is something
like telepathy using an
unknown physical causal mechanism
how can you guarantee that your
consciousness and your mind is
computed in your own brain how can you
guarantee that your brain is not merely
an antenna
and the consciousness is computed
elsewhere maybe outside of the universe
and you are
partake in this universe right in this
consciousness
yeah that's the pedro's hypothesis right
that the microtubules are somehow
quantum antennas that allow us to get
signals from across the multiverse
perhaps
i don't really understand why penrose is
affiliating himself with that so much
right
it's it's difficult because his uh
theory is different from hamerov's
theory i've never
seen penrose actively endorsing the
microtubule in the same way as hammeroff
does
in my view and i really really like
hammeroff as a person
hammeroff is building a psychedelic
sculpture garden this is theory
it's a theory that is making more
predictions every year or more
explanations every year using the same
mechanisms
and so it's a theory that explains how
anesthesia works how
psychedelics work how consciousness
works
and now also how evolution and emotion
work all
uh using the pi resonant uh quantum
underground
in a way that i was at the science of
consciousness conference sitting in the
audience and he was
putting stuff on the screen and i felt
that my basic understanding of physics
was sufficient to
understand where the physics ended and
asked the people next to me are you not
concerned that you don't understand what
he's talking about
in his physics about the pi resonant
quantum underground
and i said don't worry be shut down as
soon as he mentions that
oh dear it's not the important part of
the siri
i truly have not checked his stuff out i
will have to it's super interesting
to read it and it's it's really
beautiful i like it uh
it's it's also very poetic in a way but
i think it's more art than
science because it's uh integrating
observations it's projecting things it's
connecting
loose ends but it's not doing this in
the same way as
a scientist would probably do it which
explains it's a lack of resonance in the
sciences right there is
almost nobody outside of the pen of his
circle
who is citing these papers and working
with this and things that they are in
any way real
and worse uh discussing the reason i
think why penrose is affiliated with is
it's um you know if you are excluding
all the viable explanations except one
or the all the probable explanations
then the improbable explanation has to
be the reason
and penrose thinks that computation
cannot explain
uh all of consciousness and i think it's
because of this way he interprets
griddle's proof girdle has in some sense
proven that
computation is insufficient to do all of
mathematics
there are parts of mathematics that
cannot be done in the computational
paradigm
assuming so leads into contradictions
and penrose believes that human
mathematicians can do these parts that
computation cannot do
i think the resolution works the other
way around these other parts of
mathematics were never real mathematics
was ill-defined
the true theory of classical semantics
is wrong
you can only claim that something is
true if you can actually compute that
truth
you can only claim that something has a
value if you can actually compute that
value it's basically constructive
mathematics and constructive mathematics
is
roughly the same thing as computation
and what
girdle has shown in my view is that
constructive mathematics is real
or can be real in the sense it can be
implemented but classical mathematics
that
contains infinities cannot be
implemented cannot be real
nothing in the physical universe relies
on having known the last digit of pi
right there are mathematics that pretend
that they are
that this works and some of these
mathematics are even used in physics
but they're not real they're not
computable they cannot be implemented in
any physical causal structure
so this was the implication and this is
an implication i think that
penrose has not seen he believes that
the
ability of our minds to be conscious are
related to the uncomputable part of
mathematics and the
uncomputable parts of mathematics go
beyond known physics which in some sense
is all
computational right even quantum
mechanics takes a bunch of numbers
and perform some expensive computations
on them and then you get the next bunch
of numbers
and this is how we explain the universe
and the only part that is not explained
in this paradigm so far is quantum
gravity
so uh the culprit must be quantum
brevity right it's the only thing that's
left
from penrose perspective and the only
one who tries to offer a theory that
uses quantum gravity
to explain consciousness in the brain is
penrose using his microtubule
and i think this is how it comes
together interesting yeah
i've truthfully read it when it came
when he came out read a couple things on
it and i just put it aside and says
well i'll know that it's out there but
i'm not going to pay it any mind until
somebody comes up with some useful
experimental results
and i'll have to check out this hammer
off character i don't know about him
but let's go slightly back to this uh
big distinction between
physics and the parasite quality
which leads us into a different world i
think
that there are only two possibilities
either we live in a mechanical universe
and this is the hypothesis of physics it
says that everything
is at some level there is a causally
closed mechanical layer
and this doesn't mean that they close a
closed mechanical layer needs to look
like
what the universe looks like to us right
the einstein space
and our theories of quantum mechanics
are probably high level descriptions
that don't describe the coarsely closed
lowest level
but it's still mechanical it's still
built in such a way that can be
expressed as a computer program
and the alternative to that is that we
live in a dream
what's the difference between a dream
and a mechanical model
a dream has magical interactions the
symbolic interactions which means you
sacrifice the cat and the comment
appears or the comment appears
and it predicts your career there is no
known physical force
or plausible physical relationship that
we could discover
that would explain this kind of
interaction it just means that somebody
is messing with us there is a conspiracy
right the same conspiracy that exists in
minecraft if you open up a console and
set time set day
and the sun suddenly rises in minecraft
where you basically supersede the basic
low level
uh causal mechanics of minecraft
using a higher level of causation that
is
outside of the basic game dynamics
and this would be a world in which psi
is possible in which uh
say in the esoteric parapsychological
sense
that you can use telekinesis to overcome
physics
or where you can use clairvoyance to
overcome the limits of information
transmission
via a subliminal photonic transfer
of data between different regions of the
universe right
so how is that possible and i think the
reason
that this is so attractive that the
theory that we essentially
must live in a dream is that we actually
live in a dream
we do live in a dream it's it's possible
to have these experiences it's possible
to experience telepathy it's possible to
experience clairvoyance and so on
and it's because we live in a dream that
is generated
by a mind on a different level of of
existence and this different level of
existence happens to be physics and our
culture is a little bit confused because
it assumes that the world that you and
me see in everyday life is physics
is the physical world but there are no
colors in physics and no sounds in
physics
what we perceive is still the dream and
our
brain that is out there in physics does
not really look pink and squishy in
physics
it's only a thing that as this is what
it looks like in the dream
the dream that the brain is generating
and to get this right that is an
important thing yeah
well we i think we all know we've known
for a long time that we don't experience
actual reality you know we have an
interpretation of reality and then
we have meaning maps right so we don't
experience a simulation of reality it's
a simulacrum of reality
it's completely as if it's not
isomorphic to the world out there in
physics
and it's at different levels of
distraction right you mean the human
perceptual
capability can't tell us about atoms for
instance right without instruments
and you know the idea of colors even as
we know from anthropology the different
cultures
divide the spectrum up in different ways
so some
tribe in the amazon might not describe
the brain as pink and squishy it might
be blah blah
and squishy which is a very different
narrower part of the spectrum than pink
for instance or probably much broader i
think
actually we have a more fine-grained
color than many cultures so yeah
they're meaning maps and i think that's
where people get confused
i still remain a naive realist at heart
you know i do believe there is an
objective universe out there can't prove
it
you know as we well know i can't
logically prove the universe wasn't
created five seconds ago with
all the objects in it including our
memories and all ballistic objects in
motion but
if only for parsimonious reasons i
assume there is a
real universe out there and as you say
we have some physical laws but they're a
very long way from the planck
scale so there's probably a shitload we
don't know right
and yet so far they have shown
themselves to be remarkably
lawful we haven't been able to detect at
least with a high fidelity signal
any sigh any any real even deviation
from deep lawfulness and so at least
tentatively
i side with the physicist though i do
encourage ben which he does regularly
send me new papers on psy because
as you say if we're wrong or if i'm
wrong and
psy is real then we have to reevaluate
is the universe actually lawful
and maybe it's not just a dream maybe it
is a simulation but
for the time being i reject that on
grounds of parsimony of no other reasons
yeah so the only reason to not do it is
be uh to not accept this theory is
because you don't think that scientists
are able to explain the things that need
to be explained
which is why does reality appear real to
us
it from a machine learning perspective
it's pretty clear that if a learning
system does
not in some sense implement the belief
that the universe is learnable
then it's not an effective learning
system right
you have to believe in the learnable
universe to learn it
it's implicitly and uh so the weird
thing that we have to explain
is i think not the qualities of qualia
the qualities of qualia
are easier than most people think
because this is just the geometric
calculations that your perceptual
systems are making
it's basically the dimensions the
parameterizations of
the geometric architecture that is
computing
the perceptual models and in some sense
this
has been neglected for a long time
because scientists have focused on the
linguistic the analytical models too
much
and only with the widespread takeoff of
the machine learning paradigms and deep
learning paradigms
i think it has gotten more into the
common consciousness of cognitive
science
that perception is more akin to the deep
learning systems
than it is to linguistic systems to
symbolic systems
right the paradox is you can of course
implement the deep learning systems on
top of symbolic systems that we
actually have to they're completely
implement on top of symbolic systems
but they are symbolic systems that are
very different from our symbolic
reasoning our symbolic reasoning is
arguably
limited to a very small stack size into
very few elements at the time
we cannot hold more than like five to
seven elements in
our focus of attention at a time and
relate them to each other
unlike uh gpt3 that is looking at 2048
and relates them all to each other at
the same time
and is doing this in many many
dimensions and
with extremely high resolution and
availability and no lapse of attention
so this is a very different way of doing
symbolic operation than our mind is
doing
it's doing this on the level of low
level automata but we have to explain to
people how
the property of realness comes about and
the property of realness itself
is paradoxically not a feature of
physical reality
physical reality doesn't feel like
anything there are no feelings in there
physical realness can only be
experienced as part of a model because
it's itself a model property
right it's a label that the mind
attaches to some of these parameter
dimensions
and if you look at them you distinguish
the non-real imagination from the real
world that you experience by this label
that your mind says this is indeed
predictive of your net
next batch of sensory patterns as far as
i can make it
and this includes the internal
sensations that you have about your own
self
in your own thinking processes and
reasoning processes and your
experiential processes
your experiences are real experiences
because they are predictive
of your next experiential features right
there are models
of what you experience and the realness
itself
is a model of of the fact that they are
predictive
yeah though of course it's true that for
humans again as i said before
the resolution of our measurements and
perceptions are
pretty gross and we're able to go way
beyond that with our scientific
instruments
yes we evolved as if we are in a lawful
universe
because that's what works right but it
may well have been that we were
so coarse graining the universe due to
our low resolution vision you know the
acuity of our feeling
the ability to decompose matter that we
could have easily been
fooled by something going on deeper down
right
at least unless our instruments are
lying to us we can probe
i don't know 20 orders of magnitude
smaller than we can
get at as unaided humans and 20
orders of magnitude larger and yet
lawfulness still seems to prevail
in both the microcosm and the macrocosm
even though
our formulations of the laws are almost
certainly
very substantially incomplete that seems
to me much
stronger evidence for reality deep
reality than merely our sense of reality
though i do take your point that
you know reality is not an attribute of
the universe itself but it's rather
an experience of a conscious agent
living in the universe
but i would say we should have more
confidence in reality than merely our
naive
animal consciousness because of the fact
that we've been able to extend our
probes
a long way in both to the microcosm and
the macrocosm
i think it's important to hold it
somewhat tentatively
i think that to have an enlightened
relationship to reality it is necessary
to
realize that what you perceive is a
representation this includes yourself
and your relationship to the universe
and this is all in some sense a
representation that you don't perceive
as a representation but as an immediate
reality
and you need to make it visible as a
representation you need to pay attention
to that
you also need to pay attention to
attention in such a way that the
attention itself
becomes visible to you that you can
notice how your attentional system works
and how it's constructing your reality
if you are interested in that and for a
normal human being
the only reason to be interested in that
is because it doesn't work
and since these attention processes tend
to work very well
most people don't pay attention to them
and just take them as given the
processes of reality construction
and the people that are familiar with
these processes are those that are
naturally in altered states of minds
because they fell down the stairs at
first at some point
or have developmental issues or because
they
are in an existential crisis for
instance and this existential crisis
makes it necessary for them to
understand their own relationship to
meaning
and their own self-construction yeah
let's step back a little bit
we've been talking about mind emerging
from matter we've talked about a lot of
the leading theories
we've talked about some of the out there
theories from your perspective
what's important for the next step in
the science of explaining
mind emerging from matter where should
we be looking
next what's the next 10 years look like
so it's of course always very difficult
to make predictions especially about the
future
yes thank you yogi yeah yes
i suspect that one of the very
interesting areas that we need to look
at is
attention-based models and
the transformer is only the beginning
from my perspective there are
at least three obvious things that are
wrong with gpt3
interestingly the fact that gpt3 is not
an agent
is not one of them that can be easily
fixed right the gpt's
is obviously not an agent it doesn't
have a context so if you tell
gpt3 hey you are gpt3 what are you
then gptc will uh produce a relatively
random sentence
because uh gpt3 has been trained on
statistical
statistics and language until october
2019 and gpt streets didn't exist in
october 2019
right so unless uh openaa has built
something into gpt 3 explicitly to teach
it about gpt3 what it should say
it doesn't know what it is and if you
tell gbt3 i am talking to the aigp t3
and so on then it will assume in some
sense implicitly for some
meaning of assume that uh it's talking
about some kind of science fiction
context or a technical context in which
a human is communicating with an ai
system
and then it might guess a number of
things right but it doesn't know which
ones are right or not
it also doesn't know whether it relates
to any kind of reality
right there is no sense of an underlying
reality there is no
fixed context but you can add this fixed
context by making additional commitments
and you need to make these additional
contexts commitments i think this is an
implication of loops theorem which is
a recasting of goodell's proof a system
is not able to basically break out of
its own exomatic system
and make statements about exomatic
systems above it
in order to for a system to reason about
itself it needs to recreate itself this
in its own formalisms
and then make a statement about this
recreation of itself
so for formal systems that you have
created of course you can
build them in such a way that you can
recreate the formal system within the
formal system
so the system can make proofs about
itself but
strictly speaking you cannot make proofs
above yourself
you can solve this problem of agency in
gpt three i think by building
uh in principle a vision tool speech
module
a vision to text module that is
interpreting the camera images of a
robot
sends them to gpt3 and then gbt3 tells a
story about a robot in that world
and then a parser is reading these
statements and translates them into
motor actions of the robot
and we continuously play that game and
now arguably uh
language is not the right level of
resolution we want to have something
that is sub-conceptual we want to deal
with perceptual
stuff but gpt 3 is able to deal with
that right there is
image gpt which is able to learn the
statistics of images in the same way as
a guy inward or even
arguably in a better way than a gun
would visit the limits of its small
attentional window
so the main issue i think is the
creation of a larger attentional window
at the moment
gpt3 has massive retrograde amnesia it's
not able to remember anything from two
pages ago
except the extractions that it made from
that it's
uh able to change its neural network as
a result even though it doesn't do
online learning
is but during training it is of course
it
takes something from it has seen before
but it's not able to re-establish the
context in which it took it
it took these insights right when i read
a book
i might in a later chapter recall an
earlier chapter
and create a context this is merging the
current
chapter with the previous chapter and
then uh
rewrite everything that i learned from
the previous chapter in the new light
because i i can reconstruct what i
learned from the previous chapter and
where i got this knowledge from and so
on
right so for instance i i have an idea
that i misunderstood or that there was
too simplistic
and i need to rewrite this idea and i
asked myself where did i get this idea
from why and how am i revising this
right and now i create a
new working memory context in which i
direct my attention
and this working memory construction is
a thing that gptcv
cannot do yet so we need to extend
attention in such a way that it's able
to change working memory context
actively and construct working memory
contexts
and we need to change the level of
representation from
language to a multi-modal representation
that
is agnostic to what it represents and
addresses
and you know you mentioned something in
passing which i want to call up
which is rewriting you know one of the
things that we know humans do is our
memories
are not only low fidelity but they're
also quite subject to be
rewritten right and certain kinds of
linguistic processing may be
implementable as rewrite rules
and you know i think we both have had
some exposure to the open cog system and
the open cog system
a lot of it's based on the concept of
both local and global rewriting
and that seems very far from gpt3 i mean
it is what it is it doesn't have any
essentially dynamic rewriting capability
going on in it
exactly so this is the second thing that
is wrong with gbt3 in my view
the first thing was the working memory
window which is limited to
2048 adjacent tokens and basically there
are hard constraints in there
in which the working memory is used that
don't exist in our own mind
it's not necessarily that our working
memory is larger i suspect it's much
smaller than the ones
of gpt3 but we are able to construct the
contents of our working memories with
way more degrees of freedom
so this is the first thing the second
one is online learning gpt 3 is only
doing offline learning which is good for
an industry industrial production system
that is meant to behave
in pretty much the same way but if you
want to build a system that is working
like us it needs to continuously learn
gpt3 has stopped
learning in october 2019 so it doesn't
know about anything about covet 19
or george floyd it lives in a different
universe
and we need to have an agent that is
constantly learning and
tracking reality in real time around it
but this is something that also can be
overcome right it requires massive
changes to the algorithms that are being
used you cannot use the same
neural learning algorithms that are
currently implemented
in gpt3 but it's nothing that is
completely out of this world this can be
done
and the last thing is relevance
gpt 3 does not care about relevance the
relevance
sensation that gbt3 has is because
humans don't write everything into texts
they write things into text that are
relevant to them
so by minimizing the surprisal on all
the available texts that have
a decently good scoring on reddit means
you are probably learning something
interesting
it was interesting enough for a human to
write it down right so
just by learning from this this is way
way better than random stuff
but this is not sufficient for a system
that is interacting with the world and
takes in
rich sensory data on many modalities at
the higher bandwidths that
you can process in real time so in this
case you have to focus on those parts of
the model that are most promising
and for this you need to have a
motivational system
and i think that in practice you
will have way better results from
systems that are able to assign
relevance to learning and meta learning
in ways that the current gpt 3 is not
right so gpt swing can do style learning
in ways that no human being can do
because it learns all this stuff which
we find is
irrelevant when you read the textbook
you don't care about the style so much
you care about the content and gpt suite
does not think that the content is more
important than the style
it only looks for style and goes for so
deep style that
ultimately it often bottoms out in
content yeah say a little bit more
about you know the affective part and
how that might be added into gpt3
are the effective part uh is uh in
it's basically something where the psi
theory i think is still one of the best
theories today
the uh sci theory posits that
you can describe an agent like us
using homeostasis as a guiding principle
so there is
a homeostatic balance that keeps the
system stable in the face
of an environment that disturbs it our
mind is
in some sense solving a control problem
in many dimensions
and these control dimensions are given
to us as needs that when frustrated
produce
pain signals and then satisfied produce
pleasure signals
and this when we act on these needs we
act on purposes and models of our needs
and we have strong
biases on what kind of models of our
needs we form
and this hierarchy of purposes that we
form that becomes coherent is in some
sense the
structure of our soul it's it's not a
random set of behaviors that is just
sitting next to each other and randomly
arranged
it's a system that strives for coherence
and the more coherent it is
the more our mind appears to be as
a singular solid thing that has a
definite structure
and in some sense you could say the our
true soul is the platonic form the ideal
form
of all these purposes arranged in the
right hierarchy including our
transcendental purposes that go beyond
the individual and its present
time and space that it occupies
okay i think there we're about out of
time we didn't get to any of the
low-level things i wanted to talk about
but that was all right i think our
conversation was
good and rich and went a long way and i
hope the audience
appreciate it i know i certainly did so
joshua i'd love to have you on the show
again sometime to
talk about what you're thinking about
microside 3
and things in your own workspace but i
really want to thank you for this
amazingly broad ranged and yet deep
discussion
i thank you too i really enjoyed talking
to you again
and let's do it again sometime
[Music]
production services and audio editing by
jared janes consulting
music by tom muller at
modernspacemusic.com